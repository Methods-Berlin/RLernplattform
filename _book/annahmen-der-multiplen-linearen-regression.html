<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Annahmen der Multiplen Linearen Regression | R Lernplattform</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Annahmen der Multiplen Linearen Regression | R Lernplattform" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Annahmen der Multiplen Linearen Regression | R Lernplattform" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
set in the _output.yml file.
The HTML output format for this example is bookdown::gitbook,</p>" />
  

<meta name="author" content="Methodengruppe Berlin" />


<meta name="date" content="2022-12-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="wide--long-format.html"/>
<link rel="next" href="grafiken.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/d3-bundle-5.16.0/d3-bundle.min.js"></script>
<script src="libs/d3-lasso-0.0.5/d3-lasso.min.js"></script>
<script src="libs/save-svg-as-png-1.4.17/save-svg-as-png.min.js"></script>
<script src="libs/flatbush-4.0.0/flatbush.min.js"></script>
<link href="libs/ggiraphjs-0.4.6/ggiraphjs.min.css" rel="stylesheet" />
<script src="libs/ggiraphjs-0.4.6/ggiraphjs.min.js"></script>
<script src="libs/girafe-binding-0.8.5/girafe.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R Lernplattform</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html"><i class="fa fa-check"></i><b>1</b> Installation und Aktualisierung von R und RStudio</a>
<ul>
<li class="chapter" data-level="1.1" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#windows"><i class="fa fa-check"></i><b>1.1</b> <strong>Windows</strong></a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#installation-von-r"><i class="fa fa-check"></i><b>1.1.1</b> Installation von <span class="r"><strong>R</strong></span></a></li>
<li class="chapter" data-level="1.1.2" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#installation-von-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Installation von <span class="r"><strong>RStudio</strong></span></a></li>
<li class="chapter" data-level="1.1.3" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#aktualisierung-von-r-mit-übernahme-der-pakete-aus-der-älteren-version-paket-installr"><i class="fa fa-check"></i><b>1.1.3</b> Aktualisierung von <span class="r"><strong>R</strong></span> mit Übernahme der Pakete aus der älteren Version (Paket <strong>installr</strong>)</a></li>
<li class="chapter" data-level="1.1.4" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#aktualisierung-von-rstudio"><i class="fa fa-check"></i><b>1.1.4</b> Aktualisierung von <span class="r"><strong>RStudio</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#mac"><i class="fa fa-check"></i><b>1.2</b> <strong>Mac</strong></a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#installation-von-r-1"><i class="fa fa-check"></i><b>1.2.1</b> Installation von <span class="r"><strong>R</strong></span></a></li>
<li class="chapter" data-level="1.2.2" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#installation-von-rstudio-1"><i class="fa fa-check"></i><b>1.2.2</b> Installation von <span class="r"><strong>RStudio</strong></span></a></li>
<li class="chapter" data-level="1.2.3" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#aktualisierung-von-r"><i class="fa fa-check"></i><b>1.2.3</b> Aktualisierung von <span class="r"><strong>R</strong></span></a></li>
<li class="chapter" data-level="1.2.4" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#aktualisierung-von-rstudio-1"><i class="fa fa-check"></i><b>1.2.4</b> Aktualisierung von <span class="r"><strong>RStudio</strong></span></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="installation-und-aktualisierung-von-r-und-rstudio.html"><a href="installation-und-aktualisierung-von-r-und-rstudio.html#hinweis-zur-replizierbarkeit-von-analysen"><i class="fa fa-check"></i><b>1.3</b> <strong>Hinweis zur Replizierbarkeit von Analysen</strong></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="einführung-in-r.html"><a href="einführung-in-r.html"><i class="fa fa-check"></i><b>2</b> Einführung in R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="einführung-in-r.html"><a href="einführung-in-r.html#funktionen-pakete"><i class="fa fa-check"></i><b>2.1</b> <strong>1. Funktionen &amp; Pakete</strong></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="einführung-in-r.html"><a href="einführung-in-r.html#funktionen"><i class="fa fa-check"></i><b>2.1.1</b> Funktionen</a></li>
<li class="chapter" data-level="2.1.2" data-path="einführung-in-r.html"><a href="einführung-in-r.html#pakete"><i class="fa fa-check"></i><b>2.1.2</b> Pakete</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="einführung-in-r.html"><a href="einführung-in-r.html#daten"><i class="fa fa-check"></i><b>2.2</b> <strong>2. Daten</strong></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="einführung-in-r.html"><a href="einführung-in-r.html#datentypen"><i class="fa fa-check"></i><b>2.2.1</b> Datentypen</a></li>
<li class="chapter" data-level="2.2.2" data-path="einführung-in-r.html"><a href="einführung-in-r.html#datenstrukturen"><i class="fa fa-check"></i><b>2.2.2</b> Datenstrukturen</a></li>
<li class="chapter" data-level="2.2.3" data-path="einführung-in-r.html"><a href="einführung-in-r.html#objekte"><i class="fa fa-check"></i><b>2.2.3</b> Objekte</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="einführung-in-r.html"><a href="einführung-in-r.html#weitere-hilfen"><i class="fa fa-check"></i><b>2.3</b> <strong>3. Weitere Hilfen</strong></a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="einführung-in-r.html"><a href="einführung-in-r.html#kurzbefehle"><i class="fa fa-check"></i><b>2.3.1</b> Kurzbefehle</a></li>
<li class="chapter" data-level="2.3.2" data-path="einführung-in-r.html"><a href="einführung-in-r.html#andere-lernplattformen-und-übungen"><i class="fa fa-check"></i><b>2.3.2</b> Andere Lernplattformen und Übungen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html"><i class="fa fa-check"></i><b>3</b> Einführung in RStudio</a>
<ul>
<li class="chapter" data-level="3.1" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#allgemeines-zu-rstudio"><i class="fa fa-check"></i><b>3.1</b> Allgemeines zu <code>RStudio</code></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#skript"><i class="fa fa-check"></i><b>3.1.1</b> <strong><span class="r script">Skript</span></font></strong></a></li>
<li class="chapter" data-level="3.1.2" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#konsole"><i class="fa fa-check"></i><b>3.1.2</b> <strong><span class="r cons">Konsole</span></font></strong></a></li>
<li class="chapter" data-level="3.1.3" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#environment-history"><i class="fa fa-check"></i><b>3.1.3</b> <strong><span class="r env">Environment &amp; History</span></font></strong></a></li>
<li class="chapter" data-level="3.1.4" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#files-plots-packages-help-viewer"><i class="fa fa-check"></i><b>3.1.4</b> <strong><span class="r help">Files, Plots, Packages, Help &amp; Viewer</span></strong></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#weitere-hilfen-1"><i class="fa fa-check"></i><b>3.2</b> Weitere Hilfen</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="einführung-in-rstudio.html"><a href="einführung-in-rstudio.html#kurzbefehle-1"><i class="fa fa-check"></i><b>3.2.1</b> Kurzbefehle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="pakete-1.html"><a href="pakete-1.html"><i class="fa fa-check"></i><b>4</b> Pakete</a>
<ul>
<li class="chapter" data-level="4.1" data-path="pakete-1.html"><a href="pakete-1.html#was-ist-eine-grafische-benutzeroberfläche"><i class="fa fa-check"></i><b>4.1</b> Was ist eine grafische Benutzeroberfläche?</a></li>
<li class="chapter" data-level="4.2" data-path="pakete-1.html"><a href="pakete-1.html#was-ist-cran"><i class="fa fa-check"></i><b>4.2</b> Was ist CRAN?</a></li>
<li class="chapter" data-level="4.3" data-path="pakete-1.html"><a href="pakete-1.html#pakete-installieren"><i class="fa fa-check"></i><b>4.3</b> Pakete Installieren</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="pakete-1.html"><a href="pakete-1.html#über-die-funktion-install.packages"><i class="fa fa-check"></i><b>4.3.1</b> Über die Funktion <code>install.packages()</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="pakete-1.html"><a href="pakete-1.html#über-das-icon-install-oder-den-menüpunkt-install-packages"><i class="fa fa-check"></i><b>4.3.2</b> Über das Icon <span style="color: #75AADC">Install</span> oder den Menüpunkt <span style="color: #75AADC">Install Packages…</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="pakete-1.html"><a href="pakete-1.html#pakete-laden"><i class="fa fa-check"></i><b>4.4</b> Pakete Laden</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="pakete-1.html"><a href="pakete-1.html#über-die-funktion-library"><i class="fa fa-check"></i><b>4.4.1</b> Über die Funktion <code>library()</code></a></li>
<li class="chapter" data-level="4.4.2" data-path="pakete-1.html"><a href="pakete-1.html#über-das-häkchen-setzen-in-der-system-library"><i class="fa fa-check"></i><b>4.4.2</b> Über das Häkchen-Setzen in der <span style="color: #75AADC">System Library</span></a></li>
<li class="chapter" data-level="4.4.3" data-path="pakete-1.html"><a href="pakete-1.html#maskierung-wenn-verschiedene-pakete-gleich-benannte-funktionen-enthalten"><i class="fa fa-check"></i><b>4.4.3</b> <strong>Maskierung</strong>: Wenn verschiedene Pakete gleich benannte Funktionen enthalten</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pakete-1.html"><a href="pakete-1.html#pakete-aktualisieren"><i class="fa fa-check"></i><b>4.5</b> Pakete Aktualisieren</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="pakete-1.html"><a href="pakete-1.html#über-die-funktion-update.packages"><i class="fa fa-check"></i><b>4.5.1</b> Über die Funktion <code>update.packages()</code></a></li>
<li class="chapter" data-level="4.5.2" data-path="pakete-1.html"><a href="pakete-1.html#über-das-icon-update-oder-den-menüpunkt-check-for-package-updates"><i class="fa fa-check"></i><b>4.5.2</b> Über das Icon <span style="color: #75AADC">Update</span> oder den Menüpunkt <span style="color: #75AADC">Check for Package Updates…</span></a></li>
<li class="chapter" data-level="4.5.3" data-path="pakete-1.html"><a href="pakete-1.html#entwicklerpakete-runterladen"><i class="fa fa-check"></i><b>4.5.3</b> Entwicklerpakete runterladen</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="pakete-1.html"><a href="pakete-1.html#wichtige-hinweise-zur-replizierbarkeit"><i class="fa fa-check"></i><b>4.6</b> Wichtige Hinweise zur Replizierbarkeit</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="pakete-1.html"><a href="pakete-1.html#replizierbarkeit-von-r-skripten"><i class="fa fa-check"></i><b>4.6.1</b> Replizierbarkeit von <code>R</code>-Skripten</a></li>
<li class="chapter" data-level="4.6.2" data-path="pakete-1.html"><a href="pakete-1.html#replizierbarkeit-von-analysen"><i class="fa fa-check"></i><b>4.6.2</b> Replizierbarkeit von Analysen</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="pakete-1.html"><a href="pakete-1.html#weitere-hilfen-2"><i class="fa fa-check"></i><b>4.7</b> Weitere Hilfen</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="pakete-1.html"><a href="pakete-1.html#probleme-mit-paketen-und-funktionen"><i class="fa fa-check"></i><b>4.7.1</b> Probleme mit Paketen und Funktionen</a></li>
<li class="chapter" data-level="4.7.2" data-path="pakete-1.html"><a href="pakete-1.html#ältere-paket-versionen-installieren"><i class="fa fa-check"></i><b>4.7.2</b> Ältere Paket-Versionen installieren</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="pakete-1.html"><a href="pakete-1.html#faq"><i class="fa fa-check"></i><b>4.8</b> FAQ</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="pakete-1.html"><a href="pakete-1.html#entwicklerpakete"><i class="fa fa-check"></i><b>4.8.1</b> Entwicklerpakete</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="daten-importieren.html"><a href="daten-importieren.html"><i class="fa fa-check"></i><b>5</b> Daten importieren</a>
<ul>
<li class="chapter" data-level="5.1" data-path="daten-importieren.html"><a href="daten-importieren.html#vor-dem-einlesen-in-r"><i class="fa fa-check"></i><b>5.1</b> <strong>Vor dem Einlesen in <span class="r">R</span></strong></a></li>
<li class="chapter" data-level="5.2" data-path="daten-importieren.html"><a href="daten-importieren.html#windows-1"><i class="fa fa-check"></i><b>5.2</b> Windows</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="daten-importieren.html"><a href="daten-importieren.html#datei-herunterladen"><i class="fa fa-check"></i><b>5.2.1</b> Datei herunterladen</a></li>
<li class="chapter" data-level="5.2.2" data-path="daten-importieren.html"><a href="daten-importieren.html#in-arbeitsordner-verschieben"><i class="fa fa-check"></i><b>5.2.2</b> In Arbeitsordner verschieben</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="daten-importieren.html"><a href="daten-importieren.html#mac-1"><i class="fa fa-check"></i><b>5.3</b> Mac</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="daten-importieren.html"><a href="daten-importieren.html#datei-herunterladen-1"><i class="fa fa-check"></i><b>5.3.1</b> Datei herunterladen</a></li>
<li class="chapter" data-level="5.3.2" data-path="daten-importieren.html"><a href="daten-importieren.html#in-arbeitsordner-verschieben-1"><i class="fa fa-check"></i><b>5.3.2</b> In Arbeitsordner verschieben</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="daten-importieren.html"><a href="daten-importieren.html#weg-1-environment-import-dataset"><i class="fa fa-check"></i><b>5.4</b> <strong>Weg 1: <span class="rstud">Environment</span> &gt; <span class="rstud">Import Dataset</span></strong></a></li>
<li class="chapter" data-level="5.5" data-path="daten-importieren.html"><a href="daten-importieren.html#weg-2-files-import-dataset"><i class="fa fa-check"></i><b>5.5</b> <strong>Weg 2: <span class="rstud">Files</span> &gt; <span class="rstud">Import Dataset</span></strong></a></li>
<li class="chapter" data-level="5.6" data-path="daten-importieren.html"><a href="daten-importieren.html#weg-3-manuell-importieren-mit-funktionen"><i class="fa fa-check"></i><b>5.6</b> <strong>Weg 3: Manuell Importieren mit <code>Funktionen</code></strong></a></li>
<li class="chapter" data-level="5.7" data-path="daten-importieren.html"><a href="daten-importieren.html#faq-1"><i class="fa fa-check"></i><b>5.7</b> FAQ</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="daten-importieren.html"><a href="daten-importieren.html#csv-.txt-und-.dat"><i class="fa fa-check"></i><b>5.7.1</b> .csv, .txt und .dat</a></li>
<li class="chapter" data-level="5.7.2" data-path="daten-importieren.html"><a href="daten-importieren.html#xls-und-.xlsx"><i class="fa fa-check"></i><b>5.7.2</b> .xls und .xlsx</a></li>
<li class="chapter" data-level="5.7.3" data-path="daten-importieren.html"><a href="daten-importieren.html#sav"><i class="fa fa-check"></i><b>5.7.3</b> .sav</a></li>
<li class="chapter" data-level="5.7.4" data-path="daten-importieren.html"><a href="daten-importieren.html#dateien-via-url-direkt-aus-dem-internet-laden"><i class="fa fa-check"></i><b>5.7.4</b> Dateien via URL direkt aus dem Internet laden</a></li>
<li class="chapter" data-level="5.7.5" data-path="daten-importieren.html"><a href="daten-importieren.html#r-.rda-und-.rmd"><i class="fa fa-check"></i><b>5.7.5</b> .R, .Rda und .Rmd</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="daten-importieren.html"><a href="daten-importieren.html#weiterführende-hilfe"><i class="fa fa-check"></i><b>5.8</b> Weiterführende Hilfe</a></li>
<li class="chapter" data-level="5.9" data-path="daten-importieren.html"><a href="daten-importieren.html#übung"><i class="fa fa-check"></i><b>5.9</b> Übung</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="daten-importieren.html"><a href="daten-importieren.html#übung-1-.csv"><i class="fa fa-check"></i><b>5.9.1</b> Übung 1: <strong>.csv</strong></a></li>
<li class="chapter" data-level="5.9.2" data-path="daten-importieren.html"><a href="daten-importieren.html#übung-2-.csv"><i class="fa fa-check"></i><b>5.9.2</b> Übung 2: <strong>.csv</strong></a></li>
<li class="chapter" data-level="5.9.3" data-path="daten-importieren.html"><a href="daten-importieren.html#übung-3-.sav"><i class="fa fa-check"></i><b>5.9.3</b> Übung 3: <strong>.sav</strong></a></li>
<li class="chapter" data-level="5.9.4" data-path="daten-importieren.html"><a href="daten-importieren.html#übung-4-.xlsx"><i class="fa fa-check"></i><b>5.9.4</b> Übung 4: <strong>.xlsx</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html"><i class="fa fa-check"></i><b>6</b> Fehlermeldungen</a>
<ul>
<li class="chapter" data-level="6.1" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#tools-die-uns-helfen-fehler-zu-vermeiden"><i class="fa fa-check"></i><b>6.1</b> Tools die uns helfen, Fehler zu vermeiden</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#r-dokumentation-1"><i class="fa fa-check"></i><b>6.1.1</b> <span class="r">R</span>-Dokumentation</a></li>
<li class="chapter" data-level="6.1.2" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#code-diagnostik"><i class="fa fa-check"></i><b>6.1.2</b> Code Diagnostik</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#fehlermeldungen-verstehen"><i class="fa fa-check"></i><b>6.2</b> Fehlermeldungen verstehen</a></li>
<li class="chapter" data-level="6.3" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#suchen-im-internet"><i class="fa fa-check"></i><b>6.3</b> Suchen im Internet</a></li>
<li class="chapter" data-level="6.4" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#weiterführende-hilfe-1"><i class="fa fa-check"></i><b>6.4</b> Weiterführende Hilfe</a></li>
<li class="chapter" data-level="6.5" data-path="fehlermeldungen.html"><a href="fehlermeldungen.html#automatische-suche-mit-dem-paket-errorist"><i class="fa fa-check"></i><b>6.5</b> Automatische Suche mit dem Paket <strong>errorist</strong></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html"><i class="fa fa-check"></i><b>7</b> Datenvorbereitung</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#grundlegende-erste-schritte"><i class="fa fa-check"></i><b>7.1</b> Grundlegende erste Schritte</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#recap-kodierung-von-daten"><i class="fa fa-check"></i><b>7.1.1</b> <font color="darkgrey"><strong>Recap</strong>: Kodierung von Daten</font></a></li>
<li class="chapter" data-level="7.1.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#dataframe"><i class="fa fa-check"></i><b>7.1.2</b> Dataframe</a></li>
<li class="chapter" data-level="7.1.3" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#plausibilitäts-check"><i class="fa fa-check"></i><b>7.1.3</b> Plausibilitäts-Check</a></li>
<li class="chapter" data-level="7.1.4" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#fehlende-werte"><i class="fa fa-check"></i><b>7.1.4</b> Fehlende Werte</a></li>
<li class="chapter" data-level="7.1.5" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#faktorisieren"><i class="fa fa-check"></i><b>7.1.5</b> Faktorisieren</a></li>
<li class="chapter" data-level="7.1.6" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#wide--und-long-format"><i class="fa fa-check"></i><b>7.1.6</b> Wide- und Long-Format</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#datensätze-zusammenführen"><i class="fa fa-check"></i><b>7.2</b> Datensätze zusammenführen</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#selbe-variablen-unterschiedliche-fälle"><i class="fa fa-check"></i><b>7.2.1</b> Selbe Variablen, unterschiedliche Fälle</a></li>
<li class="chapter" data-level="7.2.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#unterschiedliche-variablen-selbe-fälle"><i class="fa fa-check"></i><b>7.2.2</b> Unterschiedliche Variablen, selbe Fälle</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#daten-extrahieren"><i class="fa fa-check"></i><b>7.3</b> Daten extrahieren</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#variablen"><i class="fa fa-check"></i><b>7.3.1</b> Variablen</a></li>
<li class="chapter" data-level="7.3.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#fälle"><i class="fa fa-check"></i><b>7.3.2</b> Fälle</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#daten-sortieren"><i class="fa fa-check"></i><b>7.4</b> Daten sortieren</a></li>
<li class="chapter" data-level="7.5" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#kodierung-ändern"><i class="fa fa-check"></i><b>7.5</b> Kodierung ändern</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#umkodieren"><i class="fa fa-check"></i><b>7.5.1</b> Umkodieren</a></li>
<li class="chapter" data-level="7.5.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#indikatorvariablen-kodierung-nominaler-merkmale"><i class="fa fa-check"></i><b>7.5.2</b> Indikatorvariablen: Kodierung nominaler Merkmale</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#summary-variablen"><i class="fa fa-check"></i><b>7.6</b> Summary-Variablen</a></li>
<li class="chapter" data-level="7.7" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#weitere-wichtige-hinweise"><i class="fa fa-check"></i><b>7.7</b> Weitere wichtige Hinweise</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#cheat-sheet-dplyr"><i class="fa fa-check"></i><b>7.7.1</b> Cheat Sheet <strong>dplyr</strong></a></li>
<li class="chapter" data-level="7.7.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#stichprobengröße"><i class="fa fa-check"></i><b>7.7.2</b> Stichprobengröße</a></li>
<li class="chapter" data-level="7.7.3" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#replizierbarkeit"><i class="fa fa-check"></i><b>7.7.3</b> Replizierbarkeit</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#übung-1"><i class="fa fa-check"></i><b>7.8</b> Übung</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#übung-1-erste-schritte"><i class="fa fa-check"></i><b>7.8.1</b> Übung 1: Erste Schritte</a></li>
<li class="chapter" data-level="7.8.2" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#übung-2-extrahieren-von-daten"><i class="fa fa-check"></i><b>7.8.2</b> Übung 2: Extrahieren von Daten</a></li>
<li class="chapter" data-level="7.8.3" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#übung-3-sortieren-von-daten"><i class="fa fa-check"></i><b>7.8.3</b> Übung 3: Sortieren von Daten</a></li>
<li class="chapter" data-level="7.8.4" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#übung-4-änderung-der-kodierung-von-daten"><i class="fa fa-check"></i><b>7.8.4</b> Übung 4: Änderung der Kodierung von Daten</a></li>
<li class="chapter" data-level="7.8.5" data-path="datenvorbereitung.html"><a href="datenvorbereitung.html#übung-5-erstellen-von-summary-variablen"><i class="fa fa-check"></i><b>7.8.5</b> Übung 5: Erstellen von Summary-Variablen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html"><i class="fa fa-check"></i><b>8</b> Fehlende Werte</a>
<ul>
<li class="chapter" data-level="8.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#sind-die-missings-einheitlich-kodiert"><i class="fa fa-check"></i><b>8.1</b> Sind die Missings einheitlich kodiert?</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#wie-kann-ich-prüfen-ob-die-missings-einheitlich-kodiert-sind"><i class="fa fa-check"></i><b>8.1.1</b> Wie kann ich prüfen, ob die Missings einheitlich kodiert sind?</a></li>
<li class="chapter" data-level="8.1.2" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#wie-kann-ich-die-missings-auf-na-setzen"><i class="fa fa-check"></i><b>8.1.2</b> Wie kann ich die Missings auf <code>NA</code> setzen?</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#enthält-ein-datensatz-missings"><i class="fa fa-check"></i><b>8.2</b> 2. Enthält ein Datensatz Missings?</a></li>
<li class="chapter" data-level="8.3" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#wie-kann-man-die-missings-zählen-und-verorten"><i class="fa fa-check"></i><b>8.3</b> 3. Wie kann man die Missings zählen (und verorten)?</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#alle-missings-eines-datensatzes"><i class="fa fa-check"></i><b>8.3.1</b> Alle Missings eines Datensatzes</a></li>
<li class="chapter" data-level="8.3.2" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#missings-in-einzelnen-spalten-oder-zeilen"><i class="fa fa-check"></i><b>8.3.2</b> Missings in <em>einzelnen</em> Spalten oder Zeilen</a></li>
<li class="chapter" data-level="8.3.3" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#missings-in-allen-spalten-oder-zeilen"><i class="fa fa-check"></i><b>8.3.3</b> Missings in <em>allen</em> Spalten oder Zeilen</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#sind-die-missings-zufällig"><i class="fa fa-check"></i><b>8.4</b> Sind die Missings zufällig?</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#arten-von-missings"><i class="fa fa-check"></i><b>8.4.1</b> Arten von Missings</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#wie-kann-man-mit-missings-umgehen"><i class="fa fa-check"></i><b>8.5</b> Wie kann man mit Missings umgehen?</a></li>
<li class="chapter" data-level="8.6" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#neuen-datensatz-erstellen-der-keine-missings-enthält"><i class="fa fa-check"></i><b>8.6</b> Neuen Datensatz erstellen, der keine Missings enthält</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#festlegen-wie-funktionen-mit-missings-umgehen-sollen"><i class="fa fa-check"></i><b>8.6.1</b> Festlegen, wie Funktionen mit Missings umgehen sollen</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#literaturempfehlungen"><i class="fa fa-check"></i><b>8.7</b> Literaturempfehlungen</a></li>
<li class="chapter" data-level="8.8" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#faq-2"><i class="fa fa-check"></i><b>8.8</b> FAQ</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#erkennt-r-deine-missings"><i class="fa fa-check"></i><b>8.8.1</b> Erkennt <span class="r">R</span> deine Missings?</a></li>
<li class="chapter" data-level="8.8.2" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#wie-können-funktionen-mit-missings-umgehen"><i class="fa fa-check"></i><b>8.8.2</b> Wie können Funktionen mit Missings umgehen?</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#übung-2"><i class="fa fa-check"></i><b>8.9</b> Übung</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#übung-1-korrekte-kodierung"><i class="fa fa-check"></i><b>8.9.1</b> Übung 1: (Korrekte) Kodierung</a></li>
<li class="chapter" data-level="8.9.2" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#übung-2-verortung"><i class="fa fa-check"></i><b>8.9.2</b> Übung 2: Verortung</a></li>
<li class="chapter" data-level="8.9.3" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#übung-3-zufälligkeit"><i class="fa fa-check"></i><b>8.9.3</b> Übung 3: Zufälligkeit</a></li>
<li class="chapter" data-level="8.9.4" data-path="fehlende-werte-1.html"><a href="fehlende-werte-1.html#übung-4-umgang"><i class="fa fa-check"></i><b>8.9.4</b> Übung 4: Umgang</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="wide--long-format.html"><a href="wide--long-format.html"><i class="fa fa-check"></i><b>9</b> Wide- &amp; Long-Format</a>
<ul>
<li class="chapter" data-level="9.1" data-path="wide--long-format.html"><a href="wide--long-format.html#vom-long--ins-wide-format"><i class="fa fa-check"></i><b>9.1</b> Vom Long- ins Wide-Format</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="wide--long-format.html"><a href="wide--long-format.html#stats-reshape"><i class="fa fa-check"></i><b>9.1.1</b> stats: <code>reshape()</code></a></li>
<li class="chapter" data-level="9.1.2" data-path="wide--long-format.html"><a href="wide--long-format.html#tidyr-spread"><i class="fa fa-check"></i><b>9.1.2</b> tidyr: <code>spread()</code></a></li>
<li class="chapter" data-level="9.1.3" data-path="wide--long-format.html"><a href="wide--long-format.html#unterschied-zwischen-reshape-und-spread"><i class="fa fa-check"></i><b>9.1.3</b> Unterschied zwischen <code>reshape()</code> und <code>spread()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="wide--long-format.html"><a href="wide--long-format.html#vom-wide--ins-long-format"><i class="fa fa-check"></i><b>9.2</b> Vom Wide- ins Long-Format</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="wide--long-format.html"><a href="wide--long-format.html#stats-reshape-1"><i class="fa fa-check"></i><b>9.2.1</b> stats: <code>reshape()</code></a></li>
<li class="chapter" data-level="9.2.2" data-path="wide--long-format.html"><a href="wide--long-format.html#tidyr-gather"><i class="fa fa-check"></i><b>9.2.2</b> tidyr: <code>gather()</code></a></li>
<li class="chapter" data-level="9.2.3" data-path="wide--long-format.html"><a href="wide--long-format.html#unterschied-zwischen-reshape-und-gather"><i class="fa fa-check"></i><b>9.2.3</b> Unterschied zwischen <code>reshape()</code> und <code>gather()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="wide--long-format.html"><a href="wide--long-format.html#andere-funktionen-zum-umformatieren"><i class="fa fa-check"></i><b>9.3</b> Andere Funktionen zum Umformatieren</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html"><i class="fa fa-check"></i><b>10</b> Annahmen der Multiplen Linearen Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#linearität"><i class="fa fa-check"></i><b>10.1</b> Linearität</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#überprüfung"><i class="fa fa-check"></i><b>10.1.1</b> Überprüfung</a></li>
<li class="chapter" data-level="10.1.2" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#umgang"><i class="fa fa-check"></i><b>10.1.2</b> Umgang</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#exogenität-der-prädiktoren"><i class="fa fa-check"></i><b>10.2</b> Exogenität der Prädiktoren</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-1"><i class="fa fa-check"></i><b>10.2.1</b> Überprüfung</a></li>
<li class="chapter" data-level="10.2.2" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#umgang-1"><i class="fa fa-check"></i><b>10.2.2</b> Umgang</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#homoskedastizität"><i class="fa fa-check"></i><b>10.3</b> Homoskedastizität</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-2"><i class="fa fa-check"></i><b>10.3.1</b> Überprüfung</a></li>
<li class="chapter" data-level="10.3.2" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#umgang-2"><i class="fa fa-check"></i><b>10.3.2</b> Umgang</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#unabhängigkeit-der-residuen"><i class="fa fa-check"></i><b>10.4</b> Unabhängigkeit der Residuen</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-3"><i class="fa fa-check"></i><b>10.4.1</b> Überprüfung</a></li>
<li class="chapter" data-level="10.4.2" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#umgang-3"><i class="fa fa-check"></i><b>10.4.2</b> Umgang</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#weitere-wichtige-aspekte"><i class="fa fa-check"></i><b>10.5</b> Weitere wichtige Aspekte</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#normalverteilung-der-residuen"><i class="fa fa-check"></i><b>10.5.1</b> Normalverteilung der Residuen</a></li>
<li class="chapter" data-level="10.5.2" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#multikollinearität"><i class="fa fa-check"></i><b>10.5.2</b> Multikollinearität</a></li>
<li class="chapter" data-level="10.5.3" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#extreme-werte-und-einflussreiche-datenpunkte"><i class="fa fa-check"></i><b>10.5.3</b> Extreme Werte und einflussreiche Datenpunkte</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="annahmen-der-multiplen-linearen-regression.html"><a href="annahmen-der-multiplen-linearen-regression.html#literatur-weiterführende-hilfe"><i class="fa fa-check"></i><b>10.6</b> Literatur &amp; weiterführende Hilfe</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="grafiken.html"><a href="grafiken.html"><i class="fa fa-check"></i><b>11</b> Grafiken</a>
<ul>
<li class="chapter" data-level="11.1" data-path="grafiken.html"><a href="grafiken.html#bevor-es-losgeht"><i class="fa fa-check"></i><b>11.1</b> Bevor es losgeht</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="grafiken.html"><a href="grafiken.html#richtiges-datenformat"><i class="fa fa-check"></i><b>11.1.1</b> Richtiges Datenformat</a></li>
<li class="chapter" data-level="11.1.2" data-path="grafiken.html"><a href="grafiken.html#welche-grafik-sollte-ich-für-meine-daten-nehmen"><i class="fa fa-check"></i><b>11.1.2</b> Welche Grafik sollte ich für meine Daten nehmen?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="grafiken.html"><a href="grafiken.html#grundlegender-aufbau-von-ggplot"><i class="fa fa-check"></i><b>11.2</b> Grundlegender Aufbau von ggplot()</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="grafiken.html"><a href="grafiken.html#ebene-grundlegendes-koordinatensystem"><i class="fa fa-check"></i><b>11.2.1</b> 1. Ebene: Grundlegendes Koordinatensystem</a></li>
<li class="chapter" data-level="11.2.2" data-path="grafiken.html"><a href="grafiken.html#ebene-art-der-grafik"><i class="fa fa-check"></i><b>11.2.2</b> Ebene: Art der Grafik</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="grafiken.html"><a href="grafiken.html#eine-variable"><i class="fa fa-check"></i><b>11.3</b> Eine Variable</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="grafiken.html"><a href="grafiken.html#kategorial"><i class="fa fa-check"></i><b>11.3.1</b> Kategorial</a></li>
<li class="chapter" data-level="11.3.2" data-path="grafiken.html"><a href="grafiken.html#metrisch"><i class="fa fa-check"></i><b>11.3.2</b> Metrisch</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="grafiken.html"><a href="grafiken.html#zwei-variablen"><i class="fa fa-check"></i><b>11.4</b> Zwei Variablen</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="grafiken.html"><a href="grafiken.html#x-kategorial-y-metrisch"><i class="fa fa-check"></i><b>11.4.1</b> X kategorial, Y metrisch</a></li>
<li class="chapter" data-level="11.4.2" data-path="grafiken.html"><a href="grafiken.html#x-und-y-metrisch"><i class="fa fa-check"></i><b>11.4.2</b> X und Y metrisch</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="grafiken.html"><a href="grafiken.html#mehr-als-zwei-variablen"><i class="fa fa-check"></i><b>11.5</b> Mehr als zwei Variablen</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="grafiken.html"><a href="grafiken.html#mindestens-eine-kategoriale-variable"><i class="fa fa-check"></i><b>11.5.1</b> Mindestens eine kategoriale Variable</a></li>
<li class="chapter" data-level="11.5.2" data-path="grafiken.html"><a href="grafiken.html#nur-kategoriale-variablen"><i class="fa fa-check"></i><b>11.5.2</b> Nur kategoriale Variablen</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="grafiken.html"><a href="grafiken.html#modifikationen"><i class="fa fa-check"></i><b>11.6</b> Modifikationen</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="grafiken.html"><a href="grafiken.html#farbe"><i class="fa fa-check"></i><b>11.6.1</b> <strong><font color="#e41a1c">F</font><font color="#377eb8">a</font><font color="#4daf4a">r</font><font color="#984ea3">b</font><font color="#ff7f00">e</font></strong></a></li>
<li class="chapter" data-level="11.6.2" data-path="grafiken.html"><a href="grafiken.html#legenden-modifizieren"><i class="fa fa-check"></i><b>11.6.2</b> <span style="border:1px; border-style:solid; border-color:black; padding: 3px;">Legenden modifizieren</span></a></li>
<li class="chapter" data-level="11.6.3" data-path="grafiken.html"><a href="grafiken.html#beschriftung"><i class="fa fa-check"></i><b>11.6.3</b> <strong><span style="font-family: Courier New,Courier,monospace;">Beschriftung</span></strong></a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="grafiken.html"><a href="grafiken.html#kategoriale-variablen-benennung-und-reihenfolge-der-ausprägungen"><i class="fa fa-check"></i><b>11.7</b> Kategoriale Variablen: Benennung und Reihenfolge der Ausprägungen</a></li>
<li class="chapter" data-level="11.8" data-path="grafiken.html"><a href="grafiken.html#grafiken-einzelner-gruppen-und-die-anpassung-von-achsengrenzen"><i class="fa fa-check"></i><b>11.8</b> Grafiken einzelner Gruppen und die Anpassung von Achsengrenzen</a></li>
<li class="chapter" data-level="11.9" data-path="grafiken.html"><a href="grafiken.html#geraden-einzeichnen"><i class="fa fa-check"></i><b>11.9</b> Geraden einzeichnen</a></li>
<li class="chapter" data-level="11.10" data-path="grafiken.html"><a href="grafiken.html#weitere-statistische-kennwerte-ergänzen"><i class="fa fa-check"></i><b>11.10</b> Weitere statistische Kennwerte ergänzen</a></li>
<li class="chapter" data-level="11.11" data-path="grafiken.html"><a href="grafiken.html#motive-themes"><i class="fa fa-check"></i><b>11.11</b> Motive (Themes)</a></li>
<li class="chapter" data-level="11.12" data-path="grafiken.html"><a href="grafiken.html#grafiken-exportieren"><i class="fa fa-check"></i><b>11.12</b> Grafiken exportieren</a>
<ul>
<li class="chapter" data-level="11.12.1" data-path="grafiken.html"><a href="grafiken.html#export-button"><i class="fa fa-check"></i><b>11.12.1</b> <span style="color: #75AADC"><strong>Export-Button</strong></span></a></li>
<li class="chapter" data-level="11.12.2" data-path="grafiken.html"><a href="grafiken.html#ggsave"><i class="fa fa-check"></i><b>11.12.2</b> <code>ggsave()</code></a></li>
</ul></li>
<li class="chapter" data-level="11.13" data-path="grafiken.html"><a href="grafiken.html#weiterführende-hilfen"><i class="fa fa-check"></i><b>11.13</b> Weiterführende Hilfen</a>
<ul>
<li class="chapter" data-level="11.13.1" data-path="grafiken.html"><a href="grafiken.html#eine-einfache-ggplot-funktion-qplot"><i class="fa fa-check"></i><b>11.13.1</b> Eine einfache ggplot-Funktion: <code>qplot()</code></a></li>
<li class="chapter" data-level="11.13.2" data-path="grafiken.html"><a href="grafiken.html#mehrere-plots-zusammenführen"><i class="fa fa-check"></i><b>11.13.2</b> Mehrere Plots zusammenführen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="r-markdown.html"><a href="r-markdown.html"><i class="fa fa-check"></i><b>12</b> R Markdown</a>
<ul>
<li class="chapter" data-level="12.1" data-path="r-markdown.html"><a href="r-markdown.html#neues-r-markdown-dokument-anlegen"><i class="fa fa-check"></i><b>12.1</b> Neues <span class="r">R Markdown</span> Dokument anlegen</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="r-markdown.html"><a href="r-markdown.html#yaml"><i class="fa fa-check"></i><b>12.1.1</b> YAML</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="r-markdown.html"><a href="r-markdown.html#text"><i class="fa fa-check"></i><b>12.2</b> Text</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="r-markdown.html"><a href="r-markdown.html#überschriften"><i class="fa fa-check"></i><b>12.2.1</b> Überschriften</a></li>
<li class="chapter" data-level="12.2.2" data-path="r-markdown.html"><a href="r-markdown.html#hervorhebung"><i class="fa fa-check"></i><b>12.2.2</b> Hervorhebung</a></li>
<li class="chapter" data-level="12.2.3" data-path="r-markdown.html"><a href="r-markdown.html#zeilenumbruch"><i class="fa fa-check"></i><b>12.2.3</b> Zeilenumbruch</a></li>
<li class="chapter" data-level="12.2.4" data-path="r-markdown.html"><a href="r-markdown.html#verlinkung"><i class="fa fa-check"></i><b>12.2.4</b> Verlinkung</a></li>
<li class="chapter" data-level="12.2.5" data-path="r-markdown.html"><a href="r-markdown.html#formeln"><i class="fa fa-check"></i><b>12.2.5</b> Formeln</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="r-markdown.html"><a href="r-markdown.html#r-code"><i class="fa fa-check"></i><b>12.3</b> <span class="r">R</span>-Code</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="r-markdown.html"><a href="r-markdown.html#code-chunk"><i class="fa fa-check"></i><b>12.3.1</b> Code Chunk</a></li>
<li class="chapter" data-level="12.3.2" data-path="r-markdown.html"><a href="r-markdown.html#inline-code"><i class="fa fa-check"></i><b>12.3.2</b> Inline Code</a></li>
<li class="chapter" data-level="12.3.3" data-path="r-markdown.html"><a href="r-markdown.html#grafiken-bilder-und-tabellen"><i class="fa fa-check"></i><b>12.3.3</b> Grafiken, Bilder und Tabellen</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="r-markdown.html"><a href="r-markdown.html#weiterführend"><i class="fa fa-check"></i><b>12.4</b> Weiterführend</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="r-markdown.html"><a href="r-markdown.html#templates"><i class="fa fa-check"></i><b>12.4.1</b> Templates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="outputs---alm---faq.html"><a href="outputs---alm---faq.html"><i class="fa fa-check"></i><b>13</b> Outputs - ALM - FAQ</a>
<ul>
<li class="chapter" data-level="13.1" data-path="outputs---alm---faq.html"><a href="outputs---alm---faq.html#github-link"><i class="fa fa-check"></i><b>13.1</b> <span class="math inline">\(t\)</span>-Test</a></li>
<li class="chapter" data-level="13.2" data-path="outputs---alm---faq.html"><a href="outputs---alm---faq.html#lineare-regression"><i class="fa fa-check"></i><b>13.2</b> Lineare Regression</a></li>
<li class="chapter" data-level="13.3" data-path="outputs---alm---faq.html"><a href="outputs---alm---faq.html#anova"><i class="fa fa-check"></i><b>13.3</b> ANOVA</a></li>
<li class="chapter" data-level="13.4" data-path="outputs---alm---faq.html"><a href="outputs---alm---faq.html#github2"><i class="fa fa-check"></i><b>13.4</b> ALM: Zusammenhänge der drei Verfahren</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html"><i class="fa fa-check"></i><b>14</b> Git und GitLab</a>
<ul>
<li class="chapter" data-level="14.1" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git"><i class="fa fa-check"></i><b>14.1</b> Git</a></li>
<li class="chapter" data-level="14.2" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#einführung-in-git"><i class="fa fa-check"></i><b>14.2</b> Einführung in Git</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#schritt-0"><i class="fa fa-check"></i><b>14.2.1</b> Schritt 0</a></li>
<li class="chapter" data-level="14.2.2" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git-init"><i class="fa fa-check"></i><b>14.2.2</b> git init</a></li>
<li class="chapter" data-level="14.2.3" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git-add"><i class="fa fa-check"></i><b>14.2.3</b> git add</a></li>
<li class="chapter" data-level="14.2.4" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git-status"><i class="fa fa-check"></i><b>14.2.4</b> git status</a></li>
<li class="chapter" data-level="14.2.5" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git-commit"><i class="fa fa-check"></i><b>14.2.5</b> git commit</a></li>
<li class="chapter" data-level="14.2.6" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git-log"><i class="fa fa-check"></i><b>14.2.6</b> git log</a></li>
<li class="chapter" data-level="14.2.7" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#zu-einem-früheren-zustand-zurückkehren"><i class="fa fa-check"></i><b>14.2.7</b> Zu einem früheren Zustand zurückkehren</a></li>
<li class="chapter" data-level="14.2.8" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#branches"><i class="fa fa-check"></i><b>14.2.8</b> Branches</a></li>
<li class="chapter" data-level="14.2.9" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#mergen"><i class="fa fa-check"></i><b>14.2.9</b> Mergen</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#github-gitlab-gitbucket"><i class="fa fa-check"></i><b>14.3</b> GitHub, GitLab, GitBucket, …</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#ein-neues-projekt-erstellen"><i class="fa fa-check"></i><b>14.3.1</b> Ein neues Projekt erstellen</a></li>
<li class="chapter" data-level="14.3.2" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#git-clone"><i class="fa fa-check"></i><b>14.3.2</b> git clone</a></li>
<li class="chapter" data-level="14.3.3" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#push"><i class="fa fa-check"></i><b>14.3.3</b> git push</a></li>
<li class="chapter" data-level="14.3.4" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#pull"><i class="fa fa-check"></i><b>14.3.4</b> git pull</a></li>
<li class="chapter" data-level="14.3.5" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#branches-archivieren-und-löschen"><i class="fa fa-check"></i><b>14.3.5</b> Branches archivieren und löschen</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="git-und-gitlab.html"><a href="git-und-gitlab.html#weitere-ressourcen"><i class="fa fa-check"></i><b>14.4</b> Weitere Ressourcen</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R Lernplattform</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="annahmen-der-multiplen-linearen-regression" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Chapter 10</span> Annahmen der Multiplen Linearen Regression<a href="annahmen-der-multiplen-linearen-regression.html#annahmen-der-multiplen-linearen-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p style="font-weight:600; font-size:36px">
Einleitung
</p>
<p>Wenn wir uns den gerichteten Zusammenhang von mehr als zwei Variablen anschauen möchten, können wir dafür die multiple lineare Regression nutzen. Bei dieser können wir <em>eine</em> abhängige Variable <font size="2">(AV, nachfolgend <em>Kriterium</em> genannt)</font> durch <em>mehrere (multiple)</em> unabhängige Variablen <font size="2">(UVs, nachfolgend <em>Prädiktoren</em> genannt)</font> vorhersagen. Grundsätzlich gilt, dass das Kriterium metrisch sein muss <font size="2">(d.h. mindestens intervallskaliert)</font>. Die Prädiktoren hingegen können auch kategorial <font size="2">(d.h. dichotom, nominal- oder ordinalskaliert)</font> sein, sofern diese korrekt kodiert werden <font size="2">(z.B. als Dummyvariablen)</font>.</p>
<aside>
<br />
Wie wir u.a. Dummykodierungen erstellen können erfahren wir im Abschnitt <a href="http://methods-berlin.com/wp-content/uploads/Datenvorbereitung.html#indikatorvariablen-kodierung-nominaler-merkmale" target="_blank"><strong>Indikatorvariablen: Kodierung nominaler Merkmale</strong></a> im Kapitel Datenvorbereitung.
</aside>
<details>
<summary class="mtitle q">
Wie sieht die Regressionsgleichung aus?
</summary>
<div class="more">
<p>Nach dem linearen Modell gilt (für Person <span class="math inline">\(i=1, ..., n\)</span> und Prädiktor <span class="math inline">\(k=1, ..., K\)</span>):<br />
</p>
<p><strong><span class="math display">\[y_i = b_0 + b_1x_1 + ... + b_Kx_K + e_i\]</span></strong></p>
<p><strong><span class="math inline">\(y\)</span></strong>: Kriterium<br />
<strong><span class="math inline">\(b_0\)</span></strong>: y-Achsenabschnitt (Intercept)<br />
<strong><span class="math inline">\(b_1, ..., b_K\)</span></strong>: Steigungen (Slopes); hier unstandardisiert<br />
<strong><span class="math inline">\(e_i\)</span></strong>: Residuum (Vorhersagefehler); gibt den Teil von y an, der nicht durch die Regressionsgleichung vorhergesagt werden kann</p>
</div>
</details>
<p style="line-height:10px;">
</p>
<p>Bei der Anwendung der multiplen linearen Regression müssen allerdings bestimmte Annahmen erfüllt sein. Wenn diese verletzt sind, besteht die Gefahr, dass die Parameterschätzungen inkorrekt <font size="2">(verzerrt)</font> sind und/oder wir inkorrekte Schlussfolgerungen über das Vorhandensein von Effekten in der Population ziehen <font size="2">(z.B. wir aufgrund von verzerrten Standardfehlern fälschlicherweise ein signifikantes Ergebnis erhalten)</font>.</p>
<p>Die wichtigsten Annahmen sind: Linearität, Exogenität, Homoskedastizität und die Unabhängigkeit der Residuen. Darüber hinaus sollten wir uns auch immer die Normalverteilung der Residuen, Multikollinearität sowie Ausreißer und einflussreiche Datenpunkte ansehen.</p>
<div style="text-align: center">
<font size="2"><strong>Gefahren bei Verletzung der Annahmen und weiterer wichtiger Punkte</strong></font>
</div>
<table>
<thead>
<tr>
<th style="text-align:left;font-weight: bold;color: white !important;background-color: #009193 !important;">
</th>
<th style="text-align:left;font-weight: bold;color: white !important;background-color: #009193 !important;">
verzerrte Koeffizienten
</th>
<th style="text-align:left;font-weight: bold;color: white !important;background-color: #009193 !important;">
verzerrte Standardfehler
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
<strong>Linearität</strong>
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
<strong>Exogenität</strong>
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
<strong>Homoskedastizität</strong>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
<strong>Unabhängigkeit der Residuen</strong>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
Normalverteilung der Residuen
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
Multikollinearität
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;color: white !important;background-color: #009193 !important;">
Einflussreiche Datenpunkte
</td>
<td style="text-align:left;">
X
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p>Bei der Prüfung von Annahmen in der multiplen linearen Regression ist die <strong>Residualdiagnostik</strong> ein wichtiges Verfahren. Residuen <span class="math inline">\(\hat e_i\)</span> sind Abweichungen der vorhergesagten Werte des Kriteriums <span class="math inline">\(\hat y_i\)</span> von den beobachteten Werten des Kriteriums <span class="math inline">\(y_i\)</span> von Person <span class="math inline">\(i\)</span>. Man schaut sich anstatt der geplotteten Rohdaten häufig die Residualplots an, weil man Plots mit mehr als zwei Achsen (bei mehr als einem Prädiktor) grafisch nicht gut darstellen kann. Zusätzlich visualisieren Residuen die Abweichungen besser und lassen uns so u.a. nicht-lineare Zusammenhänge besser aufdecken.</p>
<p>Die verschiedenen Annahmen werden im Verlauf der folgenden Abschnitte kurz erläutert und Möglichkeiten der Überprüfung <font size="2">(v.a. mit Hilfe von Grafiken)</font>, sowie zum Umgang mit Verletzung der Annahmen kurz skizziert.</p>
<details>
<summary class="mtitle q">
Warum werden bevorzugt Grafiken genutzt, um die Annahmen zu prüfen?</span>
</summary>
<div class="more">
<p>In geplotteten Daten können verschiedenste Verletzungen (z.B. Missspezifikationen der Form des Zusammenhangs zwischen den Variablen) entdeckt werden, denn graphische Darstellungen machen nur geringe Annahmen über die Art des Problems. Statistische Tests hingegen haben häufig einen eingeschränkten Fokus und sie vergleichen nur, was wir vorgegeben haben. Zusätzlich funktionieren sie nur unter bestimmten Annahmen, liefern lediglich eine 0/1-Aussage ohne die Schwere des Annahmeverstoßes zu quantifizieren und hängen stark von der Stichprobengröße ab.</p>
</div>
</details>
<p style="line-height:10px;">
</p>
<details>
<summary class="mtitle q">
Was ist die <a name="loess">Lowess Fit Line</a>?</span>
</summary>
<div class="more">
<p>Wenn wir Ergebnisse einer linearen Regression mit <code>plot()</code> darstellen, wird häufig die sogenannte <font color="red"><strong>Lowess Fit Line</strong></font> eingezeichnet.</p>
<p>Lowess steht für <strong>lo</strong>cally <strong>we</strong>ighted <strong>s</strong>catterplot <strong>s</strong>moother. Die Lowess (oder auch Loess) Fit Line ist ein Verfahren, welches den besten nonparametrischen Fit für die gegeben Daten anzeigt. Sie ist eine Auswertungshilfe bei der Beurteilung der Form des Zusammenhangs. Dabei macht sie keine Annahmen über die Form des Zusammenhangs zwischen den Variablen. Der Zusammenhang zwischen zwei Variablen wird im Streudiagramm als “smoothe” Linie, die den generellen Trend der Daten beschreibt, dargestellt. Wenn der Zusammenhang zwischen zwei Variablen in der Population linear ist, so sollte sich auch die Lowess Line einer Gerade annähern. Allerdings ist die Lowess Line häufig an den Enden der Verteilung von X weniger präzise, da hier weniger Daten vorhanden sind.</p>
</div>
</details>
<p style="line-height:10px;">
</p>
<details class="bsp">
<summary>
Beispieldatensatz für dieses Kapitel
</summary>
<p>Hier sehen wir, wie wir den Datensatz <code>erstis</code>, an dem wir in diesem Kapitel arbeiten werden, einlesen können.</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb730-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="fu">url</span>(<span class="st">&quot;http://www.beltz.de/fileadmin/beltz/downloads/</span></span>
<span id="cb730-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb730-2" aria-hidden="true" tabindex="-1"></a><span class="st">         OnlinematerialienPVU/R_fuer_Einsteiger/erstis.rda&quot;</span>))</span>
<span id="cb730-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb730-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Zeilenumbruch zwischen der ersten und zweiten Zeile noch entfernen!</span></span></code></pre></div>
<p>Die enthaltenen Daten sind aus einer Erhebung mit Erstsemesterstudierenden der Psychologie. Unter diesem <a href="https://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/R_fuer_Einsteiger/Datensatz%20Erstis_Codebook.pdf" target="_blank">Link</a> finden wir das Codebuch zum Datensatz.</p>
<p>Exemplarisch schauen wir uns für dieses Kapitel an, wie gut sich <strong>lz.1</strong> (Lebenszufriedenheit T1) durch <strong>zuf.inh.1</strong> (Zufriedenheit mit Studieninhalten T1) und <strong>zuf.bed.1</strong> (Zufriedenheit mit Studienbedingungen T1) vorhersagen lässt.<br />
</p>
<p>Dazu erstellen wir erst einen neuen Datensatz mit diesen Variablen und führen dann die Regression durch.</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Daten aus erstis in neuem Dataframe speichern ...</span></span>
<span id="cb731-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-2" aria-hidden="true" tabindex="-1"></a>daten <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(erstis<span class="sc">$</span>lz<span class="fl">.1</span>, erstis<span class="sc">$</span>zuf.inh<span class="fl">.1</span>, erstis<span class="sc">$</span>zuf.bed<span class="fl">.1</span>)</span>
<span id="cb731-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ... und Spalten umbenennen</span></span>
<span id="cb731-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(daten) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;leb_zufr&quot;</span>, <span class="st">&quot;zufr_inhalt&quot;</span>, <span class="st">&quot;zufr_beding&quot;</span>)</span>
<span id="cb731-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb731-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Regression durchführen</span></span>
<span id="cb731-7"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-7" aria-hidden="true" tabindex="-1"></a>lm_lz <span class="ot">&lt;-</span> <span class="fu">lm</span>(daten<span class="sc">$</span>leb_zufr <span class="sc">~</span> daten<span class="sc">$</span>zufr_inhalt <span class="sc">+</span> daten<span class="sc">$</span>zufr_beding, </span>
<span id="cb731-8"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">na.action =</span> <span class="st">&quot;na.exclude&quot;</span>)</span>
<span id="cb731-9"><a href="annahmen-der-multiplen-linearen-regression.html#cb731-9" aria-hidden="true" tabindex="-1"></a><span class="co"># mit &quot;na.exclude&quot; schließen wir fehlende Werte aus</span></span></code></pre></div>
<p>Für mehr Informationen dazu, wie <code>lm()</code> und andere Funktionen mit Missings umgehen, können wir uns das Kapitel <a href="http://methods-berlin.com/de/r-lernplattform/fehlende-werte" target="_blank"><strong>Fehlende Werte</strong></a> anschauen.</p>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Die Residuen brauchen wir später, daher fügen wir sie jetzt ... </span></span>
<span id="cb732-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ... schon als Variable zum Datensatz hinzu.</span></span>
<span id="cb732-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-3" aria-hidden="true" tabindex="-1"></a>daten<span class="sc">$</span>resid <span class="ot">&lt;-</span> <span class="fu">residuals</span>(lm_lz) </span>
<span id="cb732-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-4" aria-hidden="true" tabindex="-1"></a><span class="co"># wichtig: residuals() oder resid() nehmen</span></span>
<span id="cb732-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-5" aria-hidden="true" tabindex="-1"></a><span class="co"># lm_lz$residuals funktioniert hier nicht, </span></span>
<span id="cb732-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ... weil die Zeilenanzahl geringerer ist ...</span></span>
<span id="cb732-7"><a href="annahmen-der-multiplen-linearen-regression.html#cb732-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ... weil Zeilen mit Missings gelöscht werden</span></span></code></pre></div>
<p>Im Rahmen dieses Kapitels liegt der Fokus nicht auf der inhaltlichen Interpretation der Ergebnisse der multiplen linearen Regressions, sondern darauf, <strong>ob die oben genannten Annahmen erfüllt sind</strong>.</p>
<p>Nachfolgend sehen wir den Output der <code>lm()</code>-Funktion (<span class="code"><span class="ex">lm_lz</span></span>).</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb733-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_lz)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = daten$leb_zufr ~ daten$zufr_inhalt + daten$zufr_beding, 
##     na.action = &quot;na.exclude&quot;)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.2274  -3.7319   0.8666   3.8354   8.5019 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        12.7910     2.3392   5.468  1.7e-07 ***
## daten$zufr_inhalt   2.4993     0.6870   3.638 0.000369 ***
## daten$zufr_beding   1.3128     0.5743   2.286 0.023572 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.137 on 161 degrees of freedom
##   (27 observations deleted due to missingness)
## Multiple R-squared:  0.141,  Adjusted R-squared:  0.1303 
## F-statistic: 13.21 on 2 and 161 DF,  p-value: 4.87e-06</code></pre>
Wenn die Annahmen für die multiple lineare Regression in unserem Beispiel nicht erfüllt sind, besteht die Gefahr, dass unsere Parameterschätzungen (<code>Estimate</code>-Spalte) und/oder Standardfehler (<code>Std.Error</code>-Spalte) inkorrekt sind. Damit wären unsere Ergebnisse u.U. untauglich.
</details>
<p style="line-height:10px;">
</p>
<blockquote>
<p><em><strong>Achtung</strong></em>: Um eine (multiple) lineare Regression durchführen zu können, müssen unsere Daten ggf. in einem für unsere Analyse <strong>geeigneten (Tabellen-)Format</strong> vorliegen. Es gibt das <strong>Long-</strong> und das <strong>Wide-Format</strong>. Wie wir beide ineinander überführen können erfahren wir im gleichnamigen <a href="http://methods-berlin.com/r-lernplattform/wide-und-long-format" target="_blank"><strong>Kapitel</strong></a>.</p>
</blockquote>
<div id="linearität" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Linearität<a href="annahmen-der-multiplen-linearen-regression.html#linearität" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p>Mit Linearität ist die <strong>korrekte Spezifikation der Form des Zusammenhangs zwischen Kriterium und Prädiktoren</strong> gemeint. Genauer gesagt, meint die Annahme, dass der <strong>Erwartungswert des Kriteriums</strong> sich als <strong>Linearkombination der Prädiktoren</strong> darstellen lässt.</p>
</blockquote>
<blockquote>
<p><em><strong>Achtung</strong></em>: Dies bedeutet jedoch <strong>nicht</strong> notwendigerweise, dass der Zusammenhang der Variablen linear sein muss.</p>
</blockquote>
<p>Es muss sich lediglich um eine linear additive Verknüpfung der Regressionsterme handeln. Beispielsweise spezifiziert die folgende Regressionsgleichung <span class="math inline">\(y=b_0 + b_1x^2 + e\)</span> einen quadratischen Zusammenhang zwischen <span class="math inline">\(Y\)</span> und <span class="math inline">\(X\)</span> mittels einer linear additiven Verknüpfung der Regressionsterme <font size="2">(hier nur ein einziger Prädiktor <span class="math inline">\(X\)</span>)</font>. Siehe auch den Abschnitt zum Umgang mit Nicht-Linearität.</p>
<p>Wenn die Form des Zusammenhangs zwischen Kriterium und Prädiktoren nicht richtig spezifiziert wurde, können ernsthafte Probleme auftreten. Dies wäre zum Beispiel dann der Fall, wenn es zwischen Prädiktoren und Kriterium in Wirklichkeit einen quadratischen Zusammenhang gibt, wir in unserem Regressionsmodell aber nur einen linearen Zusammenhang spezifiziert haben. Sowohl die <strong>Regressionskoeffizienten</strong> als auch die <strong>Standardfehler</strong> könnten in einem solchen Fall verzerrt sein.</p>
<div id="überprüfung" class="section level3 hasAnchor" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="bivariate-streudiagramme" class="section level4 hasAnchor" number="10.1.1.1">
<h4><span class="header-section-number">10.1.1.1</span> Bivariate Streudiagramme<a href="annahmen-der-multiplen-linearen-regression.html#bivariate-streudiagramme" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In einem ersten Schritt schauen wir uns bivariate Streudiagramme an. Das heißt, wir schauen uns nicht das gesamte Modelle (mit mehreren Prädiktoren) an, sondern nur Zusammenhänge zwischen <em>einzelnen</em> Prädiktoren und dem Kriterium.</p>
<blockquote>
<p><em><strong>Achtung</strong></em>: Auch wenn die bivariaten Streudiagramme auf Linearität hinweisen, sollten wir nicht vergessen, dass auch Interkationen zwischen Prädiktoren zu nicht-linearen Zusammenhängen führen können. Die Nutzung von bivariaten Streudiagramen zur Überprüfung der Annahme der Linearität ist <strong>weder eine notwendige, noch eine hinreichende Bedingung</strong>. Sie sind daher mit Vorsicht zu beurteilen.</p>
</blockquote>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb735-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lebenszufriedenheit - Zufriedenheit mit Studieninhalten</span></span>
<span id="cb735-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb735-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(daten<span class="sc">$</span>zufr_inhalt, daten<span class="sc">$</span>leb_zufr)</span>
<span id="cb735-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb735-3" aria-hidden="true" tabindex="-1"></a>lz_inh <span class="ot">&lt;-</span> <span class="fu">lm</span>(daten<span class="sc">$</span>leb_zufr <span class="sc">~</span> daten<span class="sc">$</span>zufr_inhalt, <span class="at">na.action=</span><span class="st">&#39;na.exclude&#39;</span>) <span class="co"># Einfache Regression</span></span>
<span id="cb735-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb735-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(lz_inh) <span class="co"># Einzeichnen Regressionsgerade</span></span></code></pre></div>
<p><img src="_main_files/figure-html/bivariate%20plot%201-1.png" width="672" /></p>
<p><span class="ex">Der Plot spricht für einen linearen Zusammenhang zwischen Lebenszufriedenheit <font size="2">(Kriterium)</font> und Zufriedenheit mit Studieninhalten <font size="2">(Prädiktor)</font>.</span></p>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb736-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lebenszufriedenheit - Zufriedenheit mit Studienbedingungen</span></span>
<span id="cb736-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb736-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(daten<span class="sc">$</span>zufr_beding, daten<span class="sc">$</span>leb_zufr)</span>
<span id="cb736-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb736-3" aria-hidden="true" tabindex="-1"></a>lz_bed <span class="ot">&lt;-</span> <span class="fu">lm</span>(daten<span class="sc">$</span>leb_zufr <span class="sc">~</span> daten<span class="sc">$</span>zufr_beding, <span class="at">na.action=</span><span class="st">&#39;na.exclude&#39;</span>) <span class="co"># Einfache Regression</span></span>
<span id="cb736-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb736-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(lz_bed) <span class="co"># Einzeichnen Regressionsgerade</span></span></code></pre></div>
<p><img src="_main_files/figure-html/bivariate%20plot%202-1.png" width="672" /></p>
<p><span class="ex">Der Plot von Lebenszufriedenheit <font size="2">(Kriterium)</font> und Zufriedenheit mit Studienbedingungen <font size="2">(Prädiktor)</font> weist auf einen linearen Zusammenhang hin.</span></p>
</div>
<div id="residualplot" class="section level4 hasAnchor" number="10.1.1.2">
<h4><span class="header-section-number">10.1.1.2</span> Residualplot<a href="annahmen-der-multiplen-linearen-regression.html#residualplot" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Das wichtigste Werkzeug zur Prüfung der Linearitätsannahme ist der Residualplot. In einem Residualplot werden die vorhergesagten Werte <span class="math inline">\(\hat y_i\)</span> <font size="2">(auf der <span class="math inline">\(x\)</span>-Achse)</font> gegen die Residuen <span class="math inline">\(\hat e_i = y_i - \hat y_i\)</span> <font size="2">(auf der <span class="math inline">\(y\)</span>-Achse)</font> abgetragen.</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb737-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz, <span class="at">which =</span> <span class="dv">1</span>) </span>
<span id="cb737-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb737-2" aria-hidden="true" tabindex="-1"></a><span class="co"># erster Plot der plot()-Funktion für ein lm-Objekt ist der Residualplot</span></span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-536-1.png" width="672" />
Die <strong>gestrichelte Linie</strong> bei <span class="math inline">\(y = 0\)</span> zeigt den Erwartungswert der Residuen. Diese ist immer null und die Residuen sollten sich ohne erkennbares Muster, um diese Linie verteilen.</p>
<p>Die rote Linie ist die <span style="color:red"><a href="#loess">Lowess Fit Line</a></span>. Diese sollte sich der gestrichelten Linie annähern, wenn der Zusammenhang zwischen Prädiktoren und Kriterium linear ist.</p>
<p><span class="ex">In unserem Beispiel legt der Residualplot nahe, dass der Zusammenhang zwischen Lebenszufriedenheit und Zufriedenheit mit Studieninhalten und -bedingungen weitgehend linear ist.</span></p>
<p>Die Annahme der Linearität wäre z.B. verletzt, wenn die Residuen einen U-förmigen Zusammenhang mit den vorhergesagten Werten aufweisen würden. Das würde nahelegen, dass ein quadratischer Zusammenhang zwischen dem Kriterium und den Prädiktoren besteht, der nicht adäquat modelliert wurde.</p>
<p><img src="figures/Voraussetzungspr%C3%BCfung/Bilder/non_linearity.png" width="400px" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="umgang" class="section level3 hasAnchor" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Um einen angemessen Weg zu finden, um mit nicht-linearen Zusammenhängen zwischen den Variablen umzugehen, können wir die folgenden vier Fragen zur Eingrenzung nutzen:</p>
<ul>
<li><em><strong>Gibt es eine Theorie, die einen spezifischen nicht-linearen Zusammenhang zwischen den integrierten Variablen vorhersagt?</strong></em>
<ul>
<li>Wir sollten eine Regressionsgleichung aufstellen, die dem theoretisch implizierten mathematischen Zusammenhang widerspiegelt.</li>
</ul></li>
<li><em><strong>Wie sieht der beobachtete bivariate Zusammenhang zwischen den Variablen aus?</strong></em>
<ul>
<li>Wenn der Zusammenhang zwischen dem Kriterium und einzelnen Prädiktoren oder zwischen einzelnen Prädiktoren untereinander nicht-linear ist, können die Prädiktoren transformiert werden <font size="2">(z.B. <span class="math inline">\(log X_1\)</span>)</font>. Die Art der Transformation hängt von der Art des Zusammenhangs ab.</li>
</ul></li>
<li><em><strong>Wie sieht die <a href="#loess">Lowess Line</a> in den originalen Daten aus?</strong></em> <em>und</em><br />
</li>
<li><em><strong>Bleibt die Varianz der Residuen über den Bereich des Kriteriums hinweg konstant?</strong> <font size="2">(siehe <a href="annahmen-der-multiplen-linearen-regression.html#homoskedastizität">Homoskedastizität</a>)</font></em>
<ul>
<li><strong><em>Homos</em>kedastizität</strong>: Hierbei könnten wir einzelne Regressionsterme in Polynomen höherer Ordnung darstellen <font size="2">(z.B. <span class="math inline">\(X_1^2\)</span>, <span class="math inline">\(X_2^3\)</span>)</font>. In einigen Fällen könnten einfache Potenzfunktionen nicht ausreichend sein. Dann könnten nichtparametrische Funktionen die bessere Lösung sein, um den Zusammenhang zwischen Kriterium und Prädiktoren zu spezifizieren.</li>
<li><strong><em>Heteros</em>kedastizität</strong>: Wir könnten das Kriterium durch eine nichtlineare mathematische Funktion von <span class="math inline">\(Y\)</span> ersetzen <font size="2">(z.B. <span class="math inline">\(log Y\)</span>)</font>. Mit dieser Transformation entsprechen die Residuen nun den <em>beobachteten</em> <span class="math inline">\(log Y\)</span> minus den <em>vorhergesagten</em> <span class="math inline">\(log \hat Y\)</span>.</li>
</ul></li>
</ul>
</div>
</div>
<div id="exogenität-der-prädiktoren" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Exogenität der Prädiktoren<a href="annahmen-der-multiplen-linearen-regression.html#exogenität-der-prädiktoren" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p>Die <strong>Prädiktoren <span class="math inline">\(X\)</span> sind unabhängig vom Fehlerterm</strong> der Regressionsgleichung <span class="math inline">\(e\)</span>: <span class="math inline">\(E(e|X)=0\)</span>.</p>
</blockquote>
<p>Das impliziert z.B. perfekte Reliabilität und das alle relevanten Variablen im Modell aufgenommen sind, das heißt, dass es keine <a href="https://de.wikipedia.org/wiki/Störfaktor" target="_blank">konfundierenden Variablen</a> gibt. Das ist ein zentrales Anliegen in der Wissenschaft, jedoch ist Exogenität nicht leicht nachzuweisen.</p>
<p><span class="ex">Für unser Beispiel der Regression von ‘Zufriedenheit mit Studieninhalten’ und ‘Zufriedenheit mit Studienbedingungen’ auf ‘Lebenszufriedenheit’ müssten wir überlegen, ob noch andere Variablen einen Einfluss haben könnten. Beispielsweise könnten auch verschiedene Persönlichkeitsfaktoren mit ‘Lebenszufriedenheit’ zusammenhängen. Das würde sich dann darin äußern, dass die Prädiktoren noch systematische Varianz mit dem Fehlerterm teilen.</span></p>
<p>Wenn nicht alle relevanten Prädiktoren im Modell spezifiziert sind <em>oder</em> enthaltene Prädiktoren messfehlerbehaftet sind, <em>können</em> daraus verzerrte <strong>Regressionskoeffizienten</strong> und <strong>Standardfehler</strong> resultieren.</p>
<div id="überprüfung-1" class="section level3 hasAnchor" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vor der Erhebung müssen wir uns sorgfältig Gedanken darüber machen, welche Prädiktoren relevant sind. Diese müssen vollständig in das Modell integriert werden. Beispielsweise sollten wir stets eine Literaturrecherche durchführen, um uns über den derzeitigen Stand der Forschung in einem Themenbereich zu informieren.</p>
<p>Zur Überprüfung der Exogenität könnten wir außerdem eine <strong>hierarchische Regression</strong> durchführen, in der wir schrittweise weitere Variablen aufnehmen. Wenn sich die Regressionsgewichte bei Aufnahme eines neuen Prädiktors ändern, war die Exogenitätsannahme der ursprünglichen Prädiktoren wahrscheinlich nicht erfüllt. Solche <strong>Modellvergleiche</strong> helfen bei der Beurteilung der Exogenität.</p>
<p>Wir sollten uns zusätzlich theoretisch überlegen, ob die gemessenen Prädiktoren messfehlerbehaftet sein könnten. Direkt beobachtbare Variablen <font size="2">(z.B. Alter, höchster Bildungsabschluss oder Körpergröße)</font> stehen <em>weniger</em> im Verdacht, messfehlerbehaftet zu sein. Nicht direkt beobachtbare <font size="2">(latente)</font> Variablen hingegen <font size="2">(z.B. Berufserfolg, Kreativität oder Wohlbefinden)</font> können mit <em>größerer</em> Wahrscheinlichkeit messfehlerbehaftet sein.</p>
<p><span class="ex">Unsere Variablen ‘Lebenszufriedenheit’, ‘Zufriedenheit mit Studieninhalten’ und ‘Zufriedenheit mit Studienbedingungen’ sind alle latent. Von daher sind Messfehler wahrscheinlicher.</span></p>
<p>Wir sollten uns außerdem für die reliabelsten Erhebungsinstrumente für die Messung der Prädiktoren entscheiden. Wenn wir nicht an der Erhebung der Variablen beteiligt waren, sollten wir uns nachträglich über die Reliabilität der Erhebungsinstrumente informieren.</p>
<p><span class="ex">In unserem Fall des <code>erstis</code>-Datensatz gibt es leider keine weiteren Informationen zu den Erhebungsinstrumenten. So können wir leider nicht einschätzen, wie reliabel die Erhebungsinstrumente sind.</span></p>
<p>Die Reliabilität erhobener Variablen können wir auf verschiedene Arten schätzen. Diese werden in Abhängigkeit des Forschungsdesign und der Fragestellung ausgewählt.</p>
<p><span class="ex">Die Reliabilität der Messungen in unserem Beispiel könnten wir beispielsweise mit McDonald’s Omega bzw. dem gewichteten Omega berechnen.</span></p>
</div>
<div id="umgang-1" class="section level3 hasAnchor" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Wenn die Prädiktoren stark messfehlerbehaftet sind, sollten wir auf Regressionsmodelle mit latenten Variablen zurückgreifen. Beispielsweise können wir Messfehler mittels <strong>Strukturgleichungsmodellierung</strong> berücksichtigen.</p>
</div>
</div>
<div id="homoskedastizität" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Homoskedastizität<a href="annahmen-der-multiplen-linearen-regression.html#homoskedastizität" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p>Die <strong>Varianz der Residuen <span class="math inline">\(s^2_{e}\)</span> an einer bestimmten Stelle des Prädiktors ist für alle Prädiktorwerte gleich</strong>. Diese Varianz entspricht dem quadrierten Standardschätzfehler <span class="math inline">\(\sigma_e^2\)</span> in der Population.</p>
</blockquote>
<aside>
Homoskedastizität wird auch Varianzhomogenität genannt.
</aside>
<p>Die Annahme wäre beispielsweise verletzt, wenn mit steigenden Prädiktorwerten die Residuen größer, d.h. die Vorhersage mittels der Regressionsgerade ungenauer, werden würde.</p>
<p>Es kann vielfältige Gründe für Varianzheterogenität geben. So können z.B. stark abweichende Werte dafür verantwortlich sein <font size="2">(siehe <a href="annahmen-der-multiplen-linearen-regression.html#extreme-werte-und-einflussreiche-datenpunkte">Extreme Werte und einflussreiche Datenpunkte</a>)</font>.</p>
<p>Nur unter Gültigkeit der Annahme ist die Berechnung der <strong>Standardfehler</strong> korrekt, aber Heteroskedastizität führt <em>nicht</em> zu verzerrten Regressionkoeffizienten.</p>
<p>Andere als die vorgestellten Möglichkeiten zur Überprüfung und zum Umgang mit Heteroskedastizität inklusive der Umsetzung in <span class="r">R</span> finden wir z.B. auf <a href="https://www.r-bloggers.com/how-to-detect-heteroscedasticity-and-rectify-it/" target="_blank"><span class="r">R</span>-bloggers</a>.</p>
<div id="überprüfung-2" class="section level3 hasAnchor" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="residualplot-1" class="section level4 hasAnchor" number="10.3.1.1">
<h4><span class="header-section-number">10.3.1.1</span> Residualplot<a href="annahmen-der-multiplen-linearen-regression.html#residualplot-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Zur Überprüfung der Homoskedastizität können wir ebenfalls einen Residualplot, wie schon bei der <a href="annahmen-der-multiplen-linearen-regression.html#überprüfung">Überprüfung der Annahme der Linearität</a>, verwenden.</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb738-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz, <span class="at">which =</span> <span class="dv">1</span>) </span>
<span id="cb738-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb738-2" aria-hidden="true" tabindex="-1"></a><span class="co"># erster Plot der plot()-Funktion für ein lm-Objekt ist der Residualplot</span></span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-537-1.png" width="672" /></p>
<p>Die <strong>gestrichelte Linie</strong> bei <span class="math inline">\(y = 0\)</span> zeigt den Erwartungswert der Residuen. Diese ist immer null und die Residuen sollten sich ohne erkennbares Muster, um diese Linie verteilen.</p>
<p>Die Annahme wäre z.B. verletzt, wenn die Residuen einen nach rechts geöffneten Trichter bilden würden. Das würde bedeuten, dass die Varianz mit größer werdenden <span class="math inline">\(X\)</span>-Werten wachsen würde wie in nachfolgendem Beispiel illustriert:</p>
<p><img src="figures/Voraussetzungspr%C3%BCfung/Bilder/heteroskedasticity.png" width="400px" style="display: block; margin: auto;" /></p>
</div>
<div id="scale-location-plot" class="section level4 hasAnchor" number="10.3.1.2">
<h4><span class="header-section-number">10.3.1.2</span> Scale Location Plot<a href="annahmen-der-multiplen-linearen-regression.html#scale-location-plot" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Mit dem Scale Location Plot schauen wir, ob die Standardabweichung der standardisierten Residuen <span class="math inline">\(\frac{e_i}{s_e}\)</span> über den Bereich der vorhergesagten Werte hinweg gleich bleibt.</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb739-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz, <span class="at">which =</span> <span class="dv">3</span>) </span></code></pre></div>
<p><img src="_main_files/figure-html/scale%20location%20plot-1.png" width="672" /></p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb740-1" aria-hidden="true" tabindex="-1"></a><span class="co"># dritter Plot der plot()-Funktion für ein lm-Objekt ist der Scale Location Plot</span></span></code></pre></div>
<p>Die standardisierten Residuen sollten auch hier gleichmäßig <font size="2">(zufällig)</font> über den gesamten Bereich streuen. Außerdem sollte die <span style="color:red"><a href="#loess">Lowess Line</a></span> möglichst horizontal zur <span class="math inline">\(x\)</span>-Achse sein.</p>
<p><span class="ex">Auch der Scale Location Plot weist in unserem Beispiel auf ungefähre Varianzhomogenität hin. Das heißt, dass die standardisierten Residuen des Teils vom Kriterium ‘Lebenszufriedenheit’, der nicht durch die Prädiktoren ‘Zufriedenheit mit Studieninhalten’ und ‘Zufriedenheit mit Studienbedingungen’ vorhergesagt werden kann, gleichmäßig über die vorhergesagten Werte vom Kriterium ‘Lebenszufriedenheit’ streut.</span></p>
<details>
<summary class="mtitle">
Exkurs: Quantifizieren des Ausmaßes
</summary>
<div class="more">
<p>Bisher haben wir uns angeschaut, <em>ob</em> Heteroskedastizität vorliegt. Diese hat aber erst einen substanziellen Einfluss auf die Regression, wenn das Ausmaß “groß” ist. Wir können die Varianzheterogenität (<em>wenn</em> die graphische Überprüfung darauf hindeutet) quantifizieren, um zu entscheiden, ob wir korrektive Maßnahmen durchführen sollten. Dazu schauen wir uns eine Möglichkeit aus dem Lehrbuch von Cohen, Cohen, West &amp; Aiken (2003, S.146) an.</p>
<p>Dabei betrachten wir die <strong>konditionale (Fehler-)Varianz <span class="math inline">\(s^2_{(e | slice)}\)</span> </strong>in sog. “Slices” (d.h. Gruppen) für einzelne Prädiktoren. Wir schauen uns das exemplarisch bei <span class="ex"><em>Zufriedenheit mit Studieninhalten</em></span> an. Dazu nutzt man die Ergebnisse der einfachen Regression der Prädiktoren. Diese haben wir im Abschnitt <a href="annahmen-der-multiplen-linearen-regression.html#überprüfung">Bivariate Streudiagramme</a> schon einmal berechnet und darauf greifen wir jetzt wieder zurück.</p>
<p><strong>Das Vorgehen</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Sortieren der Residuen nach aufsteigendem Prädiktor X</strong> (<span class="ex"><em>Zufriedenheit mit Studieninhalten</em></span>)</li>
<li><strong>in ähnlich große Slices einteilen</strong><br />
Die Wahl der Anzahl der Slices ist ein Tradeoff zwischen stabiler Varianzschätzung in jedem Slice (d.h. wenig Gruppen) und der Begutachtung verschiedener Anteile der Daten (d.h. viele Gruppen).</li>
<li><strong>konditionale Varianz in den Slices berechnen</strong><br />
Dazu quadrieren wir die einzelnen Residuen, teilen diese jeweils durch die Anzahl der Personen in diesem Slice <span class="math inline">\(n_{slice}\)</span> minus 2, und summieren die Quotienten auf.</li>
</ol>
<p><strong>Zur Beurteilung der konditionalen Varianz gibt es zwei Kriterien</strong>:</p>
<ul>
<li>der Quotient aus dem Slice mit der größten konditionalen Varianz geteilt durch den Slice mit der kleinsten konditionalen Varianz sollte kleiner als 10 sein<br />
</li>
<li>mit größer werdendem X sollte die konditionale Varianz in den Slices nicht systematisch variieren (z.B. konstant kleiner oder größer werden)</li>
</ul>
<p><strong>Wenn der Quotient <span class="math inline">\(&gt; 10\)</span> ist <em>oder</em> es systematische Variation gibt, sollten wir korrektive Maßnahmen einleiten</strong></p>
<p>Nachfolgend schauen wir uns die Umsetzung dazu in <span class="r">R</span> an:</p>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Objekt erzeugen, ...</span></span>
<span id="cb741-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ... in dem die Residuen nach aufsteigender Größe in X sortiert sind:</span></span>
<span id="cb741-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-3" aria-hidden="true" tabindex="-1"></a>quant <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(erstis<span class="sc">$</span>zuf.inh<span class="fl">.1</span>, </span>
<span id="cb741-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-4" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">residuals</span>(lz_inh))[<span class="fu">order</span>(erstis<span class="sc">$</span>zuf.inh<span class="fl">.1</span>, </span>
<span id="cb741-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-5" aria-hidden="true" tabindex="-1"></a>                                             <span class="fu">residuals</span>(lz_inh)),]</span>
<span id="cb741-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-6" aria-hidden="true" tabindex="-1"></a><span class="co"># data.frame() erstellt einen Dataframe aus den übergebenen Variablen</span></span>
<span id="cb741-7"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-7" aria-hidden="true" tabindex="-1"></a><span class="co"># order() sortiert das erste Argument X aufsteigend (Default) ...</span></span>
<span id="cb741-8"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ... und gleiche Ausprägungen in X werden nach den Ausprägungen ..</span></span>
<span id="cb741-9"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ... des zweiten Arguments (hier: Residuen) sortiert</span></span>
<span id="cb741-10"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># das Komma am Ende sagt, dass wir Zeilen sortieren wollen</span></span>
<span id="cb741-11"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># mit [ ] bekommen wir die Indizes (und nicht die Werte) ausgegeben, ...</span></span>
<span id="cb741-12"><a href="annahmen-der-multiplen-linearen-regression.html#cb741-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ... welche wiederum auf den Dataframe angewendet werden</span></span></code></pre></div>
<p>Standardmäßig wird so die <em>erste</em> Variable X aufsteigend sortiert, weil <code>order(..., decreasing=FALSE)</code> der Default ist. Mit <code>decreasing=TRUE</code> können wir absteigend sortieren.</p>
<br />
&gt; <em><strong>Achtung</strong></em>:
<div class="rows">
Bei <span class="code">order(<span class="ex">X</span>, -<span class="ex">resid</span>)</span> ändert sich die <strong>Sortierung innerhalb der <em>gleichen</em> Prädiktorwerte X</strong> in Abhängigkeit davon, ob wir bei <code>order()</code> vor die <em>zweite</em> Variable (<span class="code"><span class="ex">resid</span></span>) ein <code>-</code> setzen oder nicht:<br />
Mit <span class="code"><span class="ex">resid</span></span> (so wie wir es im Beispiel machen) wird innerhalb der gleichen Prädiktorwerte <strong>aufsteigend</strong> sortiert.<br />
Mit <span class="code">-<span class="ex">resid</span></span> wird innerhalb der gleichen Prädiktorwerte <strong>absteigend</strong> sortiert.<br />
Dadurch kommen unterschiedliche Residuen in die Slices und folglich werden auch unterschiedliche konditionale Varianzen berechnet!
</div>
<p><br />
</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb742-1" aria-hidden="true" tabindex="-1"></a>quant <span class="ot">&lt;-</span> <span class="fu">na.exclude</span>(quant) <span class="co"># Missings raus</span></span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["erstis.zuf.inh.1"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["residuals.lz_inh."],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"1.333333","2":"2.2328207","_rn_":"151"},{"1":"1.666667","2":"-7.7707482","_rn_":"47"},{"1":"1.666667","2":"-4.7707482","_rn_":"180"},{"1":"1.666667","2":"-3.7707482","_rn_":"98"},{"1":"1.666667","2":"5.2292518","_rn_":"31"},{"1":"1.666667","2":"5.2292518","_rn_":"44"},{"1":"2.000000","2":"-8.7743170","_rn_":"118"},{"1":"2.000000","2":"10.2256830","_rn_":"50"},{"1":"2.333333","2":"-8.7778859","_rn_":"40"},{"1":"2.333333","2":"-8.7778859","_rn_":"83"},{"1":"2.333333","2":"-3.7778859","_rn_":"65"},{"1":"2.333333","2":"-2.7778859","_rn_":"17"},{"1":"2.333333","2":"-0.7778859","_rn_":"156"},{"1":"2.333333","2":"0.2221141","_rn_":"141"},{"1":"2.333333","2":"1.2221141","_rn_":"43"},{"1":"2.333333","2":"2.2221141","_rn_":"49"},{"1":"2.333333","2":"3.2221141","_rn_":"52"},{"1":"2.333333","2":"3.2221141","_rn_":"190"},{"1":"2.333333","2":"6.2221141","_rn_":"58"},{"1":"2.666667","2":"-10.7814548","_rn_":"75"},{"1":"2.666667","2":"-9.7814548","_rn_":"76"},{"1":"2.666667","2":"-7.7814548","_rn_":"80"},{"1":"2.666667","2":"-5.7814548","_rn_":"42"},{"1":"2.666667","2":"-0.7814548","_rn_":"185"},{"1":"2.666667","2":"-0.7814548","_rn_":"187"},{"1":"2.666667","2":"1.2185452","_rn_":"81"},{"1":"2.666667","2":"2.2185452","_rn_":"153"},{"1":"2.666667","2":"3.2185452","_rn_":"105"},{"1":"2.666667","2":"4.2185452","_rn_":"32"},{"1":"3.000000","2":"-14.7850237","_rn_":"37"},{"1":"3.000000","2":"-12.7850237","_rn_":"11"},{"1":"3.000000","2":"-8.7850237","_rn_":"56"},{"1":"3.000000","2":"-7.7850237","_rn_":"10"},{"1":"3.000000","2":"-5.7850237","_rn_":"20"},{"1":"3.000000","2":"-5.7850237","_rn_":"84"},{"1":"3.000000","2":"-4.7850237","_rn_":"160"},{"1":"3.000000","2":"-3.7850237","_rn_":"4"},{"1":"3.000000","2":"-3.7850237","_rn_":"48"},{"1":"3.000000","2":"-3.7850237","_rn_":"96"},{"1":"3.000000","2":"-2.7850237","_rn_":"59"},{"1":"3.000000","2":"-2.7850237","_rn_":"74"},{"1":"3.000000","2":"-2.7850237","_rn_":"129"},{"1":"3.000000","2":"-2.7850237","_rn_":"147"},{"1":"3.000000","2":"-1.7850237","_rn_":"63"},{"1":"3.000000","2":"-1.7850237","_rn_":"1"},{"1":"3.000000","2":"-0.7850237","_rn_":"175"},{"1":"3.000000","2":"0.2149763","_rn_":"124"},{"1":"3.000000","2":"0.2149763","_rn_":"159"},{"1":"3.000000","2":"1.2149763","_rn_":"101"},{"1":"3.000000","2":"1.2149763","_rn_":"131"},{"1":"3.000000","2":"2.2149763","_rn_":"51"},{"1":"3.000000","2":"2.2149763","_rn_":"125"},{"1":"3.000000","2":"3.2149763","_rn_":"13"},{"1":"3.000000","2":"3.2149763","_rn_":"136"},{"1":"3.000000","2":"3.2149763","_rn_":"145"},{"1":"3.000000","2":"3.2149763","_rn_":"148"},{"1":"3.000000","2":"4.2149763","_rn_":"66"},{"1":"3.000000","2":"4.2149763","_rn_":"93"},{"1":"3.000000","2":"4.2149763","_rn_":"126"},{"1":"3.000000","2":"4.2149763","_rn_":"162"},{"1":"3.000000","2":"4.2149763","_rn_":"177"},{"1":"3.000000","2":"5.2149763","_rn_":"24"},{"1":"3.000000","2":"5.2149763","_rn_":"114"},{"1":"3.000000","2":"5.2149763","_rn_":"130"},{"1":"3.000000","2":"5.2149763","_rn_":"133"},{"1":"3.000000","2":"6.2149763","_rn_":"33"},{"1":"3.000000","2":"6.2149763","_rn_":"78"},{"1":"3.000000","2":"6.2149763","_rn_":"134"},{"1":"3.000000","2":"6.2149763","_rn_":"150"},{"1":"3.000000","2":"6.2149763","_rn_":"168"},{"1":"3.000000","2":"7.2149763","_rn_":"19"},{"1":"3.000000","2":"7.2149763","_rn_":"116"},{"1":"3.000000","2":"7.2149763","_rn_":"169"},{"1":"3.000000","2":"7.2149763","_rn_":"173"},{"1":"3.000000","2":"10.2149763","_rn_":"25"},{"1":"3.333333","2":"-9.7885926","_rn_":"155"},{"1":"3.333333","2":"-5.7885926","_rn_":"94"},{"1":"3.333333","2":"-5.7885926","_rn_":"184"},{"1":"3.333333","2":"-4.7885926","_rn_":"36"},{"1":"3.333333","2":"-4.7885926","_rn_":"132"},{"1":"3.333333","2":"-3.7885926","_rn_":"38"},{"1":"3.333333","2":"-2.7885926","_rn_":"182"},{"1":"3.333333","2":"-1.7885926","_rn_":"110"},{"1":"3.333333","2":"-1.7885926","_rn_":"149"},{"1":"3.333333","2":"-0.7885926","_rn_":"144"},{"1":"3.333333","2":"0.2114074","_rn_":"138"},{"1":"3.333333","2":"1.2114074","_rn_":"6"},{"1":"3.333333","2":"1.2114074","_rn_":"109"},{"1":"3.333333","2":"1.2114074","_rn_":"183"},{"1":"3.333333","2":"2.2114074","_rn_":"106"},{"1":"3.333333","2":"2.2114074","_rn_":"113"},{"1":"3.333333","2":"2.2114074","_rn_":"120"},{"1":"3.333333","2":"2.2114074","_rn_":"143"},{"1":"3.333333","2":"2.2114074","_rn_":"189"},{"1":"3.333333","2":"3.2114074","_rn_":"54"},{"1":"3.333333","2":"3.2114074","_rn_":"107"},{"1":"3.333333","2":"4.2114074","_rn_":"30"},{"1":"3.333333","2":"4.2114074","_rn_":"163"},{"1":"3.333333","2":"6.2114074","_rn_":"103"},{"1":"3.333333","2":"6.2114074","_rn_":"152"},{"1":"3.333333","2":"8.2114074","_rn_":"179"},{"1":"3.333333","2":"9.2114074","_rn_":"62"},{"1":"3.666667","2":"-10.7921614","_rn_":"108"},{"1":"3.666667","2":"-9.7921614","_rn_":"186"},{"1":"3.666667","2":"-7.7921614","_rn_":"29"},{"1":"3.666667","2":"-6.7921614","_rn_":"127"},{"1":"3.666667","2":"-4.7921614","_rn_":"142"},{"1":"3.666667","2":"-2.7921614","_rn_":"117"},{"1":"3.666667","2":"-1.7921614","_rn_":"77"},{"1":"3.666667","2":"-0.7921614","_rn_":"71"},{"1":"3.666667","2":"-0.7921614","_rn_":"139"},{"1":"3.666667","2":"0.2078386","_rn_":"16"},{"1":"3.666667","2":"0.2078386","_rn_":"18"},{"1":"3.666667","2":"0.2078386","_rn_":"79"},{"1":"3.666667","2":"0.2078386","_rn_":"172"},{"1":"3.666667","2":"1.2078386","_rn_":"67"},{"1":"3.666667","2":"1.2078386","_rn_":"167"},{"1":"3.666667","2":"4.2078386","_rn_":"72"},{"1":"3.666667","2":"4.2078386","_rn_":"104"},{"1":"3.666667","2":"4.2078386","_rn_":"178"},{"1":"3.666667","2":"5.2078386","_rn_":"2"},{"1":"3.666667","2":"5.2078386","_rn_":"191"},{"1":"3.666667","2":"6.2078386","_rn_":"170"},{"1":"4.000000","2":"-14.7957303","_rn_":"154"},{"1":"4.000000","2":"-9.7957303","_rn_":"146"},{"1":"4.000000","2":"-8.7957303","_rn_":"53"},{"1":"4.000000","2":"-7.7957303","_rn_":"100"},{"1":"4.000000","2":"-5.7957303","_rn_":"135"},{"1":"4.000000","2":"-4.7957303","_rn_":"68"},{"1":"4.000000","2":"-4.7957303","_rn_":"86"},{"1":"4.000000","2":"-4.7957303","_rn_":"161"},{"1":"4.000000","2":"-4.7957303","_rn_":"171"},{"1":"4.000000","2":"-3.7957303","_rn_":"15"},{"1":"4.000000","2":"-3.7957303","_rn_":"85"},{"1":"4.000000","2":"-3.7957303","_rn_":"88"},{"1":"4.000000","2":"-3.7957303","_rn_":"90"},{"1":"4.000000","2":"-2.7957303","_rn_":"112"},{"1":"4.000000","2":"-1.7957303","_rn_":"95"},{"1":"4.000000","2":"-0.7957303","_rn_":"23"},{"1":"4.000000","2":"0.2042697","_rn_":"3"},{"1":"4.000000","2":"0.2042697","_rn_":"12"},{"1":"4.000000","2":"0.2042697","_rn_":"55"},{"1":"4.000000","2":"0.2042697","_rn_":"137"},{"1":"4.000000","2":"0.2042697","_rn_":"181"},{"1":"4.000000","2":"1.2042697","_rn_":"14"},{"1":"4.000000","2":"1.2042697","_rn_":"45"},{"1":"4.000000","2":"1.2042697","_rn_":"46"},{"1":"4.000000","2":"1.2042697","_rn_":"57"},{"1":"4.000000","2":"1.2042697","_rn_":"89"},{"1":"4.000000","2":"1.2042697","_rn_":"123"},{"1":"4.000000","2":"2.2042697","_rn_":"28"},{"1":"4.000000","2":"3.2042697","_rn_":"39"},{"1":"4.000000","2":"3.2042697","_rn_":"41"},{"1":"4.000000","2":"3.2042697","_rn_":"122"},{"1":"4.000000","2":"3.2042697","_rn_":"128"},{"1":"4.000000","2":"3.2042697","_rn_":"174"},{"1":"4.000000","2":"4.2042697","_rn_":"21"},{"1":"4.000000","2":"4.2042697","_rn_":"97"},{"1":"4.000000","2":"4.2042697","_rn_":"121"},{"1":"4.000000","2":"4.2042697","_rn_":"166"},{"1":"4.000000","2":"5.2042697","_rn_":"26"},{"1":"4.000000","2":"5.2042697","_rn_":"35"},{"1":"4.000000","2":"6.2042697","_rn_":"165"},{"1":"4.000000","2":"6.2042697","_rn_":"176"},{"1":"4.000000","2":"7.2042697","_rn_":"115"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[5],"max":[5]},"pages":{}}}
  </script>
</div>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Anzahl der Fälle</span></span>
<span id="cb743-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-2" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span>(quant) <span class="co"># 165</span></span>
<span id="cb743-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb743-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Einteilung: 3 Gruppen á 41 Personen, 1 Gruppe mit 42 Personen</span></span>
<span id="cb743-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-5" aria-hidden="true" tabindex="-1"></a>slice_1 <span class="ot">&lt;-</span> quant<span class="sc">$</span>residuals.lz_inh.[<span class="dv">1</span><span class="sc">:</span><span class="dv">41</span>] </span>
<span id="cb743-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-6" aria-hidden="true" tabindex="-1"></a>slice_2 <span class="ot">&lt;-</span> quant<span class="sc">$</span>residuals.lz_inh.[<span class="dv">42</span><span class="sc">:</span><span class="dv">82</span>]</span>
<span id="cb743-7"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-7" aria-hidden="true" tabindex="-1"></a>slice_3 <span class="ot">&lt;-</span> quant<span class="sc">$</span>residuals.lz_inh.[<span class="dv">83</span><span class="sc">:</span><span class="dv">123</span>]</span>
<span id="cb743-8"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-8" aria-hidden="true" tabindex="-1"></a>slice_4 <span class="ot">&lt;-</span> quant<span class="sc">$</span>residuals.lz_inh.[<span class="dv">124</span><span class="sc">:</span><span class="dv">165</span>]</span>
<span id="cb743-9"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb743-10"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-10" aria-hidden="true" tabindex="-1"></a><span class="co"># konditionale Varianz in Slices berechnen</span></span>
<span id="cb743-11"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-11" aria-hidden="true" tabindex="-1"></a>var_slice_1 <span class="ot">&lt;-</span> <span class="fu">sum</span>((slice_1<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="fu">length</span>(slice_1)<span class="sc">-</span><span class="dv">2</span>)))</span>
<span id="cb743-12"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-12" aria-hidden="true" tabindex="-1"></a>var_slice_2 <span class="ot">&lt;-</span> <span class="fu">sum</span>((slice_2<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="fu">length</span>(slice_2)<span class="sc">-</span><span class="dv">2</span>)))</span>
<span id="cb743-13"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-13" aria-hidden="true" tabindex="-1"></a>var_slice_3 <span class="ot">&lt;-</span> <span class="fu">sum</span>((slice_3<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="fu">length</span>(slice_3)<span class="sc">-</span><span class="dv">2</span>)))</span>
<span id="cb743-14"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-14" aria-hidden="true" tabindex="-1"></a>var_slice_4 <span class="ot">&lt;-</span> <span class="fu">sum</span>((slice_4<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(<span class="fu">length</span>(slice_4)<span class="sc">-</span><span class="dv">2</span>)))</span>
<span id="cb743-15"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb743-16"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-16" aria-hidden="true" tabindex="-1"></a><span class="co"># konditionale Varianzen in Vektor speichern</span></span>
<span id="cb743-17"><a href="annahmen-der-multiplen-linearen-regression.html#cb743-17" aria-hidden="true" tabindex="-1"></a>sort_var <span class="ot">&lt;-</span> <span class="fu">c</span>(var_slice_1 , var_slice_2, var_slice_3, var_slice_4)</span></code></pre></div>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb744-1" aria-hidden="true" tabindex="-1"></a>sort_var</span></code></pre></div>
<pre><code>## [1] 40.79699 25.91895 21.15083 24.16912</code></pre>
<p><span class="ex">In unserem Beispiel scheint es keine systematischen Zu- oder Abhnahme in den konditionalen Varianzen der Slices zu geben …</span></p>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb746-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>((var_slice_1 <span class="sc">/</span> var_slice_3), <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 1.929</code></pre>
<p><span class="ex">… und auch der Quotient zwischem dem Slice mit der größten und der kleinsten konditionalen Varianz ist relativ klein.</span><br />
</p>
</div>
</details>
<p style="line-height:10px;">
</p>
</div>
</div>
<div id="umgang-2" class="section level3 hasAnchor" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Wenn wir heteroskedastische Residuen haben, sollten wir gegen die potentielle Verzerrung der Standardfehler vorgehen. Dazu könnten wir beispielsweise <strong>Methoden zur Korrektur der Standardfehler</strong> oder <strong>varianzstabilisierende Verfahren</strong>, wie die Box-Cox-Transformation, nutzen. Eine andere Alternative wäre es, auf <strong>robustere Verfahren</strong> wie die gewichtete Regression mittels WLS zurückzugreifen.</p>
<details>
<summary class="mtitle">
Exkurs: WLS-Regression
</summary>
<div class="more">
<p>Der <strong>w</strong>eighted <strong>l</strong>east <strong>s</strong>quares Schätzer gewichtet jeden Fall (d.h. jede Person) danach, wie präzise die Beobachtung von <span class="math inline">\(Y\)</span> für diesen Fall war. Das bedeutet, dass Beobachtungen mit geringen (Fehler-)Varianzen höher gewichtet werden als Beobachtungen mit großen (Fehler-)Varianzen. Anders ausgedrückt werden Beobachtungen, die näher an der Regressionsgerade sind, stärker gewichtet. Im Vergleich dazu gewichtet der standardmäßig genutzte OLS-Schätzer (Ordinary Least Squares, Methode der kleinsten Quadrate) jede Beobachtung gleich.</p>
<p>Es gibt mehrere Möglichkeiten, die Gewichte <span class="math inline">\(w_i\)</span> zu schätzen. Im Folgenden schauen wir uns exemplarisch eine Methode aus dem Buch von Cohen, Cohen, West &amp; Aiken (2003, S.146-147) an.</p>
<br />
&gt; <em><strong>Achtung</strong></em>:
<div class="rows">
Wenn wir <strong>Ausreißer</strong> in unseren Daten haben, finden wir in der Fußnote 19 auf S.147 des Lehrbuchs eine <strong>geeignetere Methode zur Schätzung der Gewichte <span class="math inline">\(w_i\)</span></strong>.
</div>
<p><br />
Dazu nehmen wir die Residuen aus der OLS-Regression, quadrieren diese und regredieren sie auf unsere Prädiktoren. Die Inversen dieser vorhergesagten quadrierten Residuen sind das unsere Gewichte für die WLS-Regression.</p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb748-1" aria-hidden="true" tabindex="-1"></a>weights_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(daten<span class="sc">$</span>resid <span class="sc">^</span> <span class="dv">2</span> <span class="sc">~</span> daten<span class="sc">$</span>zufr_inhalt <span class="sc">+</span> daten<span class="sc">$</span>zufr_beding,</span>
<span id="cb748-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb748-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">na.action =</span> <span class="st">&quot;na.exclude&quot;</span>)</span>
<span id="cb748-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb748-3" aria-hidden="true" tabindex="-1"></a><span class="co"># wieder na.exclude nutzen</span></span>
<span id="cb748-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb748-4" aria-hidden="true" tabindex="-1"></a><span class="co"># sonst hat der Vektor mit den Gewichten wieder eine geringere Länge </span></span>
<span id="cb748-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb748-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb748-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb748-6" aria-hidden="true" tabindex="-1"></a>daten<span class="sc">$</span>gewichte <span class="ot">&lt;-</span> <span class="fu">fitted.values</span>(weights_lm)</span></code></pre></div>
<p>Zur Modellschätzung können wir wieder <code>lm()</code> nutzen. Dafür müssen wir nur zusätzlich den Gewichtsvektor im Argument <code>weights</code> spezifizieren.</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb749-1" aria-hidden="true" tabindex="-1"></a><span class="co"># WLS-Regression</span></span>
<span id="cb749-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb749-2" aria-hidden="true" tabindex="-1"></a>lm_wls <span class="ot">&lt;-</span> <span class="fu">lm</span>(daten<span class="sc">$</span>leb_zufr <span class="sc">~</span> daten<span class="sc">$</span>zufr_inhalt <span class="sc">+</span> daten<span class="sc">$</span>zufr_beding,</span>
<span id="cb749-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb749-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> daten<span class="sc">$</span>gewichte, <span class="at">na.action =</span> <span class="st">&quot;na.exclude&quot;</span>)</span>
<span id="cb749-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb749-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb749-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb749-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Vergleich der OLS- und WLS-Schätzung</span></span>
<span id="cb749-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb749-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_lz)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##                    Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)       12.791048  2.3391903 5.468152 1.704375e-07
## daten$zufr_inhalt  2.499315  0.6869872 3.638081 3.694881e-04
## daten$zufr_beding  1.312796  0.5743345 2.285769 2.357195e-02</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb751-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_wls)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##                    Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)       12.889931  2.3951572 5.381664 2.566204e-07
## daten$zufr_inhalt  2.545507  0.6966131 3.654119 3.488119e-04
## daten$zufr_beding  1.222937  0.5605375 2.181723 3.057982e-02</code></pre>
<p><span class="ex">Wir sehen, dass die Schätzungen von WLS denen von OLS sehr nah ist. Relevant wären hier prinzipiell mehr die Standardfehler (die bei Varianzheterogenität und OLS verzerrt wären). Da wir aber von Varianzhomogenität in unserem Beispiel ausgehen, sind auch diese sehr ähnlich.</span></p>
<blockquote>
<em><strong>Achtung</strong></em>:
<div class="row">
<p>Es gibt zwei Schwierigkeiten im Umgang mit dem WLS-Schätzer:</p>
</blockquote>
<ul>
<li>wir müssen ein angemessenes Gewicht für jede Beobachtung wählen
<ul>
<li>wenn die Gewichte nicht angemessen sind, ist WLS kein guter Schätzer</li>
<li>daher ist die WLS-Schätzung am besten, wenn die Stichprobengröße <span class="math inline">\(N\)</span> groß ist oder wenn es mehrere Beobachtungen mit identischen <span class="math inline">\(X\)</span>-Werten gibt (d.h. mehrere Personen mit den gleichen Ausprägungen auf dem jeweiligen Prädiktor)</li>
</ul></li>
<li>standardisierte Effektgrößen, wie z.B. der Determinationskoeffizient <span class="math inline">\(R^2\)</span>, haben keine eindeutige Interpretation (wie bei OLS)
</div></li>
</ul>
<p>Daher sollten wir eher OLS als WLS nutzen, <em>außer</em> wenn die Stichprobengröße sehr groß ist oder es ein großes Problem mit Heteroskedastizität gibt.</p>
</div>
</details>
<p style="line-height:10px;">
</p>
</div>
</div>
<div id="unabhängigkeit-der-residuen" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Unabhängigkeit der Residuen<a href="annahmen-der-multiplen-linearen-regression.html#unabhängigkeit-der-residuen" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p>Die Höhe des Residuums einer Beobachtung <span class="math inline">\(\hat e_i\)</span> hängt <strong>nicht</strong> von der Höhe des Residuums einer anderen Beobachtung <span class="math inline">\(\hat e_x\)</span> ab.</p>
</blockquote>
<p>Wenn Residuen abhängig sind, <em>kann</em> sich das auch in Heteroskedastizität äußern.</p>
<p>Residuen sind abhängig, wenn wir z.B. <strong>wiederholte Messungen</strong> oder <strong>Gruppenstrukturen</strong> untersuchen. Ersteres meint, dass mehrere Messungen von <em>einer Person</em>, d.h. zu mehreren Zeitpunkten, vorliegen. In diesem Fall sprechen wir auch von seriellen Abhängigkeiten. Zweiteres meint, dass die Daten “geclustert” sind und es somit systematische Zusammenhänge <em>zwischen Personen</em> gibt z.B. Schüler in einer Schulklasse. Beide Fälle müssen bei der Modellspezifikation berücksichtigt werden.<br />
</p>
<p><span class="ex">In unserem Beispiel könnte beispielsweise das Kriterium ‘Lebenszufriedenheit’ in Abhängigkeit vom Wohnort variieren. Damit wären die Daten geclustert.</span></p>
<p>Abhängigkeit der Residuen führt zwar <em>nicht</em> zu verzerrten Regressionskoeffizienten, aber es kann zu verzerrten <strong>Standardfehlern</strong> führen.<br />
</p>
<div id="überprüfung-3" class="section level3 hasAnchor" number="10.4.1">
<h3><span class="header-section-number">10.4.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ganz grundsätzlich können wir diese Annahme zuerst einmal theoretisch überprüfen, indem wir uns das Studiendesign der erhobenen Daten anschauen.</p>
<p>Wenn nur zu einem Messzeitpunkt Daten erhoben wurden und jede Person nur einmal zu diesem befragt wurde, können wir serielle Abhängigkeiten ausschließen.</p>
<p>Beim Clustering ist es etwas schwieriger, dieses nur durch Überlegung auszuschließen. Auch wenn im Studiendesign nicht vorgesehen war, dass Daten von unterschiedlichen Gruppen erhoben wurden, könnte es dennoch Ähnlichkeiten zwischen Personen hinsichtlich bestimmter Variablen geben. Um mögliche Verletzungen der Unabhängigkeitsannahme prüfen zu können, benötigen wir eine Vermutung darüber, welche Gruppierungsvariablen relevant sein könnten.<br />
</p>
<div id="ausmaß-serieller-abhängigkeit" class="section level4 hasAnchor" number="10.4.1.1">
<h4><span class="header-section-number">10.4.1.1</span> Ausmaß serieller Abhängigkeit<a href="annahmen-der-multiplen-linearen-regression.html#ausmaß-serieller-abhängigkeit" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Es gibt mehrere Möglichkeiten, das Ausmaß serieller Abhängigkeit zu beurteilen. Im Folgenden werden zwei grafische Visualisierungen vorgestellt.<br />
</p>
<div id="index-plot" class="section level5 hasAnchor" number="10.4.1.1.1">
<h5><span class="header-section-number">10.4.1.1.1</span> Index Plot<a href="annahmen-der-multiplen-linearen-regression.html#index-plot" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Einen Eindruck darüber, ob es systematische Abhängigkeiten zwischen den Residuen gibt, können wir mithilfe des Index Plot bekommen. Dieser ist ein Scatterplot, der die Residuen <span class="math inline">\(\hat e_i = y_i - \hat y_i\)</span> <font size="2">(<span class="math inline">\(y\)</span>-Achse)</font> gegen den Index <span class="math inline">\(i\)</span> <font size="2">(<span class="math inline">\(x\)</span>-Achse)</font>, der zumeist durch die (aufsteigende) Zeilennummerierung repräsentiert wird, plottet.</p>
<p>Hierbei können wir u.a. visualisieren, ob es zeitliche Abhängigkeiten gibt, z.B. ob Personen, die später an der Befragung teilgenommen haben, systematische Unterschiede in ihrer Lebenszufriedenheit <font size="2">(Kriterium)</font> zeigen.</p>
<p>Um das besser beurteilen zu können, können wir auch hier wieder die <span style="color:red"><a href="#loess">Lowess Line</a></span> einzeichnen. Diese sollte wieder möglichst horizontal zur <span class="math inline">\(x\)</span>-Achse bei <span class="math inline">\(y = 0\)</span> liegen. Beide Linien fügen wir zur Vereinfachung der Beurteilung des Plots hinzu.</p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb753-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz<span class="sc">$</span>residuals)</span>
<span id="cb753-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb753-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(lm_lz<span class="sc">$</span>residuals), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>) <span class="co"># Lowess Line einfügen (in rot)</span></span>
<span id="cb753-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb753-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="co"># Linie einzeichnen</span></span>
<span id="cb753-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb753-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">h=</span><span class="dv">0</span>, <span class="co"># h - horizontal, 0 - Schnittpunkt mit y-Achse</span></span>
<span id="cb753-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb753-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">col=</span><span class="st">&quot;grey&quot;</span>, <span class="co"># Farbe</span></span>
<span id="cb753-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb753-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">lty=</span><span class="dv">3</span>) <span class="co"># Linien-Art: gestrichelt</span></span></code></pre></div>
<p><img src="_main_files/figure-html/index%20plot-1.png" width="672" /></p>
<p><span class="ex">Die Abbildung impliziert, dass die Residuen unabhängig sind. Das entspricht unseren Vorüberlegungen, das wir nur Variablen haben, die zum gleichen Messzeitpunkt erhoben wurden.</span><br />
</p>
<details>
<summary class="mtitle">
Exkurs: Grafische Interpretationshilfe für den Index Plot
</summary>
<div class="more">
<p>Falls wir ein Messwiederholungsdesign haben und die Daten im Long-Format (d.h. Messungen einer Person in mehreren Zeilen) vorliegen, können wir die Messungen verschiedener Person farblich unterschiedlich darstellen.</p>
<p><span class="ex">In unserem Fall haben wir zwar keine Messwiederholung, aber wir illustrieren die farbliche Darstellung einmal am gleichen Beispiel.</span></p>
<p>Die <strong>Farbe</strong> der geplotteten Elemente können wir mit dem Argument <code>col</code> verändern. Um die Farbe ab einer bestimmten Anzahl an Messungen (d.h. Messwiederholungen für eine Person) jeweils zu verändern, können wir <code>rep()</code> benutzen. Diese Funktion wiederholt das erste Argument <code>x</code> (bzw. die einzelnen Elemente des ersten Arguments) jeweils so oft wie das zweite Argument <code>each</code>.</p>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb754-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb754-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz<span class="sc">$</span>residuals, <span class="at">col =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">17</span>, <span class="at">each =</span> <span class="dv">10</span>))</span>
<span id="cb754-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb754-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(lm_lz<span class="sc">$</span>residuals), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb754-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb754-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>, <span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Warning in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): graphical
## parameter &quot;type&quot; is obsolete</code></pre>
<p><img src="_main_files/figure-html/index%20plot%20colored-1.png" width="500px" /></p>
<p>Die 10 steht dafür, dass wir 10 Messwiederholungen haben. 1 bis 17 kodiert unterschiedliche Farbe. Alternativ können wir auch die Farbnamen in einem Vektor spezifizieren - dann würden wir anstatt <code>1:17</code> z.B. <span class="code">c(‘<span class="ex">red</span>’, ‘<span class="ex">blue</span>’, ‘<span class="ex">green</span>’, …)</span> einfügen.</p>
<p>Mit dem Argument <code>pch</code> können wir analog die <strong>Form der Punkte</strong> ändern.</p>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb756-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb756-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz<span class="sc">$</span>residuals, <span class="at">pch =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">17</span>, <span class="at">each =</span> <span class="dv">10</span>))</span>
<span id="cb756-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb756-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(lm_lz<span class="sc">$</span>residuals), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb756-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb756-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>, <span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Warning in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): graphical
## parameter &quot;type&quot; is obsolete</code></pre>
<p><img src="_main_files/figure-html/index%20plot%20forms-1.png" width="500px" /></p>
<p>Wenn es starke serielle Abhängigkeiten geben würde, würden sich die Fälle sichtlich voneinander unterscheiden bzw. Cluster bilden. Illustriert ist das im folgenden Plot:</p>
<pre><code>## Warning in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): graphical
## parameter &quot;type&quot; is obsolete</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-545-1.png" width="400px" style="display: block; margin: auto;" /></p>
</div>
</details>
<p style="line-height:10px;">
</p>
</div>
</div>
<div id="ausmaß-des-clusterings" class="section level4 hasAnchor" number="10.4.1.2">
<h4><span class="header-section-number">10.4.1.2</span> Ausmaß des Clusterings<a href="annahmen-der-multiplen-linearen-regression.html#ausmaß-des-clusterings" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Zu allererst können wir uns den Intraklassenkoeffizienten <font size="2">(IKK)</font> anschauen. Dieser schätzt den Anteil der Varianz einer Variable, die durch Gruppenzugehörigkeit <font size="2">(Clustering)</font> erklärt wird.</p>
<blockquote>
<p><em><strong>Achtung</strong></em>: Der IKK sollte allerdings <strong>nicht</strong> als einzige Methode zur Überprüfung des Clusterings herangezogen werden, weil wir uns hier nur Mittelwertsunterschiede anschauen. Daher wird noch eine weitere Methode, die Betrachtung von Boxplots der geclusterten Gruppen, illustriert.</p>
</blockquote>
<div id="intraklassenkorrelation" class="section level5 hasAnchor" number="10.4.1.2.1">
<h5><span class="header-section-number">10.4.1.2.1</span> Intraklassenkorrelation<a href="annahmen-der-multiplen-linearen-regression.html#intraklassenkorrelation" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Beispielsweise können wir mit Hilfe des IKK beurteilen, wie stark sich Personen innerhalb einer Gruppe ähneln.<br />
</p>
<ul>
<li>Je näher der Wert an <strong><span class="math inline">\(0\)</span></strong> ist, desto geringer ist der relative Anteil an Unterschieden <strong>zwischen</strong> den Gruppen <font size="2">(d.h. desto <strong>weniger Clustering</strong> liegt vor)</font>.</li>
<li>Je näher der Wert an <strong><span class="math inline">\(1\)</span></strong> ist, desto geringer ist der relative Anteil an Unterschieden <strong>innerhalb</strong> einer Gruppe <font size="2">(d.h. desto <strong>mehr Clustering</strong> liegt vor)</font>.</li>
</ul>
<p>Zur Überprüfung können wir z.B. die Funktion <code>ICCest</code> aus dem Paket <strong>ICC</strong> nutzen.</p>
<p><span class="ex">Für unser Beispiel schauen wir uns exemplarisch an, inwieweit Unterschiede in ‘Lebenszufriedenheit’ <font size="2">(Kriterium)</font> durch ‘Gruppenzugehörigkeit im Wintersemester’ <font size="2">(<code>erstis$gruppe</code>)</font> erklärt werden können</span>.</p>
<p>Dazu fügen wir diese Variable zu unserem Datensatz hinzu.</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb759-1" aria-hidden="true" tabindex="-1"></a>daten<span class="sc">$</span>gruppe <span class="ot">&lt;-</span> erstis<span class="sc">$</span>gruppe</span>
<span id="cb759-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb759-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb759-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb759-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ICC)</span>
<span id="cb759-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb759-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ICCest</span>(daten<span class="sc">$</span>gruppe, daten<span class="sc">$</span>leb_zufr)</span></code></pre></div>
<pre><code>## NAs removed from rows:
##  27 140</code></pre>
<pre><code>## Warning in ICCest(daten$gruppe, daten$leb_zufr):</code></pre>
<pre><code>## $ICC
## [1] 0.005398465
## 
## $LowerCI
## [1] -0.01305084
## 
## $UpperCI
## [1] 0.2595086
## 
## $N
## [1] 4
## 
## $k
## [1] 47.05115
## 
## $varw
## [1] 31.43056
## 
## $vara
## [1] 0.1705978</code></pre>
<p>Die Funktion gibt uns folgende Outputs:</p>
<ul>
<li>welche Missings <font size="2">(d.h. Zeilen)</font> entfernt wurden</li>
<li><code>$ICC</code>: die IKK <font size="2">(<em>Punkt</em>schätzung)</font></li>
<li><code>$LowerCI</code> und <code>$UpperCI</code>: die Grenzen des Konfidenzintervalls für den IKK <font size="2">(<em>Intervall</em>schätzung)</font></li>
<li><code>$N</code>: die Anzahl an Gruppen</li>
<li><code>$k</code>: die Anzahl der Personen in jeder Gruppe</li>
<li><code>$varw</code>: die Varianz innerhalb einer Gruppe</li>
<li><code>$vara</code>: die Varianz zwischen den Gruppen</li>
</ul>
<aside>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
Bei unbalancierter Gruppengröße ist k, die Anzahl der Personen in jeder Gruppe, kleiner als die mittlere Gruppengröße. Für mehr Informationen dazu schau dir die <span class="r">R</span>-Dokumentation für <code>ICCest()</code> an.
</aside>
<p><span class="ex">Die IKK weist darauf hin, dass wenig Varianz durch die Kurszugehörigkeit erklärt wird. Es ist also nicht notwendig, dass wir die Gruppenzugehörigkeit in unserem Modell berücksichtigen.</span></p>
</div>
<div id="boxplots-der-geclusterten-gruppen" class="section level5 hasAnchor" number="10.4.1.2.2">
<h5><span class="header-section-number">10.4.1.2.2</span> Boxplots der geclusterten Gruppen<a href="annahmen-der-multiplen-linearen-regression.html#boxplots-der-geclusterten-gruppen" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Zuletzt schauen wir uns die Boxplots der Verteilungen der Residuen in den Gruppen an.</p>
<p>Zur Erleichterung der Interpretation zeichnen wir wieder mit Hilfe von <code>abline(h=0, col="darkblue", type="l", lty=3)</code> eine Senkrechte bei <span class="math inline">\(y=0\)</span> <font size="2">(weil der erwartete Mittelwert der Residuen <span class="math inline">\(0\)</span> ist)</font>.</p>
<div class="sourceCode" id="cb763"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb763-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb763-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(daten<span class="sc">$</span>resid <span class="sc">~</span> daten<span class="sc">$</span>gruppe)</span>
<span id="cb763-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb763-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>, <span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lty=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Warning in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): graphical
## parameter &quot;type&quot; is obsolete</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-547-1.png" width="672" /></p>
<p>Die Interpretation hier ist ähnlich zu den Resiualplots: Der Median der einzelnen Gruppen sollte jeweils nah an der gestrichelten Linie bei <span class="math inline">\(y=0\)</span> sein. Zusätzlich sollten die Verteilungen sich stark überlappen.</p>
<p><span class="ex">Die Verteilungen der Residuen in den Gruppen sieht sehr ähnlich aus. Die Verteilungen überlappen sich deutlich. Es scheint keine systematischen Streuungsunterschiede in den Residuen in Abhängigkeit der Gruppenzugehörigkeit zu geben.</span></p>
</div>
</div>
</div>
<div id="umgang-3" class="section level3 hasAnchor" number="10.4.2">
<h3><span class="header-section-number">10.4.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="serielle-abhängigkeit" class="section level4 hasAnchor" number="10.4.2.1">
<h4><span class="header-section-number">10.4.2.1</span> Serielle Abhängigkeit<a href="annahmen-der-multiplen-linearen-regression.html#serielle-abhängigkeit" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Liegen serielle Abhängigkeiten vor, müssen wir auf geeignete Verfahren zur Analyse von Längsschnittdaten zurückgreifen <font size="2">(z.B. gemischte lineare Modelle)</font>.</p>
</div>
<div id="clustering" class="section level4 hasAnchor" number="10.4.2.2">
<h4><span class="header-section-number">10.4.2.2</span> Clustering<a href="annahmen-der-multiplen-linearen-regression.html#clustering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Liegen Abhängigkeiten aufgrund von Gruppenunterschieden vor, können wir versuchen, die Gruppenunterschiede, in Form von weiteren Variablen, ins Modell aufzunehmen. Gelingt dies nicht, müssen wir auf geeignete Verfahren zur Analyse von „geclusterten“ Daten zurückgreifen <font size="2">(z.B. gemischte lineare Modelle)</font>.</p>
</div>
</div>
</div>
<div id="weitere-wichtige-aspekte" class="section level2 hasAnchor" number="10.5">
<h2><span class="header-section-number">10.5</span> Weitere wichtige Aspekte<a href="annahmen-der-multiplen-linearen-regression.html#weitere-wichtige-aspekte" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="normalverteilung-der-residuen" class="section level3 hasAnchor" number="10.5.1">
<h3><span class="header-section-number">10.5.1</span> Normalverteilung der Residuen<a href="annahmen-der-multiplen-linearen-regression.html#normalverteilung-der-residuen" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Die Annahme, dass die Residuen in der Population normalverteilt sind, ist eigentlich gar keine Annahme im engeren Sinne. Aufgrund des zentralen Grenzwertsatzes sind die Regressionskoeffizienten in großen Stichproben selbst dann asymptotisch normalverteilt, wenn die Annahme nicht erfüllt ist. Daher ist eine Verletzung der Annahme eher in kleineren Stichproben problematisch. Da in der Praxis aber unklar ist, wann eine Stichprobe als groß genug anzusehen ist, ist es ratsam, die Verteilung der Residuen immer auf Abweichung von einer Normalverteilung hin zu prüfen.</p>
<p>Wenn die Normalverteilungsannahme der Residuen verletzt ist, ist der <strong>Standardfehler</strong> womöglich verzerrt, was zu falschen inferenzstatistischen Schlüssen führen kann.</p>
<p>Nicht normalverteilte Residuen können auch auf andere Probleme wie Modellmissspezifikation hinweisen.</p>
<div id="überprüfung-4" class="section level4 hasAnchor" number="10.5.1.1">
<h4><span class="header-section-number">10.5.1.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="histogramm" class="section level5 hasAnchor" number="10.5.1.1.1">
<h5><span class="header-section-number">10.5.1.1.1</span> Histogramm<a href="annahmen-der-multiplen-linearen-regression.html#histogramm" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Mit Hilfe eines Histogramms können wir uns die Häufigkeitsverteilung einer metrischen Variable anzeigen lassen. Dafür wird diese in verschiedene Klassen <font size="2">(‘bins’)</font> eingeteilt. Das schauen wir uns für die Residuen an.</p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb765-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb765-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(lm_lz<span class="sc">$</span>residuals)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-548-1.png" width="672" /></p>
<p>Optisch sollte ungefähr eine Normalverteilung zu erkennen sein.<br />
</p>
<p><span class="ex">In unserem Beispiel sieht es jedoch nach einer linksschiefen (d.h. rechtssteilen) Verteilung der Residuen aus.</span></p>
<details>
<summary class="mtitle">
Exkurs: Graphische Interpretationshilfe für das Histogramm
</summary>
<div class="more">
<p>Um die Beurteilung des Histogramms zu erleichtern, können wir zwei Linien einzeichnen - die reale Dichtefunktion der Variablen und die erwartete Dichtefunktion, wenn die Variable normalverteilt wäre. Diese können wir vergleichen, um die Annahme der Normalverteilung zu überprüfen.</p>
<p>Eine wichtige Voraussetzung dafür, dass wir über das Histogramm die Dichtefunktionen legen können, ist dass wir das Argument <code>prob=TRUE</code> setzen.<br />
</p>
<p>Dann zeichnen wir die reale Dichtefunktion der Residuen ein. Dafür kombinieren wir <code>line()</code> und <code>density()</code>. Erstere zeichnet eine Linie in eine Grafik ein und mit zweiterer spezifizieren wir, dass die Linie die geschätzte Dichte (der Residuen) visualisieren soll.</p>
<p>Für die normalverteilte Dichtefunktion der Residuen nutzen wir <code>curve()</code> und <code>dnorm()</code>. Mit ersterer wird eine Kurve auf Basis einer mathematischen Funktion eingezeichnet. Mit zweiterer geben wir an, dass es eine Dichtefunktion einer Normalverteilung sein soll, für die wir Mittelwert und Standardabweichung (der Residuen) angeben. Zusätzlich müssen wir hier mit <code>add=TRUE</code> festlegen, dass die Kurve über das Histogramm gelegt werden soll.</p>
<p>Um die Normalverteilung besser anschauen zu können, erweitern wir die <span class="math inline">\(x\)</span>-Achse. Das machen wir mit <span class="code">xlim=c(<span class="ex">-15</span>, <span class="ex">15</span>)</span>. Die Wahl der Grenzen von <span class="math inline">\(-15\)</span> bis <span class="math inline">\(+ 15\)</span> - ist eine theoretische Überlegung. Bei einer Normalverteilung liegen ~ <span class="math inline">\(99\)</span>% der Werte im Bereich <span class="math inline">\(+/- 3\)</span> Standardabweichungen vom Mittelwert entfernt. Die Standardabweichung der Residuen beträgt ~ 5.105.</p>
<p>Für eine bessere Übersichtlichkeit stellen wir die <span style="color:orange">reale Dichtefunktion</span> und die <span style="color:green">erwartete Dichtefunktion</span> farblich dar.</p>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(lm_lz<span class="sc">$</span>residuals, <span class="co"># Histogramm der Residuen ...</span></span>
<span id="cb766-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">prob =</span> <span class="cn">TRUE</span>, <span class="co"># ... als Dichte ...</span></span>
<span id="cb766-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">20</span>, <span class="dv">20</span>)) <span class="co"># ... mit veränderter X-Achse</span></span>
<span id="cb766-4"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-5"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="co"># erstellt eine Linie ...</span></span>
<span id="cb766-6"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">density</span>( <span class="co"># ... auf Basis der geschätzten Dichtefunktion ...</span></span>
<span id="cb766-7"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-7" aria-hidden="true" tabindex="-1"></a>    lm_lz<span class="sc">$</span>residuals), <span class="co"># ... der Residuen ...</span></span>
<span id="cb766-8"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)  <span class="co"># ... in orange</span></span>
<span id="cb766-9"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-10"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb766-11"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-11" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="co"># erstellt eine Kurve ...</span></span>
<span id="cb766-12"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dnorm</span>( <span class="co"># ... einer normalverteilten Dichtefunktion ...</span></span>
<span id="cb766-13"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-13" aria-hidden="true" tabindex="-1"></a>    x, <span class="at">mean =</span> <span class="fu">mean</span>(lm_lz<span class="sc">$</span>residuals), <span class="co"># ... auf Basis des Mittelwerts ...</span></span>
<span id="cb766-14"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> <span class="fu">sd</span>(lm_lz<span class="sc">$</span>residuals)), <span class="co"># ... und der Standardabweichung der Residuen ...</span></span>
<span id="cb766-15"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;green&quot;</span>, <span class="co">#... in grün ...</span></span>
<span id="cb766-16"><a href="annahmen-der-multiplen-linearen-regression.html#cb766-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">add =</span> <span class="cn">TRUE</span>) <span class="co"># ... die zu bestehendem Plot hinzugefügt wird</span></span></code></pre></div>
<p><img src="_main_files/figure-html/hist_advanced-1.png" width="672" /></p>
<p><span class="ex">Anhand dieser beiden Linien wird noch deutlicher, dass die Verteilung der Residuen in unserem Beispiel von einer Normalverteilung abweicht.</span></p>
</div>
</details>
<p style="line-height:10px;">
</p>
</div>
<div id="qq-plot" class="section level5 hasAnchor" number="10.5.1.1.2">
<h5><span class="header-section-number">10.5.1.1.2</span> QQ-Plot<a href="annahmen-der-multiplen-linearen-regression.html#qq-plot" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Der QQ-Plot <font size="2">(Quantil-Quantil-Plot)</font> plottet die aufsteigend geordneten standardisierten Residuen gegen die korrespondierenden Quantile der Normalverteilung. Dafür werden die Residuen durch den Standardschätzfehler geteilt <span class="math inline">\(\frac {e_i} {\hat {\sigma}}\)</span>.</p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb767-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb767-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz, <span class="at">which =</span> <span class="dv">2</span>) </span>
<span id="cb767-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb767-2" aria-hidden="true" tabindex="-1"></a><span class="co"># zweiter Plot der plot()-Funktion für ein lm-Objekt ist der QQ-Plot</span></span>
<span id="cb767-3"><a href="annahmen-der-multiplen-linearen-regression.html#cb767-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="co"># zur Illustration für unser Beispiel</span></span></code></pre></div>
<p><img src="_main_files/figure-html/qq%20plot-1.png" width="672" /></p>
<p>In der obigen Abbildung werden die theoretischen Quantile der Normalverteilung <font size="2">(<span class="math inline">\(x\)</span>-Achse)</font> gegen die standardisierten Residuen <font size="2">(<span class="math inline">\(y\)</span>-Achse)</font> abgetragen. Wenn die Residuen normalverteilt sind, sollten die Punkte ungefähr auf der winkelhalbierenden Geraden <font size="2">(gestrichelte Linie)</font> liegen. Kleinere Abweichungen, vor allem an den Enden der Geraden <font size="2">(unten links und oben rechts)</font> sind in der Praxis aber nicht ungewöhnlich und oftmals nicht weiter problematisch.</p>
<p><span class="ex"> In unserem Beispiel weichen viele Punkte mit höheren Ausprägungen (rechts von der </span> <span style="color:blue">blauen Linie</span><span class="ex">) von der winkelhalbierenden Geraden ab, was für eine gewisse Verletzung der Normalverteilungsannahme spricht.</span></p>
<p>Wenn wir sehen wollen, wie der QQ-Plot bei verschiedenen Verteilungsformen aussehen kann, können wir uns diesen <a href="https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot" target="_blank">Forumseintrag</a> zu QQ-Plots anschauen.</p>
<details>
<summary class="mtitle">
Exkurs: Shapiro-Wilk-Test
</summary>
<div class="more">
<p>Wir haben eingangs schon angerissen, warum graphische Verfahren besser geeignet sind, um Annahmen zu überprüfen. Für die Überprüfung der Normalverteilung der Residuen mittels statistischer Tests gelten die gleichen Vorbehalte: Wenn die Stichprobe groß ist, haben wir viel Power auch kleinste Abweichungen von der Normalverteilung zu finden. Gerade in dieser Situation (d.h. bei grossem <span class="math inline">\(N\)</span>) sind Abweichungen von der Normalverteilung aber gar nicht so problematisch. Bei kleinem <span class="math inline">\(N\)</span> hingegen (wenn Abweichungen potentiell gefährlich sind), fehlt dem Test dann aber oft die Teststärke Abweichungen korrekt zu erkennen.</p>
<p>Mit dem Shapiro-Wilk-Test kann getestet werden, ob Daten normaltverteilt sind (<span class="math inline">\(H_0\)</span>) oder nicht (<span class="math inline">\(H_1\)</span>).</p>
<p>Der Test wird mit der Funktion <code>shapiro.test()</code> durchgeführt. Um die Residuen der Regression zu testen, extrahieren wir diese wieder aus dem Ergebnisobjekt mit <code>lm_lz$residuals</code>.</p>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb768-1" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(lm_lz<span class="sc">$</span>residuals)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  lm_lz$residuals
## W = 0.96198, p-value = 0.0001845</code></pre>
<p><span class="ex">In unserem Beispiel kann die Nullhypothese abgelehnt werden, d.h. dass die Residuen <strong>nicht</strong> normalverteilt sind.</span></p>
</div>
</details>
<p style="line-height:10px;">
</p>
</div>
</div>
<div id="umgang-4" class="section level4 hasAnchor" number="10.5.1.2">
<h4><span class="header-section-number">10.5.1.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Zuerst sollten wir überprüfen, ob die Abweichung von der Normalverteilung auf eine Missspezifikation des Modells zurückzuführen ist.</p>
<p>Wenn das nicht zutrifft und die Stichprobe klein ist, sollten wir korrektive Maßnahmen einleiten. Wir könnten die Daten transformieren, wie bei <a href="annahmen-der-multiplen-linearen-regression.html#umgang">Umgang mit Nicht-Linearität</a>, allerdings <em>könnte</em> das auch die getesteten Hypothesen ändern, z.B. vergleichen wir nach der log-Transformation keine arithmetischen Mittel mehr sondern geometrische Mittel. Alternativ könnten wir auch robuste Testverfahren anwenden.</p>
</div>
</div>
<div id="multikollinearität" class="section level3 hasAnchor" number="10.5.2">
<h3><span class="header-section-number">10.5.2</span> Multikollinearität<a href="annahmen-der-multiplen-linearen-regression.html#multikollinearität" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Wenn <strong>Prädiktoren sehr hoch miteinander korrelieren</strong>, spricht man von Multikollinearität. Dabei können wir außerdem zwischen <strong><em>non-essentieller</em></strong> und <strong><em>essentieller</em></strong> Mutlikollinearität unterscheiden.</p>
</blockquote>
<p><strong><em>Non-essentielle</em></strong> Multikollinearität entsteht dadurch, dass Prädiktoren nicht zentriert sind.</p>
<p><strong><em>Essentielle</em></strong> Multikollinearität entsteht durch tatsächliche Zusammenhänge zwischen Variablen in der Population. Diese Abhängigkeiten zwischen Prädiktoren äußern sich dadurch, dass die Varianz eines Prädiktors großteilig durch die anderen Prädiktoren erklärt werden kann, er sich also aus einer Linearkombination der anderen Prädiktoren ergibt z.B. <span class="math inline">\(X_1=1,2,3\)</span> und <span class="math inline">\(X_2=2,4,6\)</span>.</p>
<aside>
Beispielsweise würde zwischen ‘Größe in cm’ und ‘Größe in m’ perfekte Multikollinearität bestehen, weil beide Vielfache voneinander sind.
</aside>
<p>Multikollinearität kann aber beispielsweise auch vorliegen, wenn die <strong>Anzahl an Prädiktoren <span class="math inline">\(k\)</span> größer ist als die Größe der Stichprobe <span class="math inline">\(N\)</span></strong> oder wenn wir im Modell versehentlich zweimal den <strong>gleichen Prädiktor spezifiziert</strong> haben. Multikollinearität tritt außerdem häufig bei <strong>Interaktionen zwischen Prädiktoren</strong> auf. Das kommt daher, dass eine Interaktion ein Produkt aus zwei Prädiktoren ist und folglich viel Gemeinsamkeit mit beiden Prädiktoren hat.</p>
<p>Bei sehr hohen Korrelationen zwischen den Prädiktoren, ergeben sich folgende Probleme:</p>
<ol style="list-style-type: decimal">
<li><strong>Erschwerte Interpretation der partiellen Korrelationen</strong>. Weil sich die Prädiktoren einen großen Anteil an der erklärten Varianz des Kriteriums teilen ist unklar, welchem Prädiktor welcher Anteil zugeschrieben werden soll. Um die Anteile der Varianzaufklärung besser den Prädiktoren zuordnen zu können, könnten wir die Reihenfolge der Aufnahme der Prädiktoren im Modell ändern <font size="2">(<em>hierarchisches Vorgehen</em>)</font>. Dabei schauen wir uns die Differenzen der Determinationskoeffizienten <span class="math inline">\(R^2_{k+m} - R^2_k\)</span> der Modelle (die sich durch einen weiteren Prädiktor <span class="math inline">\(m\)</span> unterscheiden) an.</li>
<li><strong>Erhöhte Standardfehler</strong>. Die Standardfehler der von Multikollinearität betroffenen Regressionkoeffizienten vergrößern sich <font size="2">(siehe <a href="annahmen-der-multiplen-linearen-regression.html#toleranz">Toleranz</a> und Formel des Standardfehlers der Regressionsgewichte)</font>, was wiederum zu breiteren Konfidenzintervallen und einer geringeren Wahrscheinlichkeit führt, die Nullhypothese abzulehnen, wenn tatsächlich ein Effekt vorliegt <font size="2">(d.h. geringere Power)</font>.</li>
</ol>
<aside>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<strong>Formel des Standardfehlers der Regressionsgewichte</strong>:<br />
<span class="math inline">\(SE_{b_k} = \frac{sd_y}{sd_x} \cdot \sqrt{\frac{1}{1-R^2_k}} \cdot \sqrt{\frac{1-R^2_y}{N - K - 1}}\)</span><br />
Toleranz: <span class="math inline">\(1-R^2_k\)</span><br />
Indeterminationskoeffizient: <span class="math inline">\(1-R^2_y\)</span>
</aside>
<div id="überprüfung-5" class="section level4 hasAnchor" number="10.5.2.1">
<h4><span class="header-section-number">10.5.2.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Um festzustellen, ob Prädiktoren hoch miteinander korreliert sind, können wir uns die <strong>Toleranz</strong> und den <strong>Variance Inflation Factor</strong> anschauen. Beide hängen direkt miteinander zusammen, aber ihre Interpretationen sind unterschiedlich.</p>
<p>Falls wir ein <em>ernsthaftes</em> Problem mit Multikollinearität haben, wird uns das in <span class="r">R</span> teilweise mit z.B. <code>aliased coefficients</code> oder <code>1 coefficient not defined because of singularities</code> angezeigt.</p>
<p><font size="2">Im Paket <strong>mctest</strong> gibt es zwei Funktionen, die helfen, Multikollinearität zu entdecken - <code>omctest()</code> - und zu lokalisieren - <code>imctest()</code>. Hierfür werden jeweils verschiedene Maße zu Rate gezogen u.a. auch die Toleranz und der VIF. Da wir die anderen Maße aber nicht vertiefend behandeln, sei an dieser Stelle <strong>nur auf das Paket hingewiesen</strong>. Bei Interesse empfielt es sich, den Artikel der Entwickler <em><a href="https://www.researchgate.net/publication/313799182_mctest_An_R_Package_for_Detection_of_Collinearity_among_Regressors" target="_blank">mctest: An R Package for Detection of Multicollinearity among Regressors</a></em> zu lesen, in dem die Maße kurz erklärt und weiterführende Quellen angegeben werden.</font></p>
<div id="toleranz" class="section level5 hasAnchor" number="10.5.2.1.1">
<h5><span class="header-section-number">10.5.2.1.1</span> Toleranz<a href="annahmen-der-multiplen-linearen-regression.html#toleranz" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<blockquote>
<p>Die Toleranz sagt uns, <strong>wie viel Varianz in <span class="math inline">\(X_j\)</span> unabhängig von den anderen Prädiktoren</strong> ist.</p>
</blockquote>
<p>Dafür wird eine Regression von Prädiktor <span class="math inline">\(X_j\)</span> auf alle anderen Prädiktoren im Modell gerechnet <font size="2">(d.h. das Kriterium bleibt außen vor)</font> und davon der Kehrwert gebildet. Sie ist somit ein Maß für die <strong>Uniqueness</strong> von <span class="math inline">\(X_j\)</span>. Die Tolreanz wird wie folgt berechnet: <span class="math inline">\(1 - R^2_j\)</span></p>
<p>In <span class="r">R</span> können wir die Toleranz z.B. über den Kehrwert des Variance Inflation Factors, mit der Funktion <code>vif()</code> aus dem Paket <strong>car</strong>, berechnen. Der Funktion übergeben wir unser lm-Objekt.</p>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb770-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb770-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb770-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">/</span> <span class="fu">vif</span>(lm_lz)</span></code></pre></div>
<pre><code>## daten$zufr_inhalt daten$zufr_beding 
##         0.8988664         0.8988664</code></pre>
<p>Je kleiner die Toleranz ist, desto größer das Problem mit Multikollinearität. <span class="math inline">\(Tol_j = 0\)</span> impliziert perfekte Multikollinearität. <span class="math inline">\(Tol_j~ &lt; 0.10\)</span> deutet auf ein ernsthaftes Problem mit Multikollinearität hin.</p>
<p><span class="ex">Ungefähr 89.9% der Varianz in Zufriedenheit mit Studienbedingungen ist unabhängig von Zufriedenheit mit Studieninhalten <font size="2">(für den Fall von genau zwei Prädiktoren, wie in unserem Beispiel, gilt auch die umgekehrte Interpretation)</font>.</span><br />
</p>
</div>
<div id="variance-inflation-factor" class="section level5 hasAnchor" number="10.5.2.1.2">
<h5><span class="header-section-number">10.5.2.1.2</span> Variance Inflation Factor<a href="annahmen-der-multiplen-linearen-regression.html#variance-inflation-factor" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<blockquote>
<p><span class="math inline">\(VIF_j\)</span> gibt an, <strong>um wie viel die Varianz des Regressionskoeffizients <span class="math inline">\(X_j\)</span> (durch die Korrelation mit den anderen Prädiktoren) erhöht</strong> wird, verglichen mit dem Fall, dass alle Prädiktoren unkorreliert sind.</p>
</blockquote>
<p><span class="math inline">\(\sqrt {VIF_j}\)</span> gibt an, um welchen Faktor sich der Standardfehler <span class="math inline">\(SE_{b_j}\)</span> durch Einschluss weiterer korrelierter Prädiktoren erhöht (verglichen mit dem Fall, dass alle Prädiktoren unkorreliert sind).</p>
<p>Der VIF wird für jeden Prädiktor im Modell berechnet. Er wird folgendermaßen bestimmt: <span class="math inline">\(\frac{1}{1 - R^2_j}\)</span>, wobei <span class="math inline">\(R^2_j\)</span> der Determinationskoeffizient der Regression des <span class="math inline">\(j\)</span>-ten Prädiktors auf alle anderen <span class="math inline">\((k - 1)\)</span> Prädiktoren ist. Das entspricht der quadrierten multiplen Korrelation zwischen <span class="math inline">\(X_j\)</span> und allen anderen Prädiktoren.</p>
<blockquote>
<p><em><strong>Achtung</strong></em>: Im Fall von zwei Prädiktoren bleibt die geteilte Varianz zwischen beiden Variablen gleich; egal welche Variable Kriterium und welche Prädiktor ist. Daher sind beide VIF gleich.</p>
</blockquote>
<p>Dazu nutzen wir aus dem Paket <strong>car</strong> die Funktion <code>vif()</code>, welcher wir unser lm-Objekt übergeben.</p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb772-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb772-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb772-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(lm_lz)</span></code></pre></div>
<pre><code>## daten$zufr_inhalt daten$zufr_beding 
##          1.112512          1.112512</code></pre>
<p>Als Daumenregel gilt, dass ein VIF größer als 10 auf ein Problem mit Multikollinearit hindeutet.</p>
<p><span class="ex">Der VIF in unserem Beispiel ist sehr klein, d.h. dass unsere beiden Prädiktoren Zufriedenheit mit Studieninhalten und Zufriedenheit mit Studienbedingungen nicht viel gemeinsame Varianz teilen.</span><br />
</p>
</div>
</div>
<div id="umgang-5" class="section level4 hasAnchor" number="10.5.2.2">
<h4><span class="header-section-number">10.5.2.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In einer Regression, die auch Interaktionen zwischen den Prädiktoren annimmt, können wir die Prädiktoren zentrieren, um <strong><em>non-essentieller</em></strong> Multikollinearität beizukommen. Hierbei sollten wir aber bei Vorhandensein von Dummyvariablen vorsichtig sein. Diese <em>müssen</em> nicht zentriert werden und eine Zentrierung erschwert zusätzlich ihre Interpretation.</p>
<p>Bei hoher <strong><em>essentieller</em></strong> Multikollinearität ist es oftmals ratsam, Prädiktoren auszuschließen, wenn diese weitgehend redundante Informationen liefern.</p>
</div>
</div>
<div id="extreme-werte-und-einflussreiche-datenpunkte" class="section level3 hasAnchor" number="10.5.3">
<h3><span class="header-section-number">10.5.3</span> Extreme Werte und einflussreiche Datenpunkte<a href="annahmen-der-multiplen-linearen-regression.html#extreme-werte-und-einflussreiche-datenpunkte" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p><strong>Extreme Werte</strong>, auch <strong>Ausreißer</strong> <font size="2">(Outlier)</font> genannt, meinen untypische Datenpunkte, die nicht zum Rest der Daten passen. Diese können sowohl auf dem Kriterium als auch auf den Prädiktoren vorkommen.<br />
</p>
</blockquote>
<ul>
<li>Wenn ein extremer Wert auf dem <strong>Kriterium</strong> vorkommt, heißt das, dass die Prädiktorwerte einer Person <span class="math inline">\(i\)</span> zwar im Wertebereich der anderen Personen liegen, aber der beobachtete Wert <span class="math inline">\(y_i\)</span> stark vom vorhergesagten <span class="math inline">\(\hat y_i\)</span> abweicht <font size="2">(Abweichung in <span class="math inline">\(Y\)</span>)</font>.</li>
<li>Wenn extreme Werte auf den <strong>Prädiktoren</strong> vorkommen, heißt das, dass die Prädiktorwerte einer Person <span class="math inline">\(i\)</span> nicht im Wertebereich der anderen Personen liegen <font size="2">(Abweichung in <span class="math inline">\(X\)</span>)</font>, aber der beobachtete Wert <span class="math inline">\(y_i\)</span> dennoch nah am vorhergesagten <span class="math inline">\(\hat y_i\)</span> ist. Extreme Werte auf den Prädiktoren haben zusätzlich eine hohe <strong>Leverage/Hebelwirkung</strong> und damit <em>potenziell</em> einen starken Einfluss auf die Regressionsgerade.</li>
</ul>
<aside>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
Die <strong>Leverage</strong> ist die absolute Abweichung eines beobachteten Wertes einer Person vom Mittel aller Prädiktoren <span class="math inline">\(X\)</span>.
</aside>
<p>In den folgenden drei Abbildungen sehen wir verdeutlicht, was mit extremen Abweichungen auf dem Kriterium bzw. den Prädiktoren gemeint ist. Dazu wurden exemplarisch <strong>Lebenszufriedenheit</strong> (<span class="math inline">\(Y\)</span>) und <strong>Zufriedenheit mit Studieninhalten</strong> (<span class="math inline">\(X_1\)</span>) gegeneinander geplottet. Hierbei wurde jeweils der <span class="math inline">\(Y\)</span>- bzw. <span class="math inline">\(X_1\)</span>-Wert von <span style="color:red">Person 50</span> geändert. Die <span style="color:blue">gestrichelte Linie</span> stellt dabei jeweils die obere Grenze des Wertebereichs des Kriteriums bzw. des Prädiktors dar.</p>
<aside>
<a href="#cooklev">Später</a> greifen wir nochmal auf das gleiche Beispiel zurück, um den Unterschied und die Konsequenzen von extremen Abweichungen auf dem Kriterium bzw. den Prädiktoren noch mehr zu verdeutlichen.
</aside>
<p><img src="_main_files/figure-html/unnamed-chunk-552-1.png" width="400px" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-552-2.png" width="400px" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-552-3.png" width="400px" style="display: block; margin: auto;" /></p>
<p>Wenn die Regressionsgerade stark durch einzelne Beobachtungen beeinflusst wird, bezeichnet man diese als <strong>einflussreiche Datenpunkte</strong> <font size="2">(<em>influentials</em>)</font>. Der Ausschluss dieser Beobachtungen würde stark abweichende Parameterschätzungen hervorbringen. Das gleichzeitige Vorhandensein von Ausreißern und Beobachtungen mit hoher Leverage könnten die Ursache dafür sein.</p>
<div id="überprüfung-6" class="section level4 hasAnchor" number="10.5.3.1">
<h4><span class="header-section-number">10.5.3.1</span> Überprüfung<a href="annahmen-der-multiplen-linearen-regression.html#überprüfung-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Stoßen wir über auffällige Werte in unserem Datensatz, sollte wir zunächst kontrollieren, ob diese durch Eingabefehler oder fehlerhafte Kodierungen fehlender Werte <font size="2">(<em>Missings</em>)</font> zustande gekommen sind.</p>
<p>Beispielsweise werden in manchen Anwendungen Missings nicht mit <code>NA</code>, sondern z.B. wie bei Unipark mit <code>99</code> oder <code>-99</code> kodiert. Wir müssen diese <em>vor</em> der Auswertung auf <code>NA</code> umkodieren, da <span class="r">R</span> diese sonst nicht als Missings erkennt. Für mehr Informationen dazu können wir im <a href="http://methods-berlin.com/de/r-lernplattform/fehlende-werte" target="_blank"><strong>Kapitel zu Fehlenden Werten</strong></a> nachschauen.</p>
<p>Stark abweichende Werte lassen sich oft einfach mit Hilfe von <strong>Plots</strong> oder <strong>Deskriptivstatistiken</strong> identifizieren.</p>
<div id="extreme-werte-auf-dem-kriterium" class="section level5 hasAnchor" number="10.5.3.1.1">
<h5><span class="header-section-number">10.5.3.1.1</span> Extreme Werte auf dem Kriterium<a href="annahmen-der-multiplen-linearen-regression.html#extreme-werte-auf-dem-kriterium" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Hierbei schaut man sich vor allem die <strong>Residuen</strong> an.</p>
<div id="plot-der-studentisierten-gelöschten-residuen" class="section level6 hasAnchor" number="10.5.3.1.1.1">
<h6><span class="header-section-number">10.5.3.1.1.1</span> Plot der studentisierten gelöschten Residuen<a href="annahmen-der-multiplen-linearen-regression.html#plot-der-studentisierten-gelöschten-residuen" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>Zur Exploration von Ausreißern auf dem Kriterium können wir uns die studentisierten gelöschten Residuen, geplottet gegen den Index <span class="math inline">\(i\)</span>, anschauen.</p>
<aside>
Studentisierte gelöschte Residuen werden auch als <strong>externally studentized residuals</strong> bezeichnet.
</aside>
<p>Studentisierte gelöschte Residuen werden wie folgt berechnet: <span class="math inline">\(\frac {e_i} {\hat {\sigma} \cdot \sqrt{1 - h_m}}\)</span>  </p>
<p>Sie sind theoretisch <span class="math inline">\(t\)</span>-verteilt mit <span class="math inline">\(df = N − k − 1\)</span> (N = Stichprobengröße, k = Anzahl Prädiktoren). Wir erhalten die Anzahl der Freiheitsgrade aus dem lm-Objekt mittels <span class="code">summary(<span class="ex">lm_lz</span>)$fstat[“dendf”]</span>.</p>
<blockquote>
<p><strong>Studentisiert</strong> heißt, dass die Residuen durch die geschätzte Populationsstandardabweichung der Residuen an der Stelle <span class="math inline">\(x_m\)</span> <font size="2">(das meint den Hebelwert der Person <span class="math inline">\(h_m\)</span>)</font> geteilt werden.</p>
</blockquote>
<blockquote>
<p><strong>Gelöscht</strong> bedeutet geschätzte Abweichung des vorhergesagten Wertes vom beobachteten Wert <font size="2">(das sind die normalen Residuen)</font> in einem Modell <strong>ohne</strong> die entsprechende Person. Wir sagen also <span class="math inline">\(\hat y_i\)</span> für Person <span class="math inline">\(i\)</span> mit Hilfe eines Modells hervor, für welches Person <span class="math inline">\(i\)</span> nicht in die Parameterschätzung mit eingegangen ist.<br />
</p>
</blockquote>
<p><font size="2"> Für mehr Informationen zu studentisierten gelöschten Residuen <em>(externally studentized residuals)</em> siehe S.399ff im Lehrbuch von Cohen, Cohen, West &amp; Aiken (2003).</font></p>
<p>Wir extrahieren diese mit <code>rstudent()</code> aus dem lm-Objekt.</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb774-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">rstudent</span>(lm_lz))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-553-1.png" width="672" /></p>
<p>Es gibt keine einheitlichen Richtlinien darüber, ab wann ein studentisiertes gelöschtes Residuum als extrem groß anzusehen ist. Wir schauen nur, ob einzelne Werte stark vom Cluster der anderen Werte abweichen.</p>
<p><span class="ex">In unserem Beispiel gibt es keine Werte, die <strong>extrem</strong> von der Verteilung der anderen abweichen. Wir schauen uns dennoch exemplarisch einmal die zwei größten Werte an <font size="2">(d.h. die kleiner gleich - 3 sind)</font>.</span></p>
<p>In folgender Abbildung schauen wir uns an, wie eine <span style="color:red">extreme Abweichung</span> eines studentisierten gelöschten Residuums aussehen könnte. In folgendem Plot wurde nur ein studentisiertes gelöschtes Residuum eingefügt; die anderen Werte sind gleich geblieben.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-554-1.png" width="400px" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb775"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb775-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb775-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which</span>(<span class="fu">unname</span>(<span class="fu">rstudent</span>(lm_lz) <span class="sc">&lt;=</span> <span class="sc">-</span><span class="dv">3</span>))  <span class="co"># Indizes aller Werte, die kleiner gleich -3 sind</span></span></code></pre></div>
<pre><code>## [1]  37 154</code></pre>
<p>Mit <code>which()</code> lassen wir uns die Indizes derjenigen studentisierten gelöschten Residuen ausgeben, die <span class="math inline">\(\leq-3\)</span> sind.</p>
<p>Wir nutzen außerdem <code>unname()</code>, weil <code>rstudent()</code> einen benannten numerischen Vektor <font size="2">(<em>named num</em>)</font> erstellt und bei Nutzung von <code>which()</code> die Indizes sonst doppelt ausgegeben werden würden. Bei <em>named nums</em> werden die Indizes nämlich schon im Vektor mitgespeichert <font size="2">(ohne dass dieser dadurch seine Dimensionalität ändert)</font>.</p>
</div>
<div id="outlier-test" class="section level6 hasAnchor" number="10.5.3.1.1.2">
<h6><span class="header-section-number">10.5.3.1.1.2</span> Outlier Test<a href="annahmen-der-multiplen-linearen-regression.html#outlier-test" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>Alternativ könnten wir auch einen Signifikanztest <em>nur</em> für das größte studentisierte gelöschte Residuum durchführen. Dabei wird dessen p-Wert mit einer Bonferroni-Korrektur angepasst. Dazu wird der p-Wert mit der Stichprobengröße <font size="2">(hier: <span class="math inline">\(N=164\)</span>)</font> multipliziert. Das an der Stichprobengröße relativierte <font size="2">(d.h. durch dieses geteilt)</font> Signifikanzlevel <span class="math inline">\(\alpha\)</span> markiert den kritischen Wert <font size="2">(d.h. das korrigierte Signifkanzlevel)</font>.</p>
<p>Dazu nutzen wir <code>outlierTest()</code> aus dem Paket <strong>car</strong>. Wir nutzen konventionell <span class="math inline">\(\alpha=0.05\)</span>.</p>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb777-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb777-2"><a href="annahmen-der-multiplen-linearen-regression.html#cb777-2" aria-hidden="true" tabindex="-1"></a><span class="fu">outlierTest</span>(lm_lz)</span></code></pre></div>
<pre><code>## No Studentized residuals with Bonferroni p &lt; 0.05
## Largest |rstudent|:
##     rstudent unadjusted p-value Bonferroni p
## 37 -3.053226          0.0026521      0.43494</code></pre>
<p><span class="ex">Der Test liefert Evidenz dafür, dass das größte studentisierte gelöschte Residuum nicht extrem von den anderen abweicht.</span></p>
</div>
</div>
<div id="extreme-werte-auf-den-prädiktoren" class="section level5 hasAnchor" number="10.5.3.1.2">
<h5><span class="header-section-number">10.5.3.1.2</span> Extreme Werte auf den Prädiktoren<a href="annahmen-der-multiplen-linearen-regression.html#extreme-werte-auf-den-prädiktoren" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Hierbei schauen wir uns vor allem die <strong>Hebelwerte</strong> <span class="math inline">\(h_{ii}\)</span> einzelner Beobachtungen <font size="2">(engl. leverage oder hatvalues)</font> an.</p>
<blockquote>
<p>Hebelwerte geben die absolute Abweichung eines beobachteten Wertes einer Person vom Mittel aller Prädiktoren <span class="math inline">\(X\)</span> <font size="2">(dem sog. Schwerpunkt)</font> an.</p>
</blockquote>
<p>Fälle mit großer Hebelwirkung haben <em>potenziell</em> einen größeren Einfluss auf die Parameterschätzungen <font size="2">(<span class="math inline">\(0 &lt; h_{ii} &lt; 1\)</span>)</font>.</p>
<div id="plot-und-histogramm-der-hebelwerte" class="section level6 hasAnchor" number="10.5.3.1.2.1">
<h6><span class="header-section-number">10.5.3.1.2.1</span> Plot und Histogramm der Hebelwerte<a href="annahmen-der-multiplen-linearen-regression.html#plot-und-histogramm-der-hebelwerte" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>In kleinen bis mittelgroßen Datensätzen ist ein Indexplot der Hebelwerte eine ausreichende Methode, um Ausreißer auf den Prädiktoren zu erkennen.<br />
</p>
<p>Dazu extrahieren wir die Hebelwerte mit Hilfe der Funktion <code>hatvalues()</code> aus dem lm-Objekt. Damit fehlende Werte <font size="2">(<code>NA</code>)</font> ausgeschlossen werden <font size="2">(ihre Hebelwirkung würde <span class="math inline">\(0\)</span> betragen)</font>, wenden wir außerdem <code>[!is.na()]</code> an. <code>is.na()</code> evaluiert, ob die Elemente vorhanden sind <font size="2">(<code>TRUE</code> oder <code>FALSE</code>)</font>, <code>!</code> sorgt dafür, dass <em>keine</em> Missings angewählt werden, und <code>[ ]</code> gibt die Indizes aus.</p>
<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb779-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb779-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">hatvalues</span>(lm_lz)[<span class="sc">!</span><span class="fu">is.na</span>(daten<span class="sc">$</span>resid)])</span></code></pre></div>
<p><img src="_main_files/figure-html/plot%20hat%20values-1.png" width="672" /></p>
<p>In größeren Datensätzen sollten wir die Hebelwerte der Übersichtlichkeit halber in einem Histogramm visualisieren.</p>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb780-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">hatvalues</span>(lm_lz)[<span class="sc">!</span><span class="fu">is.na</span>(daten<span class="sc">$</span>resid)])</span></code></pre></div>
<p><img src="_main_files/figure-html/hist%20hat%20values-1.png" width="672" /></p>
<p>Wir sollten uns hierbei auf die Inspektion weniger, extremer Werte beschränken und vor allem nur auf solche, die weit entfernt von den restlichen (nah beieinander liegenden Werten) sind.</p>
<p>Den größten Hebelwert und seinen Index können wir uns folgendermaßen ausgeben lassen:</p>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb781-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb781-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>((<span class="fu">hatvalues</span>(lm_lz)), <span class="at">decreasing=</span><span class="cn">TRUE</span>)[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>##        151 
## 0.06632099</code></pre>
<p>Wenn wir z.B. die größten drei Werte betrachten möchte, schreiben wir <code>[1:3]</code> anstatt <code>[1]</code>. Wenn wir alle Werte <em>absteigend</em> <font size="2">(weil <code>decreasing=TRUE</code>)</font> betrachten möchten, lassen wir die eckigen Klammern mit den Indizes komplett weg.</p>
<p><span class="ex">Der Hebelwert von Person 151 liegt etwas abseits von der Verteilung der anderen. Noch extremere Werte sollten wir uns immer genauer anschauen. In unserem Beispiel liegen aber keine offensichtlich extremen Hebelwerte vor.</span></p>
</div>
</div>
<div id="einflussreiche-datenpunkte" class="section level5 hasAnchor" number="10.5.3.1.3">
<h5><span class="header-section-number">10.5.3.1.3</span> Einflussreiche Datenpunkte<a href="annahmen-der-multiplen-linearen-regression.html#einflussreiche-datenpunkte" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div id="residuen-leverage-plot" class="section level6 hasAnchor" number="10.5.3.1.3.1">
<h6><span class="header-section-number">10.5.3.1.3.1</span> Residuen-Leverage Plot<a href="annahmen-der-multiplen-linearen-regression.html#residuen-leverage-plot" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>Wenn es große Residuen und Hebelwerte gibt, können wir uns weiterführend den Residuen-Leverage Plot anschauen. Dieser plottet die Hebelwerte <font size="2">(<span class="math inline">\(x\)</span>-Achse)</font> gegen die standardisierten Residuen <font size="2">(<span class="math inline">\(y\)</span>-Achse)</font>.</p>
<p>Zur Standardisierung werden die Residuen durch den Standardschätzfehler geteilt <span class="math inline">\(\frac {e_i} {\hat {\sigma}}\)</span></p>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb783-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz, <span class="at">which=</span><span class="dv">5</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/resid%20lev%20plot-1.png" width="672" /></p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb784-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fünfter Plot der plot()-Funktion für ein lm-Objekt ist der Residuen-Leverage Plot</span></span></code></pre></div>
<p>Die <span style="color:red"><a href="#loess">Lowess Line</a></span> sollte auch hier wieder flach und nah an der gestrichelten Linie bei <span class="math inline">\(y=0\)</span> sein.</p>
<p><span class="ex">Die Werte der Person mit dem Index 50 weisen eine leicht erhöhte hohe Cooks Distance auf. Allerdings sind die Grenzen bei 0.5 und 1 nicht einmal sichtbar, weil alle Werte der Cooks Distance relativ klein sind. Auch die </span><span style="color:red"><a href="#loess">Lowess Line</a></span><span class="ex"> ist flach an nah bei y=0. Beides spricht dafür, dass in unserem Datensatz keine einflussreichen Datenpunkte, die die Parameter verzerren könnten, enthalten sind.</span><br />
</p>
<p>In diesem <a href="https://stats.stackexchange.com/questions/58141/interpreting-plot-lm" target="_blank">Forumseintrag</a> wird der Residuen-Leverage-Plot noch ausführlicher erklärt.</p>
<details>
<summary class="mtitle q">
<a name="cooklev"></a>Was ist die Cooks Distance? Und wie hängt diese mit den standardisierten Residuen, der Leverage und der Lowess Fit Line zusammen?
</summary>
<div class="more">
<blockquote>
<p>Die Cooks Distance ist ein Maß dafür, wie sich die Regressionsgerade und damit die vorhergesagten Werte ändern würden, wenn wir die Daten einer betrachteten Person <span class="math inline">\(i\)</span> (<span class="math inline">\(Cooks D_i\)</span>) ausschliessen würden, wobei <span class="math inline">\(Cooks D_i \geq 0\)</span> ist.</p>
</blockquote>
<p>Je größer die <span class="math inline">\(Cooks D_i\)</span>, desto größer der Einfluss der Beobachtungen von Person <span class="math inline">\(i\)</span>.</p>
<p>Im Residuen-Leverage-Plot werden auch Linien der <strong>Cooks Distance</strong> mit den Werten <span class="math inline">\(0.5\)</span> und <span class="math inline">\(1.0\)</span> abgetragen, <strong>wenn</strong> Beobachtungen in die Nähe dieser Grenzen kommen (was im oberen Beispiel nicht der Fall ist).</p>
<p>Wir können uns folgendermaßen auch nur die Werte der Cooks Distance gegen den Index geplottet anschauen:</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb785-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lm_lz, <span class="at">which=</span><span class="dv">4</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/plot%20cd-1.png" width="600px" style="display: block; margin: auto;" /></p>
<p>Schauen wir uns den <strong>Residuen-Leverage-Plot</strong> noch einmal an.</p>
<p>In den folgenden Abbildungen wurden die Werte von <strong>Person 50</strong> auf dem Kriterium und einem Prädiktor (Zufriedenheit mit Studieninhalten) jeweils einzeln und anschließend gemeinsam manipuliert, um den jeweiligen Einfluss im Vergleich zum bestehenden Datensatz (der schon weiter oben dargestellt war) zu veranschaulichen.</p>
<p>In der Einführung zu <a href="annahmen-der-multiplen-linearen-regression.html#extreme-werte-und-einflussreiche-datenpunkte">Extremen Werte und einflussreichen Datenpunkte</a> haben wir den Unterschied zwischen Ausreißern auf dem Kriterium und den Prädiktoren schon angesprochen. Die Abbildungen sollen deren Implikationen noch verdeutlichen. Bei der Interpretation helfen die durchgezogene <span style="color:red"><a href="#loess">Lowess Fit Line</a></span> und die rot gestrichelten Grenzwerte der Cooks Distance.</p>
<p><img src="_main_files/figure-html/resid%20lev%20plot%202-1.png" width="600px" style="display: block; margin: auto;" /></p>
<p><img src="_main_files/figure-html/sim%20lev%20resid%20plot%201-1.png" width="600px" style="display: block; margin: auto;" /></p>
<div style="text-align: center">
Das standardisierte Residuum ist größer; die Leverage ist gleich.<br />
Die Lowess Line ist immer noch flach und nah an der gestrichelten Linie bei <span class="math inline">\(y=0\)</span>.<br />
Die Cooks Distance ist wesentlich größer, sie beträgt fast <span class="math inline">\(1\)</span>.
</div>
<p><br />
</p>
<p><img src="_main_files/figure-html/sim%20lev%20resid%20plot%202-1.png" width="600px" style="display: block; margin: auto;" /></p>
<div style="text-align: center">
Das standardisierte Residuum ist <em>vom Betrag</em> her ähnlich; die Leverage ist größer.<br />
Die Lowess Line weicht wesentlich stärker von der gestrichelten Linie bei <span class="math inline">\(y=0\)</span> ab.<br />
Die Cooks Distance ist etwas größer, aber noch <span class="math inline">\(&lt; 0.5\)</span>.
</div>
<p><br />
</p>
<p><img src="_main_files/figure-html/sim%20lev%20resid%20plot%203-1.png" width="600px" style="display: block; margin: auto;" /></p>
<div style="text-align: center">
Das standardisierte Residuum ist größer; die Leverage ist größer.<br />
Die Lowess Line weicht extrem von der gestrichelten Linie bei <span class="math inline">\(y=0\)</span> ab.<br />
Die Cooks Distance ist <span class="math inline">\(&gt; 1\)</span>.
</div>
<p><br />
</p>
</div>
</details>
<p style="line-height:10px;">
</p>
</div>
</div>
</div>
<div id="umgang-6" class="section level4 hasAnchor" number="10.5.3.2">
<h4><span class="header-section-number">10.5.3.2</span> Umgang<a href="annahmen-der-multiplen-linearen-regression.html#umgang-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<blockquote>
<p><em><strong>Achtung</strong></em>: Wir sollten abweichende Beobachtungen nicht unbedacht aus der Analyse entfernen. Sie können nicht nur durch fehlerhafte Messung, sondern auch korrekte, aber seltene Messungen zutande gekommen sein <font size="2">(z.B. weil wenig Leute eine gewisse Ausprägung auf einer bestimmten Variable besitzen)</font>.<br />
</p>
</blockquote>
<p>Außerdem gibt es keine einheitlichen Richtlinien darüber, ab wann wir Ausreißer und einflussreiche Datenpunkte entfernen sollten. Wir sollte diese immer mit Hinblick auf die Gesamtverteilung bewerten. Jeder Ausschluss sollte plausibel begründet werden können.</p>
<p>Am besten ist es immer, zu überprüfen, ob wir robuste Ergebnisse vorliegen haben. Wir führen die vorgestellten Analysen mit und ohne kritische Werte durch und schauen uns an, was passiert. Ändern sich die Befunde nicht, sind wir wahrscheinlich auf der sicheren Seite.</p>
</div>
</div>
</div>
<div id="literatur-weiterführende-hilfe" class="section level2 hasAnchor" number="10.6">
<h2><span class="header-section-number">10.6</span> Literatur &amp; weiterführende Hilfe<a href="annahmen-der-multiplen-linearen-regression.html#literatur-weiterführende-hilfe" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dieses Kapitel basiert größtenteils auf dem in der Vorlesung <em>Multivariate Verfahren</em> des Masterstudiengangs Psychologie genutzen Lehrbuch:</p>
<blockquote>
<p><font size="2"><strong>Cohen</strong>, J., <strong>Cohen</strong>, P., <strong>West</strong>, S. G., &amp; <strong>Aiken</strong>, L. S. (2003). <em>Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences</em> Hillsdale, NJ: Erlbaum.<br />
Abschnitt 4.3 Assumptions and Ordinary Least Squares Regresion (S.117-125)<br />
Abschnitt 4.4 Detecting Violations of Assumptions (S.125-141)<br />
Abschnitt 4.5 Remedies: Alternative Approaches When Problems Are Detected (S.141-149)<br />
Abschnitt 10.3 Detecting Outliers: Regression Diagnostics” (S.394-411)<br />
Abschnitt 10.5 Multicollinearity” (S.419-425)</font><br />
<font size="1">(für HU-Studierende über <a href="http://ub.hu-berlin.de" target="_blank">ub.hu-berlin.de</a> zugänglich)</font></font><br />
</p>
</blockquote>
<p>Für ein <strong>deutschsprachiges</strong> Buch:  </p>
<blockquote>
<p><font size="2"><strong>Gollwitzer</strong>, M., <strong>Eid</strong>, M., &amp; <strong>Schmitt</strong>, M. (2017). <em>Statistik und Forschungsmethoden.</em> Weinheim: Beltz Verlagsgruppe. <strong>(für HU-Studierende online zugänglich)</strong><br />
Kapitel “Regressionsdiagnostik” (S. 704-725)<br />
<font size="1">(für HU-Studierende über <a href="http://ub.hu-berlin.de" target="_blank">ub.hu-berlin.de</a> zugänglich)</font></font></p>
</blockquote>
<p>Zur weiteren <strong>Hilfe bei der Interpretation von Plots</strong>, können wir diesen <a href="https://stats.stackexchange.com/questions/58141/interpreting-plot-lm" target="_blank">Forumseintrag</a> sowie diese <a href="https://data.library.virginia.edu/diagnostic-plots/" target="_blank">Seite</a> nutzen. </font></p>
<hr />
<p><font size="2">Um eine möglichst exakte Replikation der Funktionen zu gewährleisten gibt es im folgenden relevante Angaben zum System (<strong><span class="r">R</span>-Version</strong>, <strong>Betriebssystem</strong>, <strong>geladene Pakete mit Angaben zur Version</strong>), mit welchem diese Seite erstellt wurde.</p>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="annahmen-der-multiplen-linearen-regression.html#cb786-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.2.2 (2022-10-31 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 22621)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Germany.utf8  LC_CTYPE=English_Germany.utf8   
## [3] LC_MONETARY=English_Germany.utf8 LC_NUMERIC=C                    
## [5] LC_TIME=English_Germany.utf8    
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices utils     datasets  methods  
## [8] base     
## 
## other attached packages:
##  [1] ICC_2.4.0        tidyr_1.2.1      naniar_0.6.1     VIM_6.2.2       
##  [5] colorspace_2.0-3 car_3.1-1        carData_3.0-5    rmarkdown_2.18  
##  [9] readr_2.1.3      Hmisc_4.7-2      ggplot2_3.4.0    Formula_1.2-4   
## [13] survival_3.4-0   lattice_0.20-45  readxl_1.4.1     foreign_0.8-84  
## [17] knitr_1.41       devtools_2.4.5   usethis_2.1.6    kableExtra_1.3.4
## [21] dplyr_1.0.10     psych_2.2.9     
## 
## loaded via a namespace (and not attached):
##   [1] deldir_1.0-6        ellipsis_0.3.2      class_7.3-20       
##   [4] visdat_0.5.3        htmlTable_2.4.1     base64enc_0.1-3    
##   [7] fs_1.5.2            rstudioapi_0.14     proxy_0.4-27       
##  [10] remotes_2.4.2       fansi_1.0.3         ranger_0.14.1      
##  [13] xml2_1.3.3          splines_4.2.2       mnormt_2.1.1       
##  [16] cachem_1.0.6        robustbase_0.95-0   pkgload_1.3.2      
##  [19] jsonlite_1.8.4      cluster_2.1.4       png_0.1-8          
##  [22] shiny_1.7.3         compiler_4.2.2      httr_1.4.4         
##  [25] backports_1.4.1     assertthat_0.2.1    Matrix_1.5-1       
##  [28] fastmap_1.1.0       cli_3.4.1           later_1.3.0        
##  [31] htmltools_0.5.4     prettyunits_1.1.1   tools_4.2.2        
##  [34] gtable_0.3.1        glue_1.6.2          Rcpp_1.0.9         
##  [37] cellranger_1.1.0    jquerylib_0.1.4     vctrs_0.5.1        
##  [40] svglite_2.1.0       nlme_3.1-160        lmtest_0.9-40      
##  [43] laeken_0.5.2        xfun_0.35           stringr_1.5.0      
##  [46] ps_1.7.2            rvest_1.0.3         mime_0.12          
##  [49] miniUI_0.1.1.1      lifecycle_1.0.3     DEoptimR_1.0-11    
##  [52] zoo_1.8-11          MASS_7.3-58.1       scales_1.2.1       
##  [55] hms_1.1.2           promises_1.2.0.1    parallel_4.2.2     
##  [58] RColorBrewer_1.1-3  yaml_2.3.6          memoise_2.0.1      
##  [61] gridExtra_2.3       sass_0.4.4          rpart_4.1.19       
##  [64] latticeExtra_0.6-30 stringi_1.7.8       highr_0.9          
##  [67] e1071_1.7-12        checkmate_2.1.0     boot_1.3-28        
##  [70] pkgbuild_1.4.0      rlang_1.0.6         pkgconfig_2.0.3    
##  [73] systemfonts_1.0.4   evaluate_0.18       purrr_0.3.5        
##  [76] htmlwidgets_1.5.4   processx_3.8.0      tidyselect_1.2.0   
##  [79] norm_1.0-10.0       magrittr_2.0.3      bookdown_0.30      
##  [82] R6_2.5.1            generics_0.1.3      profvis_0.3.7      
##  [85] DBI_1.1.3           pillar_1.8.1        withr_2.5.0        
##  [88] abind_1.4-5         sp_1.5-1            nnet_7.3-18        
##  [91] tibble_3.1.8        crayon_1.5.2        interp_1.1-3       
##  [94] utf8_1.2.2          tzdb_0.3.0          urlchecker_1.0.1   
##  [97] jpeg_0.1-10         data.table_1.14.6   callr_3.7.3        
## [100] vcd_1.4-10          digest_0.6.30       webshot_0.5.4      
## [103] xtable_1.8-4        httpuv_1.6.6        munsell_0.5.0      
## [106] viridisLite_0.4.1   bslib_0.4.1         sessioninfo_1.2.2</code></pre>
<p>Für Informationen zur Interpretation dieses Outputs schaut auch den Abschnitt <a href="http://methods-berlin.com/wp-content/uploads/Pakete.html#replizierbarkeit-von-analysen" target="_blank"><strong>Replizierbarkeit von Analysen</strong></a> des Kapitels zu Paketen an.
</font></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="wide--long-format.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="grafiken.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
