# Outputs - ALM - FAQ

Das Allgemeine Lineare Modell <font size="2">(ALM)</font> umfasst verschiedene inferenzstatistische  und varianzanalytische Verfahren, darunter **$t$-Test** (`t.test()`), **ANOVA** (`aov()`) und **lineare Regression** (`lm()`).

Im Folgenden schauen wir uns an, wie die **Outputs** der jeweiligen Funktionen `t.test()`, `aov()` und `lm()` aufgebaut sind und wie diese interpretiert werden. Dafür nutzen wir jeweils dieselben zwei Variablen. Wir werden zudem vor der Durchführung der Methoden deren **Annahmen prüfen**.  Abschließend beschäftigen wir uns mit den **Gemeinsamkeiten der Verfahren** (für unseren speziellen Fall von einer metrischen abhängigen Variablen und einer kategorialen unabhängigen Variablen).  

<aside>\
\
Wir gehen nur knapp auf die Prüfung der Annahmen ein. Eine ausführlichere Einleitung  befindet sich [hier](Voraussetzungspruefung.qmd).</aside>

<!--Zur Veranschaulichung untersuchen wir, ob sich Studierende mit und ohne Nebenjob signifikant in ihrer Zufriedenheit mit der Bewältigung von Studienbelastungen unterscheiden. Diese ungerichtete $H_1$ überprüfen wir mit einem Signifikanzniveau von $\alpha = 0.05$. -->

<details class ="bsp"><summary>Beispieldatensatz für dieses Kapitel</summary><p>

Wir schauen uns im folgenden den Datensatz `erstis` an. Dieser enthalt Daten aus einer Erhebung mit Erstsemesterstudierenden der Psychologie. Das zugehörige Codebook finden wir <a href="https://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/R_fuer_Einsteiger/Datensatz%20Erstis_Codebook.pdf" target="_blank">hier</a>.

Den Datensatz laden wir mit der `load()`-Funktion in unsere Environment: 

```{r}
#| echo: false
load(url("http://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/R_fuer_Einsteiger/erstis.rda"))
```

```{r}
#| eval: false
load(url("http://www.beltz.de/fileadmin/beltz/downloads/
         OnlinematerialienPVU/R_fuer_Einsteiger/erstis.rda"))
# Zeilenumbruch zwischen der ersten und zweiten Zeile noch entfernen!
```

Wir wollen untersuchen, ob sich das Vorhandenseins eines **Nebenjobs** (`job`) auf die **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`, erster Messzeitpunkt) auswirkt.
 
Dazu speichern wir beide Variablen in einem neuen Datensatz. 
 
```{r}
#| eval: true
# Daten aus erstis in neuem Dataframe speichern und umbennenen
daten <- data.frame(job = erstis$job, zf_belastung = erstis$zuf.bel.1)
```

Wir müssen außerdem noch überprüfen, ob die Variablen entsprechend ihres Messniveaus kodiert sind:

```{r}
str(daten)
```

Wie erhofft liegt die nominalskalierte Variable `job` als ungeordneter Faktor und die intervallskalierte Variable `zf_belastung` als <span class="r">numeric vor.

Mehr Informationen zu Datentypen und angemessener Kodierung finden wir im Kapitel [Einführung in R](Einfuehrung_in_R.qmd).

</p></details>
\

## $t$-Test {#github-link}

> Der $t$-Test untersucht, ob es signifikante Mittelwertsunterschiede in der Population hinsichtlich einer metrischen Variablen gibt. Der Begriff umfasst eine Gruppe von Hypothesentests, darunter den $t$-Test für unabhängige Stichproben und den $t$-Test für abhängige Stichproben <font size="2">(Beobachtungspaare)</font>. 

In unserem Beispiel schauen wir, ob sich Personen mit und ohne  **Nebenjob** (`job`) hinsichtlich der **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) unterscheiden.

Weil es sich bei Studierenden mit und ohne Nebenjob um zwei voneinander unabhängige Stichproben <font size="2">(d.h. unterschiedliche Personen)</font> handelt, verwenden wir den __$t$-Test für unabhängige Stichproben__. 

<p style="line-height:10px;"></p>

<details><summary>Überprüfung der Annahmen des $t$-Tests</summary><div class="more">\

> *__Achtung__*:  <div class="rows">An dieser Stelle sei wieder auf das [ausführliche Skript](Voraussetzungspruefung.qmd) zur Annahmenprüfung verwiesen. Im Folgenden schauen wir uns jeweils nur ein mögliches Verfahren zur Überprüfung der spezifischen Annahmen an.\

Zur Durchführung eines $t$-Tests für unabhängige Zufallsstichproben müssen folgende Annahmen erfüllt sein: 

- <font color="green">es muss sich um __einfache, voneinander unabhängige Stichproben__ handeln</font>
- __Normalverteilung__ des untersuchten Merkmals in beiden Populationen 
- __Varianzhomogenität__ des untersuchten Merkmals in beiden Populationen

\
<!--
<span class="highlight">Intervallskalierung

Im Codebook steht zu `zuf.bel.1` <font size="2">(was bei uns `zf_belastung` ist)</font> *"Je höher der Wert, desto stärker die Ausprägung"*, was auf eine Intervallskalierung schließen lässt. 

Jetzt müssen wir noch prüfen, ob das Messniveau auch in <span class="r">R korrekt repräsentiert wird. Intervallskalierte Daten werden mit numerischen Datentypen kodiert. Mit der Funktion `str()` können wir diesen überprüfen.

```{r}
str(daten$zf_belastung)
```

Unser interessierendes Merkmal `zf_belastung` liegt als <span class="r">numeric vor.

Mehr zu Datentypen und -strukturen erfahren wir in [Einführung in R](Einfuehrung_in_R.qmd).
-->
<span class="highlight">Normalverteilung

Schauen wir uns dazu jeweils für beide Gruppen von `job` einen **QQ-Plot** an.\

<!-- ```{r, warning=FALSE} -->
<!-- library(ggplot2) -->
<!-- ggplot(data = daten, aes(x = zf_belastung)) + # Koordinatensystem -->
<!--   geom_histogram() + # Histogramm -->
<!--   facet_grid(~ job) # einzelne Plots nach den Ausprägungen von job -->
<!-- # die Kategorie NA fasst die fehlenden Werte auf der Variablen job zusammen -->
<!-- # diese können wir hier unbeachtet lassen -->
<!-- ``` -->

```{r}
#| warning: false
library(ggplot2)
ggplot(data = daten, aes(sample = zf_belastung)) + # Koordinatensystem
  stat_qq() + stat_qq_line() + # QQ-Plot + Hilfslinie
  facet_grid(~ job) # einzelne Plots nach den Ausprägungen von job
# die Kategorie NA fasst die fehlenden Werte auf der Variablen job zusammen
# diese können wir hier unbeachtet lassen
```

Mehr Informationen zum Erstellen von Grafiken mit dem Paket **ggplot2** finden wir im Kapitel zu [Grafiken](Grafiken.qmd).\

> *__Achtung__*:  <div class="rows">Hilfe zur Interpretation von QQ-Plots finden wir hier: @sec-Normalverteilung-der-Residuen.\
**Hinweis**: Die Residuen in der linearen Regression sind beim $t$-Test dasselbe wie in den Gruppen zentrierte Werte der $AV$ (d.h. Abweichungen vom gruppenspezifischen Mittelwert) in unserem Beispiel.\

In beiden Diagrammen weichen die Punkte leicht von der Linie ab, d.h. dass die Daten nicht perfekt normalverteilt sind. Wir können uns aber auf den zentralen Grenzwertsatz stützen, welcher besagt, dass der Mittelwert eines Merkmals bei wachsender Stichprobengröße approximativ normalverteilt ist. Generell gibt es keinen Richtwert, der besagt, wann Stichproben hinreichend groß sind. Mit unseren Stichprobengrößen ($n_{ja} = 87$ und $n_{nein} = 86$) und den geringfügigen Abweichungen von einer Normalverteilung in den beiden Gruppen können wir erwarten, dass die Annahme hinreichend erfüllt ist.\

<span class="highlight">Varianzhomogenität

> Varianzhomogenität bedeutet, dass die Varianzen in den untersuchten Populationen gleich sind. Wenn dies der Fall ist, sollten sich auch die Stichprobenvarianzen ähneln. 

Ist diese Annahme nicht erfüllt, müssen wir auf robustere Methoden, z.B. den Welch's $t$-Test für unabhängige Stichproben, zurückgreifen.

Zur Überprüfung der Varianzhomogenität können wir beispielsweise den __Levene Test__ nutzen. In diesem wird die Nullhypothese überprüft, dass die Populationsvarianzen homogen sind ($\sigma^2_{ja} = \sigma^2_{nein}$). Weil die $H_0$ die Wunschhypothese ist, ist es von größerer Relevanz, diese nicht fälschlicherweise abzulehnen, d.h. einen $\beta$-Fehler zu machen <font size="2">(relativ gesehen zum $\alpha$-Fehler)</font>. Wir können das Risiko für einen $\beta$-Fehler nur *indirekt* kontrollieren, indem wir das $\alpha$-Level erhöhen. Daher legen wir unser Signifikanzniveau auf $\alpha=.20$ <font size="2">(zweiseitig)</font> fest.

Wir führen den Test mit der Funktion `leveneTest()` aus dem Paket **car** durch.

```{r}
#| results: markup
#| eval: !expr T
library(car)
leveneTest(zf_belastung ~ job, daten)
```

Da der $p$-Wert (`Pr(>F)`) größer als unser $\alpha$-Level ist, können wir die $H_0$ beibehalten. 

Nachdem die Annahmen weitgehend erfüllt erscheinen, können wir den $t$-Test für unabhängige Stichproben anwenden.

</details>
\

Mit der Funktion `t.test()` aus dem Basispaket **stats** können unterschiedliche Arten von $t$-Tests durchgeführt werden. Welches Verfahren verwendet werden soll, legen wir mit den Parametern `paired` und `var.equal` fest.


- Mit `paired` spezifizieren wir, ob eine **Abhängigkeit der  Stichproben** besteht.
`TRUE` zu einem $t$-Test für Beobachtungspaare, `FALSE` führt zur Durchführung eines $t$-Tests für unabhängige Stichproben.

- Mit `var.equal` spezifizieren wir, ob **Varianzhomogenität** vorliegt. Wenn die Annahme nicht erfüllt ist, legen wir mit `FALSE` fest, dass der Welch's $t$-Test durchgeführt werden soll.

Wir wollen einen *ungerichteten* $t$-Test für unabhängige Stichproben durchführen und legen unser Signifikanzlevel $\alpha=.05$ fest. 

```{r}
#| label: t-Test
#| eval: false
t.test(formula = zf_belastung ~ job, 
       data = daten,
       paired = FALSE, # unabhängige SP
       var.equal = TRUE, # Annahme Varianzhomogenität erfüllt
       alternative ="two.sided", # zweiseitige (ungerichtete) Testung
       na.action = "na.exclude") # Ausschluss fehlender Werte
```

<aside>\
Mehr Informationen zum Umgang mit fehlenden Werten finden wir im Kapitel [Fehlende Werte](Fehlende-Werte.qmd).</aside>

```{r}
#| label: t-test out
#| out.width: 550px
#| echo: false
knitr::include_graphics("figures/Voraussetzungsprüfung/Bilder/t-test.png")
```

Wir erhalten u.a. folgende Informationen: 

- <font color="#FF2600">`t`</font>: empirische Prüfgröße des $t$-Tests
- <font color="#77BB40">`df`</font>: Anzahl der Freiheitsgerade der $t$-Verteilung <font size="2">(entspricht $N-2$)</font>\

<details class="bsp" style="background:white; border-style: solid; border-color:black; color:black;"><summary>Wir kommen wir auf $N=169$?</summary><div>
Wir haben alle Fälle mit fehlenden Werten auf *einer* der beiden Variablen ausgeschlossen (*casewise deletion* durch `na.action = "na.exclude"`). Wir können diese Bedingung folgendermaßen auf unseren Datensatz anwenden, um $N$ für unsere spezifische Analyse zu berechnen:

```{r}
nrow(daten[!is.na(daten$job) & !is.na(daten$zf_belastung),])
```

Für mehr Informationen siehe das Kapitel zu [Fehlenden Werten](Fehlende-Werte.qmd).
</details>

<p style="line-height:10px;"></p>

- <font color="#0533FF">`p-value`</font>: in $p$-Wert umgerechneter empirischer $t$-Wert <!--, also die Wahrscheinlichkeit, den gegebenen empirischen $t$-Wert oder einen extremeren zu erhalten, wenn die $H_0$ gilt.-->\
Durch den Vergleich mit unserem $\alpha$-Niveau können wir anhand dieser Information zu einer Testentscheidung gelangen. Ist der $p$-Wert kleiner als $\alpha$, verwerfen wir die $H_0$. 
- <font color="#FF9300">`95 percent confidence interval`</font>: obere und untere Grenze des 95% Konfidenzintervalls der *Mittelwertsdifferenz*
- <font color="#942192">`sample estimates`</font>: Stichprobenmittelwerte der Gruppen

Durch Betrachtung des $p$-Wertes stellen wir fest, dass die Wahrscheinlichkeit unter Gültigkeit der $H_O$, einen empirischen $t$-Wert von $\mid -1.278 \mid$ oder extremer zu erhalten, bei 20.3% liegt. Da dieser $p$-Wert deutlich über $\alpha=.05$ liegt, behalten wir die Nullhypothese bei. Wir gehen davon aus, dass Studierende mit und ohne Nebenjob sich *nicht* statistisch signifikant in ihrer Zufriedenheit mit der Bewältigung von Studienbelastungen unterscheiden. 


## Lineare Regression

> Die lineare Regression ermöglicht es, eine abhängige Variable <font size="2">(AV, Kriterium)</font> durch eine oder mehrere unabhängige Variablen <font size="2">(UVs, Prädiktoren)</font> vorherzusagen. Das Kriterium muss metrisch sein, wohingegen die Prädiktoren auch kategorial sein können, wenn sie adäquat kodiert sind <font size="2">(siehe z.B. [Indikatorvariablen: Kodierung nominaler Merkmale][Indikatorvariablen: Kodierung nominaler Merkmale] im Kapitel Datenvorbereitung)</font>.

<aside>\
ein Prädiktor: *einfache* lineare Regression;\
\
mehrere Prädiktoren: *multiple* lineare Regression</aside> 

Wir führen eine einfache lineare Regression durch, in der wir die **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) auf das Vorhandensein eines **Nebenjobs** (`job`) zurückführen.

Wir legen unser Signifikanzlevel auf $\alpha=.05$ fest.

Bei der linearen Regression ist die sogenannte Residualdiagnostik ein essentieller Teil der Annahmenprüfung. Allerdings müssen wir dafür die Regression bereits durchgeführt haben. Wir können die Annahmenprüfung also erst *nach* der Regression machen.

Mit der Funktion `lm()` aus dem Basispaket **stats** können wir eine lineare Regression durchführen.

```{r}
#| eval: !expr T
lm_belastung <- lm(formula = zf_belastung ~ job,
                   data = daten, 
                   na.action = "na.exclude") # Ausschluss fehlender Werte
```

Mehr Informationen zum Umgang mit fehlenden Werten finden wir im Kapitel [Fehlende Werte](Fehlende-Werte.qmd).

Das Ergebnisobjekt `lm_belastung` schauen wir uns erst *nach* der Annahmenprüfung an.

<p style="line-height:10px;"></p>

<details><summary>Überprüfung der Annahmen der (einfachen) linearen Regression</summary><div class="more">\

> *__Achtung__*:  <div class="rows">Im Rahmen dieses Kapitels besprechen wir die Annahmen und deren Überprüfung nicht im Detail. Mehr Informationen finden wir im Kapitel zur [Prüfung der Annahmen der multiplen linearen Regression](Voraussetzungspruefung.qmd), die denen der einfachen linearen Regression sehr ähnlich ist.\

```{r}
#| echo: !expr F
# aus Bortz S. 192f
# drei Annahmen: Linearität, Homoskedastizität, Normalität
# aus Folien Meth II: Normlaverteilung y-Werte, + Unabhängigkeit der Residuen
```

Folgende vier Annahmen sind bei der einfachen linearen Regression mit der inferenzstatistischen Absicherung verbunden:

- __Linearität__
- __Homoskedastizität__
- __Normalverteilung__ der Residuen
- __Unabhängigkeit der Residuen__

\

<span class="highlight">Linearität

> Die Abhängigkeit zwischen Erwartungswert des Kriteriums und Prädiktor ist linear.

Diese Annahme lässt sich mittels eines **Residualplots** untersuchen. Dieser plottet die vorhergesagten Kriteriumswerte $\hat y_i$ gegen die Residuen $\hat e_i$.

```{r}
#| label: Linearitätsannahme
#| eval: !expr T
plot(lm_belastung, which=1)
```
Weil wir nur eine kategoriale $UV$ mit zwei Ausprägungen haben, ordnen sich die Punkte in zwei vertikalen Linien an.

Da sich die Lowess Fit Line <font size="2">(rote gestrichelte Linie)</font>, welche den generellen (nonparametrischen) Trend der Daten beschreibt, dem Erwartungswert der Residuen bei $y=0$ <font size="2">(schwarze gestrichelten Linie)</font> annähert, können wir annehmen, dass Linearität vorliegt.

Mehr Informationen zur Lowess Fit Line und zum Residuenplot finden wir im Kapitel zur [Prüfung der Annahmen der multiplen linearen Regression](Voraussetzungspruefung.qmd).


<span class="highlight">Homoskedastizität

> Die Varianz der $y$-Werte, die an einer bestimmten Stelle des Prädiktors vorliegt, ist für alle Prädiktorwerte gleich (Varianzhomogenität).

Diese haben wir bereits im Abschnitt zum [$t$-Test](#github-link) mittels des **Levene-Tests** überprüft. 

Den Residualplot, den wir gerade zur Überprüfung der Annahme der Linearität genutzt haben, können wir auch zur Überprüfung der Annahme der Homoskedatizität nutzen. Weil die Residuen sich ohne erkennbares Muster um den Erwartungswert der Residuen bei $y=0$ <font size="2">(schwarze gestrichelten Linie)</font> verteilen, nehmen wir Homoskedastizität an.

<span class="highlight">Normalverteilung der Residuen

> Die Verteilung der $y$-Werte an einer bestimmten Stelle der $UV$ ist eine Normalverteilung.

```{r}
#| echo: !expr F
# asymptotisch normalverteilt aus Master VL
```

Eine Verletzung dieser Annahme ist eher in kleineren Stichproben problematisch. In großen Stichproben sind die Regressionskoeffizienten aufgrund des zentralen Grenzwertsatzes selbst dann asymptotisch normalverteilt, wenn die Annahme nicht erfüllt ist. Es gibt jedoch keinen Richtwert, ab wann eine Stichprobe als hinreichend groß gilt. Wir sollten die Annahme immer überprüfen. Dazu schauen wir uns einen **QQ-Plot** der Residuen an.

```{r}
#| label: Normalität
#| eval: !expr T
plot(lm_belastung, which=2)
```

Unser Kriterium Zufriedenheit mit der Bewältigung von Studienbelastungen scheint in Abhängigkeit der Gruppenzugehörigkeit leicht von einer Normalverteilung abzuweichen. Die Größe unserer Stichprobe, $N = 169$, legt nahe, dass <font size="2">(nach dem zentralen Grenzwertsatz)</font> die Regressionskoeffizienten approximativ normalverteilt sind und der Standardfehler der Steigung nicht verzerrt ist.

<span class="highlight">Unabhängigkeit der Residuen

> Die Höhe des Residuums einer Beobachtung ist unabhängig von der Höhe des Residuums einer anderen Beobachtung.

**Serielle Abhängigkeit**, d.h. mehrere Messungen von *einer* Person, können wir ausschließen, da es sich nicht um ein Messwiederholungs-Design handelt.

Zur Überprüfung auf **Clustering**, d.h. systematische Zusammenhänge *zwischen* Personen einer Gruppe, müssten wir im Verdacht stehende (erhobene) Gruppenvariablen begutachten. Da dies aber den Rahmen dieses Kapitels sprengen würde, lassen wir das außen vor.

Da wir keine Hinweise auf Verletzung der Annahmen gefunden haben, schauen wir uns nun die Ergebnisse der einfachen linearen Regression an.

</details>
\

Wir schauen uns die Ergebnis unseres Regressionsmodells mittels `summary()` an:

```{r}
#| label: lineare Regression
#| eval: false
summary(lm_belastung)
```

```{r}
#| label: lm out
#| out.width: 550px
#| echo: false
knitr::include_graphics("figures/Voraussetzungsprüfung/Bilder/lm neu.png")
```

Der Output sagt uns, inwiefern wir **Zufriedenheit mit der Bewältigung von Studienbelastungen** mit dem **Vorliegen eines Nebenjobs** vorhersagen können.

Wir bekommen Auskunft über:

- die Signifikanztests der geschätzten Populationskoeffizienten $\hat b_0$ und $\hat b_1 ... \hat b_k$ <font size="2">(unserer $k$ Prädiktoren)</font> 
- den Signifikanztest der insgesamt aufgeklärten Varianz des gesamten Regressionsmodells $R^2$

In unserem Fall einer einfachen linearen Regression sind die Ergebnisse der Signifikanztestung von Schätzung der Steigung und Schätzung der Varianzaufklärung des Gesamtmodells identisch.

Unter `Coefficients` finden wir Informationen zu den geschätzten **Regressionskoeffizienten** - Intercept und Steigungskoeffizient(en): 

```{r}
#| label: lm out o
#| out.width: 450px
#| echo: false
knitr::include_graphics("figures/Voraussetzungsprüfung/Bilder/lm oben.png")
```

- <font color="#FF2600">`Estimate`</font>: Schätzung der (Populations-)Regressionskoeffizienten
  - `(Intercept)`: vorhergesagter Wert des Kriteriums wenn alle Prädiktoren 0 sind <font size="2">(bei metrischen Prädiktoren)</font> bzw. vorhergesagter Wert des Kriteriums in den jeweiligen Referenzgruppen <font size="2">(bei kategorialen Prädiktoren)</font>; Wert von `zf_belastung` in der Referenzgruppe `job == ja` 
  - `jobnein`: Steigungskoeffizient, der die erwartete Veränderung im Kriterium angibt, wenn der Prädiktor um eine Einheit erhöht wird <font size="2">(bei metrischen Prädiktoren)</font> bzw. in (einer) der Vergleichsgruppen <font size="2">(bei kategorialen Prädiktoren)</font>; Unterschied von `job == nein` im Vergleich zur Referenzgruppe `job == ja` im Hinblick auf `zf_belastung`
- <font color="#77BB40">`Std.Error`</font>: Standardfehler des Regressionskoeffizienten
- <font color="#0533FF">`t.value`</font>: empirischer $t$-Wert für die Signifikanztestung des (partiellen) Regressionskoeffizienten
- <font color="#FF9300">`Pr(>|t|)`</font>: in $p$-Wert umgerechneter empirischer $t$-Wert
- <font color="#942192">`Sign.codes`</font>: durch Sternchen gekennzeichnete Signifikanzniveaus der geschätzten Regressionskoeffizienten

Der Intercept $b_0 = 2.679$ gibt uns den Mittelwert der Personen **mit Nebenjob** (`job == "ja"`, Referenzgruppe) auf der Skala von **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) an. Wir gelangen durch Betrachtung von $p < 2^{-16}$ zu der Testentscheidung, die $H_0$, dass der Intercept in der Population 0 ist, abzulehnen.

<aside>\
$t$-Test des Intercepts $b_0$:\
$H_0$: $\beta_0 = 0$\
$H_1$: $\beta_0 > 0$</aside>

Der Steigungskoeffizient $b_1 = 0.131$ sagt uns, dass Personen **ohne Nebenjob** (`job == "nein"`) sich im Mittel 0.131 Punkte höher auf der Skala von **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) beschreiben. Zudem gelangen wir durch Betrachtung von $p = 0.203$ zu der Testentscheidung, die $H_0$, dass der Populationskoeffizient $\beta_1 = 0$ ist, beizubehalten.

<aside>\
$t$-Test des Steigungs-koeffizienten $b_1$:\
$H_0$: $\beta_1 = 0$\
$H_1$: $\beta_1 \neq 0$</aside>

<p style="line-height:10px;"></p>

Im unteren Abschnitt finden wir Informationen bezüglich des **Gesamtmodells**:

```{r}
#| label: lm out u
#| out.width: 475px
#| echo: false
knitr::include_graphics("figures/Voraussetzungsprüfung/Bilder/lm unten.png")
```

- <font color="#FE41FF">`Residual Standard Error`</font>: Standardschätzfehler $s_e$\
Gütemaß für die Genauigkeit der Regressionsvorhersage
- <font color="#AA7942">`Multiple R-squared`</font>: Determinationskoeffizient $R^2$\
Gütemaß für die Schätzgenauigkeit
- <font color="#AA7942">`Adjusted R squared`</font>: korrigierter Determinationskoeffizient $R_{korr}^2$; gilt durch Korrektur der Freiheitsgrade als erwartungstreuer Schätzer für die Population
- <font color="#00FDFF">`F-statistic`</font>: empirischer Wert des $F$-Tests des Determinationskoeffizienten $R^2$ <font size="2">(d.h. des Gesamtmodells)</font> mit Anzahl der Zähler- <font size="2">($k$)</font> und Nenner-Freiheitsgrade <font size="2">($N-k-1$)</font> der $F$-Verteilung mit zugehörigem $p$-Wert.

<aside>\
\
\
\
\
\
\
Handelt es sich um eine einfache lineare Regression mit nur einem Prädiktor (wie in unserem Fall), führt der $F$-Test des Determinations-koeffizienten zum selben Ergebnis wie der $t$-Test des Steigungs-koeffizienten.</aside> 

<!-- <aside> __Beachte: Als Sonderform des Allgemeinen Linearen Modells weist der zuvor besprochene *t*-Test einige Zusammenhänge mit der linearen Regression auf. So entspricht der empirische *t*-Wert von `lm()` immer der empirischen Prüfgröße des t-Tests__  __(In unserem Fall t = I0.652I).__  __Potentiell unterschiedliche Vorzeichen haben hierbei keine Bedeutung. Zudem entspricht der *F*-Wert der `lm()`-Funktion (i.d.R.) der quadrierten empirischen Prüfgröße des *t*-Tests (*t²*). Näheres zu den Zusammenhängen des ALM findet ihr [am Ende des Skripts](#github2).__
</aside> -->

Der Determinationskoeffizienten $R^2 = 0.009685$ sagt aus, dass in unserer Stichprobe knapp 1% der Variation in der **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) durch das Vorhandensein eines **Nebenjobs** (`job`) erklärt werden kann. Wir können die $H_0$, dass der Determinationskoeffizient in der Population $0$ ist ($\rho^2 = 0$), durch Betrachtung von $p = 0.203$ beibehalten.

<aside>\
$F$-Test des Determinations-koeffizienten $R^2$:\
$H_0: \rho^2 = 0$\
$H_1: \rho^2 > 0$</aside>


## ANOVA

> Eine ANOVA (Analysis of Variance) überprüft den Einfluss von einer bzw. mehreren kategorialen unabhängigen Variablen <font size="2">(UVs, Faktoren)</font> mit $p$ Faktorstufen auf eine metrische abhängige Variable <font size="2">(AV)</font>. Dazu wird eine Varianzdekomposition durchgeführt, welche die Gesamtvarianz in systematische und Fehlervarianz zerlegt.

<!--Basierend auf dem Prinzip der Varianzdekomposition testet sie, inwiefern die Gesamtunterschiedlichkeit in der $AV$ auf die unterschiedlichen Faktorstufen der $UV(s)$ zurückzuführen ist. Hierbei wird die Gesamtvarianz in die systematische Varianz *zwischen* den Gruppen (*"des Gruppierungsfaktors"*) und die Varianz *innerhalb* der Gruppen (*"der Residuen"*) zerlegt und das Verhältnis dieser beiden Varianzanteile zueinander überprüft: Ist die Varianz zwischen den Gruppen im Verhältnis zur Varianz innerhalb der Gruppen groß, wird die Nullhypothese verworfen. --> 

Wir wollen in unserem Beispiel überprüfen inwiefern Unterschiede in der **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) auf das Vorhandensein eines **Nebenjobs** (`job`) zurückzuführen ist.

Wir haben ein minimal **unbalanciertes Design**, weil die Anzahl der Beobachtungen in den Faktorstufen von `job` sich geringfügig unterscheiden mit $n_{ja} = 87$ und $n_{nein} = 86$.

Unser Signifikanzlevel legen wir auf $\alpha=.05$ fest.

```{r}
#| echo: !expr F
# auch im Bortz keine Hinweise auf Annahmenprüfung für ANOVA
```

<p style="line-height:10px;"></p>

<details><summary>Überprüfung der Annahmen der ANOVA</summary><div class="more">

Vor der Durchführung der ANOVA mit unseren Beispieldaten müssen wir zwei Annahmen prüfen: 

- __Normalverteilung__ des untersuchten Merkmals in beiden Populationen 
- __Homoskedastizität__ des untersuchten Merkmals in beiden Populationen

\

Beides haben wir im Rahmen der Durchführung des [$t$-Test](#github-link) bereits untersucht und Evidenz dafür gefunden.
</details>
\

Zur Durchführung der ANOVA verwenden wir die `aov()`Funktion. 

```{r}
#| eval: false
anova <- aov(zf_belastung ~ job, 
             data = daten, 
             na.action = "na.exclude") # Ausschluss fehlender Werte
summary(anova)
```

<aside>Mehr Informationen zum Umgang mit fehlenden Werten im [gleichnamigen Kapitel](Fehlende-Werte.qmd).</aside>

```{r}
#| label: aov out
#| out.width: 400px
#| echo: false
#| fig.align: center
# man bekommt auch nur mit anova Ouput, aber wesentlich weniger Details
# aber dafür Standardschätzfehler
knitr::include_graphics("figures/Voraussetzungsprüfung/Bilder/aov.png")
```

Der Output liefert die folgenden Informationen für den Gruppierungsfaktor (`job`) und für die Residuen (`Residuals`): 

- <font color="#FF2600">`Df`</font>: Anzahl der Freiheitsgrade der $F$-Verteilung
  - ... des Gruppierungsfaktor: $df_{job} = p - 1$
  - ... der Residuen:  $df_{e} = N-p$
- <font color="#77BB40">`Sum Sq`</font>: Quadratsumme
  - ... des Gruppierungsfaktors (*"Treatmentquadratsumme"*)
  - ... der Residuen (*"Fehlerquadratsumme"*)
- <font color="#0533FF">`Mean Sq`</font>: Mittlere Quadratsumme <font size="2">(MQ)</font>\
relativieren die Quadratsumme eines Effekts an seinen Freiheitsgraden 
- <font color="#FF9300">`F value`</font>: empirische Prüfgröße des $F$-Tests\
entspricht dem Quotienten $\frac {MQ_{job}} {MQ_e}$
- <font color="#942192">`Pr(>F)`</font>: in $p$-Wert umgerechneter empirischer $F$-Wert

<!-- 
<aside> __Beachte: Auch die ANOVA weist als Sonderform des Allgemeinen Linearen Modells  Zusammenhänge mit der linearen Regression auf. Hierbei entspricht der empirische *F*-Wert der aov Funktion dem *F*-Wert des globalen Tests der `lm()`-Funktion.__  __(In unserem Fall F=0.316).__  __Näheres zu den Zusammenhängen des ALM findet ihr [hier](#github2).__
</aside> 
-->

Unser $p$-Wert deutet darauf hin, dass unter Gültigkeit der $H_0$ die Wahrscheinlichkeit, den vorliegenden $F$-Wert von 1.633 oder einen größeren zu erhalten, 20,3% beträgt. Wir kommen somit zu der Testentscheidung, die $H_0$ beizubehalten. Das bedeutet, dass wir davon ausgehen, dass zwischen den Populationen von Studierenden mit und ohne Nebenjob keine überzufälligen Mittelwertsunterschiede bezüglich der Zufriedenheit mit der Bewältigung von Studienbelastungen  existieren.


## ALM: Zusammenhänge der drei Verfahren  {#github2}

Wie bereits eingangs erwähnt, gehören $t$-Test, lineare Regression und ANOVA alle zum Allgemeinen Linearen Modell <font size="2">(ALM)</font>.

Für den hier betrachteten Spezialfall von nur einer UV mit nur zwei Stufen <font size="2">(und adäquater Kodierung; siehe z.B. [Indikatorvariablen: Kodierung nominaler Merkmale][Indikatorvariablen: Kodierung nominaler Merkmale] aus dem Kapitel Datenvorbereitung)</font> kommen die drei Verfahren zum selben Ergebnis bei der Signifikanztestung, obwohl scheinbar andere Hypothesen getestet werden.

```{r}
#| echo: false
#| column: l-body-outset
library(kableExtra)
library(knitr)

Verfahren <- c("$t$-Test für unabhängige Stichproben", "einfache lineare Regression",
               "einfache lineare Regression", "ANOVA")
Hypothesentest <- c("Mittelwertsunterschied in den Gruppen\n\n$H_0$: $\\mu_1 = \\mu_2$\n\n$H_1$: $\\mu_1 \\neq \\mu_2$ <font size=\"1\">(ungerichtet)</font>", "Steigungskoeffizient $b_1$\n\n$H_0$: $\\beta_1 = 0$\n\n$H_1$: $\\beta_1 \\neq 0$ <font size=\"1\">(ungerichtet)</font>", "Determinationskoeffizient $R^2$\n\n$H_0$: $\\rho^2 = 0$\n\n$H_1$: $\\rho^2$ > $0$ <font size=\"1\">(gerichtet)</font>", "Mittelwertsunterschied in den Gruppen\n\n$H_0$: $\\mu_1 = \\mu_2$\n\n$H_1$: $\\mu_1 \\neq \\mu_2$ <font size=\"1\">(ungerichtet)</font>") 
"t" <- c("-1.278", "1.278", "", "")
"F" <- c("", "", "1.633", "1.633")
"p" <- c("0.203", "0.203", "0.203", "0.203")

tabelle <- data.frame(Verfahren, Hypothesentest, t, F, p)
names(tabelle) <- c("Verfahren", "getestete Hypothesen", "$t$", "$F$", "$p$")

kable(tabelle, escape=FALSE) %>%
  kable_styling(full_width = TRUE, c("condensed")) %>%
  add_header_above(c(" " = 2, "Empirische Prüfgröße" = 3),
                   color = "white", background = "#009193") %>%
  row_spec(0, bold = T, color = "white", background = "#009193") %>%
  column_spec(1, bold = T, color = "white", background = "#009193", 
              width="15em") %>%
  collapse_rows(columns = 1, valign = "middle")
```

Wir können $t$- und $F$-Werte ineinander überführen durch folgende Formel: $F = t^2 \longrightarrow t^2=1.278^2=1.633=F$.

> *__Achtung__*:  <div class="rows"> Dass der $t$-Wert einmal negativ <font size="2">($t$-Test)</font> und einmal positiv <font size="2">(einfache lineare Regression)</font> ist liegt daran, dass die Gruppen jeweils vertauscht wurden.\

Das __Allgemeine Lineare Modell__ <font size="2">(ALM)</font> umfasst varianzanalytische Verfahren sowie (multiple) Korrelations- und Regressionsrechnung. Dadurch können nicht nur metrische sondern auch kategoriale Merkmale <font size="2">(als $UV$s)</font> untersucht werden, sofern die kategorialen Merkmale in geeigneter Form kodiert sind.

<aside>\
\
Mehr Informationen zu Kodierung gibt es im Kapitel [Einführung in R](Einfuehrung_in_R.qmd).</aside>

In unserem Fall von einer intervallskalierten $AV$ und einer nominalskalierten $UV$ werden in den drei Verfahren jeweils die Mittelwerte der $AV$ für die jeweiligen $UV$ gebildet. Beim $t$-Test und der einfachen linearen Regression haben wir diese auch ausgegeben bekommen:

- $t$-Test:\
`mean in group ja` $= 2.67$\
`mean in group nein` $= 2.80$
- Einfache lineare Regression:\
$Intercept = 2.67$\
$b_1 = 0.131$\
$Intercept + b_1 = 2.81$

Dadurch sind die getesteten Hypothesen der drei Verfahren in diesem speziellen Fall <font size="2">($AV$: intervallskaliert, $UV$: nominalskaliert)</font> äquivalent.

---

<font size="2">Um eine möglichst exakte Replikation der Funktionen zu gewährleisten gibt es im folgenden relevante Angaben zum System (**`R`-Version**, **Betriebssystem**, **geladene Pakete mit Angaben zur Version**), mit welchem diese Seite erstellt wurde.

```{r}
sessionInfo()
```

Für Informationen zur Interpretation dieses Outputs schaut auch den Abschnitt [Replizierbarkeit von Analysen](Pakete.qmd#replizierbarkeit-von-analysen) des Kapitels zu Paketen an.</font>







