# Outputs - ALM - FAQ

Das Allgemeine Lineare Modell (ALM) umfasst verschiedene inferenzstatistische und varianzanalytische Verfahren, darunter $t$-Test (`t.test()`), **ANOVA** (`aov()`) und **lineare Regression** (`lm()`).

Im Folgenden schauen wir uns an, wie die **Outputs** der jeweiligen Funktionen `t.test()`, `aov()` und `lm()` aufgebaut sind und wie diese interpretiert werden. Dafür nutzen wir jeweils dieselben zwei Variablen. Wir werden zudem vor der Durchführung der Methoden deren **Annahmen prüfen**. Abschließend beschäftigen wir uns mit den **Gemeinsamkeiten der Verfahren** (für unseren speziellen Fall von einer metrischen abhängigen Variablen und einer kategorialen unabhängigen Variablen).

<aside>\
\
Wir gehen nur knapp auf die Prüfung der Annahmen ein. Eine ausführlichere Einleitung befindet sich [hier](Voraussetzungspruefung.qmd).</aside>

<!--Zur Veranschaulichung untersuchen wir, ob sich Studierende mit und ohne Nebenjob signifikant in ihrer Zufriedenheit mit der Bewältigung von Studienbelastungen unterscheiden. Diese ungerichtete $H_1$ überprüfen wir mit einem Signifikanzniveau von $\alpha = 0.05$. -->

<details>

<summary>Beispieldatensatz für dieses Kapitel</summary>

Wir schauen uns im folgenden den Datensatz `erstis` an. Dieser enthalt Daten aus einer Erhebung mit Erstsemesterstudierenden der Psychologie. Das zugehörige Codebook finden wir <a href="https://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/R_fuer_Einsteiger/Datensatz%20Erstis_Codebook.pdf" target="_blank">hier</a>.

Den Datensatz laden wir mit der `load()`-Funktion in unsere Environment:

```{r}
#| echo: false
load(url("http://www.beltz.de/fileadmin/beltz/downloads/OnlinematerialienPVU/R_fuer_Einsteiger/erstis.rda"))
```

```{r}
#| eval: false
load(url("http://www.beltz.de/fileadmin/beltz/downloads/
         OnlinematerialienPVU/R_fuer_Einsteiger/erstis.rda"))
# Zeilenumbruch zwischen der ersten und zweiten Zeile noch entfernen!
```

Wir wollen untersuchen, ob sich das Vorhandenseins eines **Nebenjobs** (`job`) auf die **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`, erster Messzeitpunkt) auswirkt.

Dazu speichern wir beide Variablen in einem neuen Datensatz.

```{r}
#| eval: true
# Daten aus erstis in neuem Dataframe speichern und umbennenen
daten <- data.frame(job = erstis$job, zf_belastung = erstis$zuf.bel.1)
```

Wir müssen außerdem noch überprüfen, ob die Variablen entsprechend ihres Messniveaus kodiert sind:

```{r}
str(daten)
```

Wie erhofft liegt die nominalskalierte Variable `job` als ungeordneter Faktor und die intervallskalierte Variable `zf_belastung` als numeric vor.

Mehr Informationen zu Datentypen und angemessener Kodierung finden wir im Kapitel [Einführung in R](Einfuehrung_in_R.qmd).

</details>


## $t$-Test {#github-link}

> Der $t$-Test untersucht, ob es signifikante Mittelwertsunterschiede in der Population hinsichtlich einer metrischen Variablen gibt. Der Begriff umfasst eine Gruppe von Hypothesentests, darunter den $t$-Test für unabhängige Stichproben und den $t$-Test für abhängige Stichproben (Beobachtungspaare).

In unserem Beispiel schauen wir, ob sich Personen mit und ohne **Nebenjob** (`job`) hinsichtlich der **Zufriedenheit mit der Bewältigung von Studienbelastungen** (`zf_belastung`) unterscheiden.

Weil es sich bei Studierenden mit und ohne Nebenjob um zwei voneinander unabhängige Stichproben (d.h. unterschiedliche Personen) handelt, verwenden wir den $t$-Test für unabhängige Stichproben.

<details>

<summary>Überprüfung der Annahmen des $t$-Tests</summary>

\

> ***Achtung***: An dieser Stelle sei wieder auf das [ausführliche Skript](Voraussetzungspruefung.qmd) zur Annahmenprüfung verwiesen. Im Folgenden schauen wir uns jeweils nur ein mögliches Verfahren zur Überprüfung der spezifischen Annahmen an.\

Zur Durchführung eines $t$-Tests für unabhängige Zufallsstichproben müssen folgende Annahmen erfüllt sein:

-   es muss sich um **einfache, voneinander unabhängige Stichproben** handeln
-   **Normalverteilung** des untersuchten Merkmals in beiden Populationen
-   **Varianzhomogenität** des untersuchten Merkmals in beiden Populationen

\
<!--
Intervallskalierung

Im Codebook steht zu `zuf.bel.1` (was bei uns `zf_belastung` ist) *"Je höher der Wert, desto stärker die Ausprägung"*, was auf eine Intervallskalierung schließen lässt. 

Jetzt müssen wir noch prüfen, ob das Messniveau auch in R korrekt repräsentiert wird. Intervallskalierte Daten werden mit numerischen Datentypen kodiert. Mit der Funktion `str()` können wir diesen überprüfen.

```{r}
str(daten$zf_belastung)
```

Unser interessierendes Merkmal `zf_belastung` liegt als numeric vor.

Mehr zu Datentypen und -strukturen erfahren wir in [Einführung in R](Einfuehrung_in_R.qmd).
--> Normalverteilung

Schauen wir uns dazu jeweils für beide Gruppen von `job` einen **QQ-Plot** an.\

<!-- ```{r, warning=FALSE} -->

<!-- library(ggplot2) -->

<!-- ggplot(data = daten, aes(x = zf_belastung)) + # Koordinatensystem -->

<!--   geom_histogram() + # Histogramm -->

<!--   facet_grid(~ job) # einzelne Plots nach den Ausprägungen von job -->

<!-- # die Kategorie NA fasst die fehlenden Werte auf der Variablen job zusammen -->

<!-- # diese können wir hier unbeachtet lassen -->

<!-- ``` -->

```{r}
#| warning: false
library(ggplot2)
ggplot(data = daten, aes(sample = zf_belastung)) + # Koordinatensystem
  stat_qq() + stat_qq_line() + # QQ-Plot + Hilfslinie
  facet_grid(~ job) # einzelne Plots nach den Ausprägungen von job
# die Kategorie NA fasst die fehlenden Werte auf der Variablen job zusammen
# diese können wir hier unbeachtet lassen
```

Mehr Informationen zum Erstellen von Grafiken mit dem Paket **ggplot2** finden wir im Kapitel zu [Grafiken](Grafiken.qmd).\

> ***Achtung***: Hilfe zur Interpretation von QQ-Plots finden wir hier: @sec-Normalverteilung-der-Residuen.\
> **Hinweis**: Die Residuen in der linearen Regression sind beim $t$-Test dasselbe wie in den Gruppen zentrierte Werte der $AV$ (d.h. Abweichungen vom gruppenspezifischen Mittelwert) in unserem Beispiel.\

In beiden Diagrammen weichen die Punkte leicht von der Linie ab, d.h. dass die Daten nicht perfekt normalverteilt sind. Wir können uns aber auf den zentralen Grenzwertsatz stützen, welcher besagt, dass der Mittelwert eines Merkmals bei wachsender Stichprobengröße approximativ normalverteilt ist. Generell gibt es keinen Richtwert, der besagt, wann Stichproben hinreichend groß sind. Mit unseren Stichprobengrößen ($n_{ja} = 87$ und $n_{nein} = 86$) und den geringfügigen Abweichungen von einer Normalverteilung in den beiden Gruppen können wir erwarten, dass die Annahme hinreichend erfüllt ist.\

Varianzhomogenität

> Varianzhomogenität bedeutet, dass die Varianzen in den untersuchten Populationen gleich sind. Wenn dies der Fall ist, sollten sich auch die Stichprobenvarianzen ähneln.

Ist diese Annahme nicht erfüllt, müssen wir auf robustere Methoden, z.B. den Welch's $t$-Test für unabhängige Stichproben, zurückgreifen.

Zur Überprüfung der Varianzhomogenität können wir beispielsweise den **Levene Test** nutzen. In diesem wird die Nullhypothese überprüft, dass die Populationsvarianzen homogen sind ($\sigma^2_{ja} = \sigma^2_{nein}$). Weil die $H_0$ die Wunschhypothese ist, ist es von größerer Relevanz, diese nicht fälschlicherweise abzulehnen, d.h. einen $\beta$-Fehler zu machen (relativ gesehen zum $\alpha$-Fehler). Wir können das Risiko für einen $\beta$-Fehler nur *indirekt* kontrollieren, indem wir das $\alpha$-Level erhöhen. Daher legen wir unser Signifikanzniveau auf $\alpha=.20$ (zweiseitig) fest.

Wir führen den Test mit der Funktion `leveneTest()` aus dem Paket **car** durch.

```{r}
#| results: markup
#| eval: !expr T
#| message: false
library(car)
leveneTest(zf_belastung ~ job, daten)
```

Da der $p$-Wert (`Pr(>F)`) größer als unser $\alpha$-Level ist, können wir die $H_0$ beibehalten.

Nachdem die Annahmen weitgehend erfüllt erscheinen, können wir den $t$-Test für unabhängige Stichproben anwenden.

</details>

\

Mit der Funktion `t.test()` aus dem Basispaket **stats** können unterschiedliche Arten von $t$-Tests durchgeführt werden. Welches Verfahren verwendet werden soll, legen wir mit den Parametern `paired` und `var.equal` fest.

-   Mit `paired` spezifizieren wir, ob eine **Abhängigkeit der Stichproben** besteht. `TRUE` zu einem $t$-Test für Beobachtungspaare, `FALSE` führt zur Durchführung eines $t$-Tests für unabhängige Stichproben.

-   Mit `var.equal` spezifizieren wir, ob **Varianzhomogenität** vorliegt. Wenn die Annahme nicht erfüllt ist, legen wir mit `FALSE` fest, dass der Welch's $t$-Test durchgeführt werden soll.

Wir wollen einen *ungerichteten* $t$-Test für unabhängige Stichproben durchführen und legen unser Signifikanzlevel $\alpha=.05$ fest.

```{r}
#| label: t-Test
#| eval: false
t.test(formula = zf_belastung ~ job, 
       data = daten,
       paired = FALSE, # unabhängige SP
       var.equal = TRUE, # Annahme Varianzhomogenität erfüllt
       alternative ="two.sided", # zweiseitige (ungerichtete) Testung
       na.action = "na.exclude") # Ausschluss fehlender Werte
```

<aside>\
Mehr Informationen zum Umgang mit fehlenden Werten finden wir im Kapitel [Fehlende Werte](Fehlende-Werte.qmd).</aside>

```{r}
#| label: t-test out
#| out.width: 550px
#| echo: false
knitr::include_graphics("figures/Voraussetzungsprüfung/Bilder/t-test.png")
```

Wir erhalten u.a. folgende Informationen:

- <span style="color:red"> `t` </span>: empirische Prüfgröße des $t$-Tests
- <span style="color:#59A608"> `df` </span>: Anzahl der Freiheitsgerade der $t$-Verteilung (entspricht $N-2$)\

<details>

<summary>Wie kommen wir auf $N=169$?</summary>

Wir haben alle Fälle mit fehlenden Werten auf *einer* der beiden Variablen ausgeschlossen (*casewise deletion* durch `na.action = "na.exclude"`). Wir können diese Bedingung folgendermaßen auf unseren Datensatz anwenden, um $N$ für unsere spezifische Analyse zu berechnen:

```{r}
nrow(daten[!is.na(daten$job) & !is.na(daten$zf_belastung),])
```

Für mehr Informationen siehe das Kapitel zu [Fehlenden Werten](Fehlende-Werte.qmd).

</details>


- <span style="color:blue"> `p-value` </span>: in $p$-Wert umgerechneter empirischer $t$-Wert <!--, also die Wahrscheinlichkeit, den gegebenen empirischen $t$-Wert oder einen extremeren zu erhalten, wenn die $H_0$ gilt.-->\
Durch den Vergleich mit unserem $\alpha$-Niveau können wir anhand dieser Information zu einer Testentscheidung gelangen. Ist der $p$-Wert kleiner als $\alpha$, verwerfen wir die $H_0$. 
- <span style="color:orange"> `95 percent confidence interval` </span>: obere und untere Grenze des 95% Konfidenzintervalls der *Mittelwertsdifferenz*
- <span style="color:purple"> `sample estimates` </span>: Stichprobenmittelwerte der Gruppen

Durch Betrachtung des $p$-Wertes stellen wir fest, dass die Wahrscheinlichkeit unter Gültigkeit der $H_O$, einen empirischen $t$-Wert von $\mid -1.278 \mid$ oder extremer zu erhalten, bei 20.3% liegt. Da dieser $p$-Wert deutlich über $\alpha=.05$ liegt, behalten wir die Nullhypothese bei. Wir gehen davon aus, dass Studierende mit und ohne Nebenjob sich *nicht* statistisch signifikant in ihrer Zufriedenheit mit der Bewältigung von Studienbelastungen unterscheiden. 

